{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from building_model.Intervalstrategy_research import Intervalstrategy\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/l_cry/Desktop/data/MLtimingdata150107_181120TFCFE.csv')\n",
    "data.rename(columns={'Unnamed: 0': 'date'}, inplace=True)\n",
    "data = data.fillna(method=\"ffill\", axis=0)\n",
    "data['HIGH1'] = data.HIGH.shift(-1)\n",
    "data['HIGH2'] = data.HIGH.shift(-2)\n",
    "data['HIGH3'] = data.HIGH.shift(-3)\n",
    "data['HIGH4'] = data.HIGH.shift(-4)\n",
    "data['HIGH5'] = data.HIGH.shift(-5)\n",
    "data['HIGH6'] = data.HIGH.shift(-6)\n",
    "data['HIGH7'] = data.HIGH.shift(-7)\n",
    "data['maxHigh'] = data[['HIGH', 'HIGH1', 'HIGH2', 'HIGH3', 'HIGH4', 'HIGH5', 'HIGH6']].max(axis=1)\n",
    "data['HIGH_CHG'] = np.log(data['maxHigh']/data.CLOSE.shift(1))*100\n",
    "data['CLOSE3'] = data.CLOSE.shift(-3)\n",
    "data['CLOSE1'] = data.CLOSE.shift(-1)\n",
    "data['CLOSE_CHG_3'] = np.log(data.CLOSE3/data.CLOSE)*100\n",
    "data['CLOSE_CHG'] = np.log(data.PCT_CHG/100+1)*100\n",
    "data['CLOSE_CHG_1'] = np.log(data.CLOSE1/data.CLOSE)*100\n",
    "data['LOW1'] = data.LOW.shift(-1)\n",
    "data['LOW2'] = data.LOW.shift(-2)\n",
    "data['LOW3'] = data.LOW.shift(-3)\n",
    "data['LOW4'] = data.LOW.shift(-4)\n",
    "data['LOW5'] = data.LOW.shift(-5)\n",
    "data['LOW6'] = data.LOW.shift(-6)\n",
    "data['minLOW'] = data[['LOW','LOW1','LOW2','LOW3','LOW4','LOW5','LOW6']].max(axis=1)\n",
    "data['LOW_CHG'] = np.log(data['minLOW']/data.CLOSE.shift(1))*100\n",
    "data = data[data.CLOSE_CHG_1.notnull()].reset_index(drop=True)\n",
    "#all_factorlist = \"atr,bias,cci,dma,dmi,dpo,macd,mtm,priceosc,roc,rsi,sar,si\"\n",
    "all_factorlist = \"PCT_CHG,atr,bias,dma,dmi,dpo,macd,mtm,priceosc,roc,rsi,sar,si\"\n",
    "factorlist = all_factorlist.upper().replace(' ', '').split(\",\")\n",
    "datelist = data['date']\n",
    "# 定义常量\n",
    "days = 100\n",
    "time_step = 1\n",
    "data.head(10)\n",
    "\n",
    "#%%\n",
    "interstra = Intervalstrategy(7)\n",
    "pnl = pd.DataFrame(datelist)\n",
    "pnl['y'] = 0.0\n",
    "pnl['yhat_lstm'] = 0.0\n",
    "pnl['yhat_lstm_0'] = np.nan\n",
    "pnl['yhat_lstm_1'] = np.nan\n",
    "valid_num = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = data[['HIGH_CHG','CLOSE_CHG_1','CLOSE_CHG_3']+factorlist].corr()\n",
    "f, ax= plt.subplots(figsize = (10, 7))\n",
    "sns.heatmap(corr, \n",
    "xticklabels = corr.columns.values, \n",
    "yticklabels = corr.columns.values,ax=ax) # 画热力图 \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1          NaN\n",
       "2      289.952\n",
       "3      290.064\n",
       "4      290.468\n",
       "5      290.962\n",
       "6      291.372\n",
       "7      291.738\n",
       "8      291.902\n",
       "9      292.302\n",
       "10     292.300\n",
       "11     292.646\n",
       "12     292.744\n",
       "13     293.096\n",
       "14     292.972\n",
       "15     292.962\n",
       "16     292.408\n",
       "17     292.142\n",
       "18     292.236\n",
       "19     292.706\n",
       "20     293.604\n",
       "21     294.044\n",
       "22     294.612\n",
       "23     294.746\n",
       "24     295.128\n",
       "25     295.804\n",
       "26     296.608\n",
       "27     297.264\n",
       "28     297.494\n",
       "29     297.750\n",
       "        ...   \n",
       "914    293.305\n",
       "915    293.395\n",
       "916    293.720\n",
       "917    293.960\n",
       "918    294.110\n",
       "919    294.120\n",
       "920    294.080\n",
       "921    294.205\n",
       "922    294.215\n",
       "923    294.180\n",
       "924    294.140\n",
       "925    294.215\n",
       "926    294.430\n",
       "927    294.545\n",
       "928    294.765\n",
       "929    294.925\n",
       "930    295.090\n",
       "931    295.105\n",
       "932    294.885\n",
       "933    294.710\n",
       "934    294.695\n",
       "935    295.030\n",
       "936    295.410\n",
       "937    295.550\n",
       "938    295.540\n",
       "939    295.455\n",
       "940    295.600\n",
       "941    295.875\n",
       "942    296.290\n",
       "943    296.465\n",
       "Name: CLOSE, Length: 944, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.CLOSE.rolling(3).apply(lambda x: sum(x),raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-07\n",
      "2016-01-08\n",
      "2016-01-11\n",
      "2016-01-12\n",
      "2016-01-13\n",
      "2016-01-14\n",
      "2016-01-15\n",
      "2016-01-18\n",
      "2016-01-19\n",
      "2016-01-20\n",
      "2016-01-21\n",
      "2016-01-22\n",
      "2016-01-25\n",
      "2016-01-26\n",
      "2016-01-27\n",
      "2016-01-28\n",
      "2016-01-29\n",
      "2016-02-01\n",
      "2016-02-02\n",
      "2016-02-03\n",
      "2016-02-04\n",
      "2016-02-05\n",
      "2016-02-15\n",
      "2016-02-16\n",
      "2016-02-17\n",
      "2016-02-18\n",
      "2016-02-19\n",
      "2016-02-22\n",
      "2016-02-23\n",
      "2016-02-24\n",
      "2016-02-25\n",
      "2016-02-26\n",
      "2016-02-29\n",
      "2016-03-01\n",
      "2016-03-02\n",
      "2016-03-03\n",
      "2016-03-04\n",
      "2016-03-07\n",
      "2016-03-08\n",
      "2016-03-09\n",
      "2016-03-10\n",
      "2016-03-11\n",
      "2016-03-14\n",
      "2016-03-15\n",
      "2016-03-16\n",
      "2016-03-17\n",
      "2016-03-18\n",
      "2016-03-21\n",
      "2016-03-22\n",
      "2016-03-23\n",
      "2016-03-24\n",
      "2016-03-25\n",
      "2016-03-28\n",
      "2016-03-29\n",
      "2016-03-30\n",
      "2016-03-31\n",
      "2016-04-01\n",
      "2016-04-05\n",
      "2016-04-06\n",
      "2016-04-07\n",
      "2016-04-08\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.7245 - acc: 0.5294 - val_loss: 0.6913 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7034 - acc: 0.5882 - val_loss: 0.6909 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6861 - acc: 0.5686 - val_loss: 0.6906 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6756 - acc: 0.6078 - val_loss: 0.6903 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6678 - acc: 0.6078 - val_loss: 0.6895 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.6588 - acc: 0.6078 - val_loss: 0.6890 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6500 - acc: 0.6078 - val_loss: 0.6887 - val_acc: 0.6000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6428 - acc: 0.6078 - val_loss: 0.6883 - val_acc: 0.6000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.6363 - acc: 0.6078 - val_loss: 0.6877 - val_acc: 0.6000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6291 - acc: 0.6275 - val_loss: 0.6875 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6223 - acc: 0.6667 - val_loss: 0.6870 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6163 - acc: 0.6863 - val_loss: 0.6866 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6106 - acc: 0.7255 - val_loss: 0.6861 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 0.6053 - acc: 0.7255 - val_loss: 0.6859 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.5996 - acc: 0.7255 - val_loss: 0.6851 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5937 - acc: 0.7451 - val_loss: 0.6843 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5882 - acc: 0.7451 - val_loss: 0.6836 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5824 - acc: 0.7451 - val_loss: 0.6829 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5783 - acc: 0.7451 - val_loss: 0.6818 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5724 - acc: 0.7843 - val_loss: 0.6810 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5676 - acc: 0.7843 - val_loss: 0.6803 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5629 - acc: 0.7647 - val_loss: 0.6795 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5579 - acc: 0.7647 - val_loss: 0.6789 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.5536 - acc: 0.8039 - val_loss: 0.6782 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5487 - acc: 0.7843 - val_loss: 0.6772 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5446 - acc: 0.7647 - val_loss: 0.6763 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5400 - acc: 0.7843 - val_loss: 0.6756 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5349 - acc: 0.8039 - val_loss: 0.6745 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5306 - acc: 0.8039 - val_loss: 0.6735 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5266 - acc: 0.8039 - val_loss: 0.6724 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5232 - acc: 0.8039 - val_loss: 0.6713 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5185 - acc: 0.8039 - val_loss: 0.6702 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5146 - acc: 0.8235 - val_loss: 0.6691 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5101 - acc: 0.8039 - val_loss: 0.6680 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5058 - acc: 0.8039 - val_loss: 0.6669 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5014 - acc: 0.8235 - val_loss: 0.6658 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4977 - acc: 0.8235 - val_loss: 0.6647 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4936 - acc: 0.8235 - val_loss: 0.6637 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.4907 - acc: 0.8235 - val_loss: 0.6627 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4859 - acc: 0.8235 - val_loss: 0.6618 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4825 - acc: 0.8235 - val_loss: 0.6607 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4793 - acc: 0.8235 - val_loss: 0.6598 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4756 - acc: 0.8235 - val_loss: 0.6586 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4723 - acc: 0.8235 - val_loss: 0.6576 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4685 - acc: 0.8235 - val_loss: 0.6565 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4649 - acc: 0.8235 - val_loss: 0.6557 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4621 - acc: 0.8235 - val_loss: 0.6546 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4584 - acc: 0.8235 - val_loss: 0.6528 - val_acc: 0.6000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4546 - acc: 0.8235 - val_loss: 0.6512 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4515 - acc: 0.8235 - val_loss: 0.6495 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4475 - acc: 0.8431 - val_loss: 0.6483 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4446 - acc: 0.8431 - val_loss: 0.6471 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4421 - acc: 0.8431 - val_loss: 0.6458 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.4387 - acc: 0.8431 - val_loss: 0.6442 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5097 - acc: 0.781 - 0s 314us/step - loss: 0.4358 - acc: 0.8431 - val_loss: 0.6428 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4321 - acc: 0.8431 - val_loss: 0.6412 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4291 - acc: 0.8431 - val_loss: 0.6401 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4261 - acc: 0.8431 - val_loss: 0.6390 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4232 - acc: 0.8431 - val_loss: 0.6376 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4197 - acc: 0.8431 - val_loss: 0.6361 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4178 - acc: 0.8431 - val_loss: 0.6350 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4145 - acc: 0.8431 - val_loss: 0.6336 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4114 - acc: 0.8431 - val_loss: 0.6324 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4089 - acc: 0.8627 - val_loss: 0.6316 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4414 - acc: 0.843 - 0s 235us/step - loss: 0.4056 - acc: 0.8627 - val_loss: 0.6304 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4037 - acc: 0.8627 - val_loss: 0.6288 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4013 - acc: 0.8627 - val_loss: 0.6279 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3985 - acc: 0.8627 - val_loss: 0.6263 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.3962 - acc: 0.8627 - val_loss: 0.6253 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3942 - acc: 0.8627 - val_loss: 0.6241 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3914 - acc: 0.8627 - val_loss: 0.6234 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3893 - acc: 0.8627 - val_loss: 0.6228 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3875 - acc: 0.8627 - val_loss: 0.6211 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3851 - acc: 0.8627 - val_loss: 0.6189 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3824 - acc: 0.8627 - val_loss: 0.6177 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3806 - acc: 0.8627 - val_loss: 0.6175 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3783 - acc: 0.8627 - val_loss: 0.6158 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3761 - acc: 0.8627 - val_loss: 0.6151 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3750 - acc: 0.8627 - val_loss: 0.6144 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3732 - acc: 0.8627 - val_loss: 0.6140 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3706 - acc: 0.8627 - val_loss: 0.6124 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3684 - acc: 0.8627 - val_loss: 0.6112 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3669 - acc: 0.8627 - val_loss: 0.6093 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3473 - acc: 0.875 - 0s 176us/step - loss: 0.3650 - acc: 0.8627 - val_loss: 0.6075 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3641 - acc: 0.8627 - val_loss: 0.6069 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3616 - acc: 0.8627 - val_loss: 0.6058 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3597 - acc: 0.8627 - val_loss: 0.6053 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3588 - acc: 0.8627 - val_loss: 0.6036 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3578 - acc: 0.8627 - val_loss: 0.6034 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3553 - acc: 0.8627 - val_loss: 0.6013 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3539 - acc: 0.8627 - val_loss: 0.5991 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3532 - acc: 0.8627 - val_loss: 0.5992 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3509 - acc: 0.8627 - val_loss: 0.5984 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3496 - acc: 0.8627 - val_loss: 0.5967 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3478 - acc: 0.8627 - val_loss: 0.5959 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3460 - acc: 0.8627 - val_loss: 0.5939 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3450 - acc: 0.8627 - val_loss: 0.5934 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3430 - acc: 0.8627 - val_loss: 0.5918 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3418 - acc: 0.8627 - val_loss: 0.5905 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3397 - acc: 0.8824 - val_loss: 0.5883 - val_acc: 0.7000\n",
      "2016-04-11\n",
      "2016-04-12\n",
      "2016-04-13\n",
      "2016-04-14\n",
      "2016-04-15\n",
      "2016-04-18\n",
      "2016-04-19\n",
      "2016-04-20\n",
      "2016-04-21\n",
      "2016-04-22\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3271 - acc: 0.9216 - val_loss: 0.7906 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3192 - acc: 0.9216 - val_loss: 0.7892 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 161us/step - loss: 0.3147 - acc: 0.9216 - val_loss: 0.7852 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3107 - acc: 0.9216 - val_loss: 0.7884 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3066 - acc: 0.9216 - val_loss: 0.7888 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3034 - acc: 0.9216 - val_loss: 0.7859 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3029 - acc: 0.9216 - val_loss: 0.7814 - val_acc: 0.6000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2983 - acc: 0.9216 - val_loss: 0.7813 - val_acc: 0.6000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2965 - acc: 0.9216 - val_loss: 0.7849 - val_acc: 0.6000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 296us/step - loss: 0.2938 - acc: 0.9216 - val_loss: 0.7850 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2921 - acc: 0.9216 - val_loss: 0.7805 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.2891 - acc: 0.9216 - val_loss: 0.7821 - val_acc: 0.6000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2872 - acc: 0.9216 - val_loss: 0.7815 - val_acc: 0.6000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2849 - acc: 0.9216 - val_loss: 0.7824 - val_acc: 0.6000\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 196us/step - loss: 0.2833 - acc: 0.9216 - val_loss: 0.7838 - val_acc: 0.6000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1802 - acc: 0.968 - 0s 196us/step - loss: 0.2813 - acc: 0.9216 - val_loss: 0.7839 - val_acc: 0.6000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2794 - acc: 0.9216 - val_loss: 0.7846 - val_acc: 0.6000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2781 - acc: 0.9216 - val_loss: 0.7812 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2759 - acc: 0.9216 - val_loss: 0.7808 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 0.2745 - acc: 0.9216 - val_loss: 0.7857 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 0.2721 - acc: 0.9216 - val_loss: 0.7866 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.2701 - acc: 0.9216 - val_loss: 0.7871 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2683 - acc: 0.9216 - val_loss: 0.7889 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 0.2666 - acc: 0.9412 - val_loss: 0.7868 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 222us/step - loss: 0.2647 - acc: 0.9216 - val_loss: 0.7874 - val_acc: 0.6000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3388 - acc: 0.875 - 0s 157us/step - loss: 0.2629 - acc: 0.9216 - val_loss: 0.7902 - val_acc: 0.6000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.2617 - acc: 0.9216 - val_loss: 0.7906 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2601 - acc: 0.9216 - val_loss: 0.7881 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2583 - acc: 0.9216 - val_loss: 0.7910 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2568 - acc: 0.9216 - val_loss: 0.7939 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2557 - acc: 0.9216 - val_loss: 0.7904 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2535 - acc: 0.9216 - val_loss: 0.7888 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2522 - acc: 0.9216 - val_loss: 0.7929 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2505 - acc: 0.9216 - val_loss: 0.7954 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2489 - acc: 0.9216 - val_loss: 0.7975 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.2478 - acc: 0.9216 - val_loss: 0.7945 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2465 - acc: 0.9216 - val_loss: 0.7916 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2447 - acc: 0.9216 - val_loss: 0.7934 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2425 - acc: 0.9216 - val_loss: 0.7964 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2376 - acc: 0.937 - 0s 176us/step - loss: 0.2406 - acc: 0.9216 - val_loss: 0.7961 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2397 - acc: 0.9216 - val_loss: 0.8009 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2374 - acc: 0.9412 - val_loss: 0.8028 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2360 - acc: 0.9216 - val_loss: 0.8037 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2348 - acc: 0.9412 - val_loss: 0.7992 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2327 - acc: 0.9412 - val_loss: 0.7978 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2315 - acc: 0.9216 - val_loss: 0.8028 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2300 - acc: 0.9216 - val_loss: 0.8058 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2285 - acc: 0.9412 - val_loss: 0.8036 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2273 - acc: 0.9412 - val_loss: 0.8037 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2252 - acc: 0.9412 - val_loss: 0.8041 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2240 - acc: 0.9412 - val_loss: 0.8050 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2226 - acc: 0.9216 - val_loss: 0.8094 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2227 - acc: 0.9608 - val_loss: 0.8063 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2200 - acc: 0.9608 - val_loss: 0.8048 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2189 - acc: 0.9412 - val_loss: 0.8072 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2173 - acc: 0.9608 - val_loss: 0.8082 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2165 - acc: 0.9608 - val_loss: 0.8137 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 193us/step - loss: 0.2162 - acc: 0.9608 - val_loss: 0.8111 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2143 - acc: 0.9412 - val_loss: 0.8104 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2135 - acc: 0.9412 - val_loss: 0.8172 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2128 - acc: 0.9412 - val_loss: 0.8216 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2110 - acc: 0.9608 - val_loss: 0.8253 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2099 - acc: 0.9608 - val_loss: 0.8257 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2101 - acc: 0.9608 - val_loss: 0.8233 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2080 - acc: 0.9412 - val_loss: 0.8293 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.2072 - acc: 0.9608 - val_loss: 0.8360 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2059 - acc: 0.9608 - val_loss: 0.8403 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2052 - acc: 0.9608 - val_loss: 0.8391 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2039 - acc: 0.9412 - val_loss: 0.8436 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2030 - acc: 0.9608 - val_loss: 0.8437 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.2025 - acc: 0.9412 - val_loss: 0.8479 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2014 - acc: 0.9608 - val_loss: 0.8517 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 141us/step - loss: 0.1999 - acc: 0.9608 - val_loss: 0.8519 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1989 - acc: 0.9608 - val_loss: 0.8581 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1976 - acc: 0.9608 - val_loss: 0.8594 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1971 - acc: 0.9608 - val_loss: 0.8659 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1953 - acc: 0.9608 - val_loss: 0.8633 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1945 - acc: 0.9608 - val_loss: 0.8611 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1937 - acc: 0.9608 - val_loss: 0.8602 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.1925 - acc: 0.9608 - val_loss: 0.8676 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1915 - acc: 0.9608 - val_loss: 0.8705 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1900 - acc: 0.9608 - val_loss: 0.8752 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1410 - acc: 0.968 - 0s 157us/step - loss: 0.1891 - acc: 0.9608 - val_loss: 0.8808 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1889 - acc: 0.9608 - val_loss: 0.8852 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1871 - acc: 0.9608 - val_loss: 0.8906 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1864 - acc: 0.9608 - val_loss: 0.8886 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1855 - acc: 0.9608 - val_loss: 0.8909 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1846 - acc: 0.9608 - val_loss: 0.8974 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1838 - acc: 0.9608 - val_loss: 0.9013 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1826 - acc: 0.9608 - val_loss: 0.9016 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1820 - acc: 0.9608 - val_loss: 0.9095 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1808 - acc: 0.9608 - val_loss: 0.9108 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1799 - acc: 0.9608 - val_loss: 0.9156 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1799 - acc: 0.9608 - val_loss: 0.9228 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1783 - acc: 0.9608 - val_loss: 0.9289 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1773 - acc: 0.9608 - val_loss: 0.9303 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1772 - acc: 0.9608 - val_loss: 0.9298 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1755 - acc: 0.9608 - val_loss: 0.9336 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1749 - acc: 0.9608 - val_loss: 0.9326 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1741 - acc: 0.9608 - val_loss: 0.9327 - val_acc: 0.7000\n",
      "2016-04-25\n",
      "2016-04-26\n",
      "2016-04-27\n",
      "2016-04-28\n",
      "2016-04-29\n",
      "2016-05-03\n",
      "2016-05-04\n",
      "2016-05-05\n",
      "2016-05-06\n",
      "2016-05-09\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 1.3676 - acc: 0.5686 - val_loss: 4.4962 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.2818 - acc: 0.5686 - val_loss: 4.4651 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.2274 - acc: 0.5686 - val_loss: 4.4453 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1847 - acc: 0.5686 - val_loss: 4.4273 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1473 - acc: 0.5882 - val_loss: 4.4355 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1159 - acc: 0.5882 - val_loss: 4.4239 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 1.0869 - acc: 0.5882 - val_loss: 4.4126 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.0603 - acc: 0.5882 - val_loss: 4.4053 - val_acc: 0.2000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0363 - acc: 0.6275 - val_loss: 4.3909 - val_acc: 0.2000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0148 - acc: 0.6275 - val_loss: 4.3682 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9917 - acc: 0.6275 - val_loss: 4.3501 - val_acc: 0.2000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9692 - acc: 0.6275 - val_loss: 4.3505 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9504 - acc: 0.6275 - val_loss: 4.3378 - val_acc: 0.2000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9327 - acc: 0.6275 - val_loss: 4.3331 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.9132 - acc: 0.6275 - val_loss: 4.3211 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8974 - acc: 0.6275 - val_loss: 4.3115 - val_acc: 0.2000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.8824 - acc: 0.6275 - val_loss: 4.2939 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.8685 - acc: 0.6471 - val_loss: 4.2667 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8525 - acc: 0.6471 - val_loss: 4.2462 - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8390 - acc: 0.6667 - val_loss: 4.2306 - val_acc: 0.1000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8276 - acc: 0.6667 - val_loss: 4.1967 - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8158 - acc: 0.6667 - val_loss: 4.1821 - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.8061 - acc: 0.7059 - val_loss: 4.1787 - val_acc: 0.1000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7942 - acc: 0.7059 - val_loss: 4.1596 - val_acc: 0.1000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7832 - acc: 0.7059 - val_loss: 4.1330 - val_acc: 0.1000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7741 - acc: 0.7059 - val_loss: 4.1217 - val_acc: 0.1000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7640 - acc: 0.7059 - val_loss: 4.0956 - val_acc: 0.1000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.7553 - acc: 0.7059 - val_loss: 4.0634 - val_acc: 0.1000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7475 - acc: 0.7255 - val_loss: 4.0456 - val_acc: 0.1000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7798 - acc: 0.750 - 0s 196us/step - loss: 0.7392 - acc: 0.7255 - val_loss: 4.0207 - val_acc: 0.1000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7314 - acc: 0.7255 - val_loss: 3.9797 - val_acc: 0.1000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7228 - acc: 0.7255 - val_loss: 3.9543 - val_acc: 0.1000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7164 - acc: 0.7255 - val_loss: 3.9247 - val_acc: 0.1000\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 137us/step - loss: 0.7091 - acc: 0.7255 - val_loss: 3.8913 - val_acc: 0.1000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.7028 - acc: 0.7255 - val_loss: 3.8437 - val_acc: 0.1000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6943 - acc: 0.7255 - val_loss: 3.8223 - val_acc: 0.1000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6873 - acc: 0.7255 - val_loss: 3.7909 - val_acc: 0.1000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.6804 - acc: 0.7451 - val_loss: 3.7525 - val_acc: 0.1000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6734 - acc: 0.7647 - val_loss: 3.7165 - val_acc: 0.1000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6671 - acc: 0.7647 - val_loss: 3.6863 - val_acc: 0.1000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.6603 - acc: 0.7647 - val_loss: 3.6435 - val_acc: 0.1000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7342 - acc: 0.781 - 0s 327us/step - loss: 0.6547 - acc: 0.7647 - val_loss: 3.6227 - val_acc: 0.1000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6487 - acc: 0.7647 - val_loss: 3.5766 - val_acc: 0.1000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6418 - acc: 0.7647 - val_loss: 3.5561 - val_acc: 0.1000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6351 - acc: 0.7843 - val_loss: 3.5152 - val_acc: 0.1000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6283 - acc: 0.7843 - val_loss: 3.4800 - val_acc: 0.1000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.6229 - acc: 0.7843 - val_loss: 3.4494 - val_acc: 0.1000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 276us/step - loss: 0.6185 - acc: 0.7843 - val_loss: 3.4079 - val_acc: 0.1000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6120 - acc: 0.7843 - val_loss: 3.3784 - val_acc: 0.1000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6062 - acc: 0.7843 - val_loss: 3.3432 - val_acc: 0.1000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6010 - acc: 0.7843 - val_loss: 3.3075 - val_acc: 0.1000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5946 - acc: 0.7843 - val_loss: 3.2877 - val_acc: 0.1000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5902 - acc: 0.7843 - val_loss: 3.2639 - val_acc: 0.1000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5850 - acc: 0.7843 - val_loss: 3.2343 - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5800 - acc: 0.7843 - val_loss: 3.1944 - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 180us/step - loss: 0.5752 - acc: 0.7843 - val_loss: 3.1667 - val_acc: 0.1000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6607 - acc: 0.812 - 0s 255us/step - loss: 0.5699 - acc: 0.7843 - val_loss: 3.1455 - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5653 - acc: 0.7843 - val_loss: 3.1200 - val_acc: 0.1000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5604 - acc: 0.7843 - val_loss: 3.0837 - val_acc: 0.1000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5563 - acc: 0.7843 - val_loss: 3.0552 - val_acc: 0.1000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5514 - acc: 0.7843 - val_loss: 3.0392 - val_acc: 0.1000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5462 - acc: 0.7843 - val_loss: 3.0008 - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5412 - acc: 0.7843 - val_loss: 2.9681 - val_acc: 0.1000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5366 - acc: 0.7843 - val_loss: 2.9366 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5331 - acc: 0.7843 - val_loss: 2.8952 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5282 - acc: 0.8235 - val_loss: 2.8698 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5236 - acc: 0.8235 - val_loss: 2.8539 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.5194 - acc: 0.8235 - val_loss: 2.8295 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5154 - acc: 0.8431 - val_loss: 2.8043 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5113 - acc: 0.8431 - val_loss: 2.7838 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5082 - acc: 0.8431 - val_loss: 2.7583 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5051 - acc: 0.8627 - val_loss: 2.7349 - val_acc: 0.4000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5010 - acc: 0.8627 - val_loss: 2.7116 - val_acc: 0.4000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4982 - acc: 0.8627 - val_loss: 2.6825 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4937 - acc: 0.8627 - val_loss: 2.6519 - val_acc: 0.4000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4902 - acc: 0.8627 - val_loss: 2.6369 - val_acc: 0.4000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4877 - acc: 0.8627 - val_loss: 2.6233 - val_acc: 0.4000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4840 - acc: 0.8627 - val_loss: 2.5902 - val_acc: 0.4000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4809 - acc: 0.8627 - val_loss: 2.5807 - val_acc: 0.4000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4772 - acc: 0.8627 - val_loss: 2.5628 - val_acc: 0.4000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4738 - acc: 0.8627 - val_loss: 2.5366 - val_acc: 0.4000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4719 - acc: 0.8627 - val_loss: 2.5098 - val_acc: 0.4000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4676 - acc: 0.8627 - val_loss: 2.4946 - val_acc: 0.4000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4646 - acc: 0.8627 - val_loss: 2.4657 - val_acc: 0.4000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4612 - acc: 0.8627 - val_loss: 2.4391 - val_acc: 0.4000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 184us/step - loss: 0.4582 - acc: 0.8627 - val_loss: 2.4201 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4557 - acc: 0.8627 - val_loss: 2.3901 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4526 - acc: 0.8627 - val_loss: 2.3677 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.4497 - acc: 0.8627 - val_loss: 2.3334 - val_acc: 0.4000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.4454 - acc: 0.8627 - val_loss: 2.3143 - val_acc: 0.4000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4432 - acc: 0.8627 - val_loss: 2.3010 - val_acc: 0.4000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4402 - acc: 0.8627 - val_loss: 2.2761 - val_acc: 0.4000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4383 - acc: 0.8627 - val_loss: 2.2658 - val_acc: 0.4000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4354 - acc: 0.8627 - val_loss: 2.2459 - val_acc: 0.4000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4334 - acc: 0.8627 - val_loss: 2.2370 - val_acc: 0.4000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4302 - acc: 0.8627 - val_loss: 2.2218 - val_acc: 0.4000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4287 - acc: 0.8627 - val_loss: 2.2147 - val_acc: 0.4000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4269 - acc: 0.8627 - val_loss: 2.1811 - val_acc: 0.4000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4227 - acc: 0.8627 - val_loss: 2.1647 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4200 - acc: 0.8627 - val_loss: 2.1415 - val_acc: 0.4000\n",
      "2016-05-10\n",
      "2016-05-11\n",
      "2016-05-12\n",
      "2016-05-13\n",
      "2016-05-16\n",
      "2016-05-17\n",
      "2016-05-18\n",
      "2016-05-19\n",
      "2016-05-20\n",
      "2016-05-23\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.8905 - acc: 0.6667 - val_loss: 0.2970 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 303us/step - loss: 0.8627 - acc: 0.6863 - val_loss: 0.2998 - val_acc: 0.9000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8411 - acc: 0.6863 - val_loss: 0.3018 - val_acc: 0.9000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.8278 - acc: 0.7059 - val_loss: 0.3042 - val_acc: 0.9000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8145 - acc: 0.7059 - val_loss: 0.3054 - val_acc: 0.9000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8031 - acc: 0.7059 - val_loss: 0.3069 - val_acc: 0.9000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7924 - acc: 0.7059 - val_loss: 0.3080 - val_acc: 0.9000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7823 - acc: 0.7255 - val_loss: 0.3097 - val_acc: 0.9000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.7726 - acc: 0.7255 - val_loss: 0.3116 - val_acc: 0.9000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.7629 - acc: 0.7255 - val_loss: 0.3124 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7544 - acc: 0.7255 - val_loss: 0.3141 - val_acc: 0.9000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7474 - acc: 0.7255 - val_loss: 0.3157 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7384 - acc: 0.7255 - val_loss: 0.3174 - val_acc: 0.9000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7305 - acc: 0.7255 - val_loss: 0.3183 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7231 - acc: 0.7451 - val_loss: 0.3199 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7162 - acc: 0.7451 - val_loss: 0.3208 - val_acc: 0.9000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 100us/step - loss: 0.7094 - acc: 0.7451 - val_loss: 0.3222 - val_acc: 0.9000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.7023 - acc: 0.7647 - val_loss: 0.3233 - val_acc: 0.9000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.6973 - acc: 0.7451 - val_loss: 0.3243 - val_acc: 0.9000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 367us/step - loss: 0.6886 - acc: 0.7647 - val_loss: 0.3252 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.6837 - acc: 0.7451 - val_loss: 0.3261 - val_acc: 0.9000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7060 - acc: 0.781 - 0s 0us/step - loss: 0.6782 - acc: 0.7451 - val_loss: 0.3272 - val_acc: 0.9000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6729 - acc: 0.7451 - val_loss: 0.3277 - val_acc: 0.9000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6088 - acc: 0.781 - 0s 0us/step - loss: 0.6678 - acc: 0.7451 - val_loss: 0.3295 - val_acc: 0.9000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.6613 - acc: 0.7451 - val_loss: 0.3305 - val_acc: 0.9000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6566 - acc: 0.7451 - val_loss: 0.3307 - val_acc: 0.9000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6518 - acc: 0.7451 - val_loss: 0.3315 - val_acc: 0.9000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5723 - acc: 0.750 - 0s 216us/step - loss: 0.6458 - acc: 0.7451 - val_loss: 0.3327 - val_acc: 0.9000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6395 - acc: 0.7451 - val_loss: 0.3339 - val_acc: 0.9000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6351 - acc: 0.7451 - val_loss: 0.3357 - val_acc: 0.9000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6292 - acc: 0.7451 - val_loss: 0.3366 - val_acc: 0.9000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.6246 - acc: 0.7451 - val_loss: 0.3374 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.6199 - acc: 0.7451 - val_loss: 0.3387 - val_acc: 0.9000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.6155 - acc: 0.7451 - val_loss: 0.3404 - val_acc: 0.9000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6095 - acc: 0.7451 - val_loss: 0.3417 - val_acc: 0.9000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6063 - acc: 0.7451 - val_loss: 0.3415 - val_acc: 0.9000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6011 - acc: 0.7451 - val_loss: 0.3422 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5967 - acc: 0.7451 - val_loss: 0.3421 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5931 - acc: 0.7451 - val_loss: 0.3424 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 117us/step - loss: 0.5883 - acc: 0.7451 - val_loss: 0.3432 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 133us/step - loss: 0.5832 - acc: 0.7451 - val_loss: 0.3447 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.5787 - acc: 0.7451 - val_loss: 0.3457 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5749 - acc: 0.7451 - val_loss: 0.3468 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 117us/step - loss: 0.5704 - acc: 0.7647 - val_loss: 0.3483 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5656 - acc: 0.7647 - val_loss: 0.3492 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5616 - acc: 0.7647 - val_loss: 0.3500 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5576 - acc: 0.7647 - val_loss: 0.3510 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.5539 - acc: 0.7843 - val_loss: 0.3520 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5491 - acc: 0.7843 - val_loss: 0.3524 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.5460 - acc: 0.7843 - val_loss: 0.3531 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.5418 - acc: 0.7843 - val_loss: 0.3542 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5382 - acc: 0.7843 - val_loss: 0.3551 - val_acc: 0.7000\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 176us/step - loss: 0.5356 - acc: 0.7843 - val_loss: 0.3561 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5321 - acc: 0.7843 - val_loss: 0.3570 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5279 - acc: 0.7843 - val_loss: 0.3574 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5251 - acc: 0.7843 - val_loss: 0.3583 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.5217 - acc: 0.7843 - val_loss: 0.3583 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5195 - acc: 0.7843 - val_loss: 0.3585 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5152 - acc: 0.7843 - val_loss: 0.3589 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5118 - acc: 0.7843 - val_loss: 0.3585 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.5090 - acc: 0.7843 - val_loss: 0.3587 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5060 - acc: 0.7843 - val_loss: 0.3587 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5024 - acc: 0.7843 - val_loss: 0.3600 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.4996 - acc: 0.7843 - val_loss: 0.3603 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4964 - acc: 0.7843 - val_loss: 0.3609 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4933 - acc: 0.7843 - val_loss: 0.3620 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4909 - acc: 0.7843 - val_loss: 0.3617 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4878 - acc: 0.7843 - val_loss: 0.3629 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4848 - acc: 0.7843 - val_loss: 0.3635 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4825 - acc: 0.7843 - val_loss: 0.3637 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.4785 - acc: 0.7843 - val_loss: 0.3644 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4759 - acc: 0.7843 - val_loss: 0.3643 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4745 - acc: 0.7843 - val_loss: 0.3649 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 0.4703 - acc: 0.7843 - val_loss: 0.3653 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4680 - acc: 0.7843 - val_loss: 0.3667 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4656 - acc: 0.8039 - val_loss: 0.3673 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4625 - acc: 0.8039 - val_loss: 0.3682 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4594 - acc: 0.8039 - val_loss: 0.3686 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 178us/step - loss: 0.4582 - acc: 0.8039 - val_loss: 0.3681 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4548 - acc: 0.8039 - val_loss: 0.3693 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4525 - acc: 0.8039 - val_loss: 0.3705 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4494 - acc: 0.8039 - val_loss: 0.3715 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4471 - acc: 0.8039 - val_loss: 0.3726 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.4444 - acc: 0.8039 - val_loss: 0.3735 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4425 - acc: 0.8039 - val_loss: 0.3750 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4400 - acc: 0.8039 - val_loss: 0.3768 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4377 - acc: 0.8039 - val_loss: 0.3780 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4350 - acc: 0.8039 - val_loss: 0.3778 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4332 - acc: 0.8039 - val_loss: 0.3796 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4302 - acc: 0.8039 - val_loss: 0.3806 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4276 - acc: 0.8039 - val_loss: 0.3820 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4259 - acc: 0.8039 - val_loss: 0.3831 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4234 - acc: 0.8039 - val_loss: 0.3838 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4211 - acc: 0.8235 - val_loss: 0.3845 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4184 - acc: 0.8235 - val_loss: 0.3857 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4167 - acc: 0.8235 - val_loss: 0.3858 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4149 - acc: 0.8431 - val_loss: 0.3871 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4134 - acc: 0.8431 - val_loss: 0.3870 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.4113 - acc: 0.8627 - val_loss: 0.3884 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4087 - acc: 0.8627 - val_loss: 0.3904 - val_acc: 0.7000\n",
      "2016-05-24\n",
      "2016-05-25\n",
      "2016-05-26\n",
      "2016-05-27\n",
      "2016-05-30\n",
      "2016-05-31\n",
      "2016-06-01\n",
      "2016-06-02\n",
      "2016-06-03\n",
      "2016-06-06\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.9879 - acc: 0.5098 - val_loss: 0.4318 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 191us/step - loss: 0.9470 - acc: 0.5294 - val_loss: 0.4342 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.9251 - acc: 0.5294 - val_loss: 0.4357 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.9061 - acc: 0.5294 - val_loss: 0.4369 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8892 - acc: 0.5294 - val_loss: 0.4382 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8738 - acc: 0.5294 - val_loss: 0.4401 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 232us/step - loss: 0.8602 - acc: 0.5294 - val_loss: 0.4418 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8469 - acc: 0.5294 - val_loss: 0.4430 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8343 - acc: 0.5294 - val_loss: 0.4444 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8232 - acc: 0.5490 - val_loss: 0.4460 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8115 - acc: 0.5490 - val_loss: 0.4477 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8015 - acc: 0.5490 - val_loss: 0.4495 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7926 - acc: 0.5490 - val_loss: 0.4513 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7819 - acc: 0.5490 - val_loss: 0.4528 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7912 - acc: 0.562 - 0s 177us/step - loss: 0.7716 - acc: 0.5490 - val_loss: 0.4544 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7629 - acc: 0.5490 - val_loss: 0.4559 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7548 - acc: 0.5294 - val_loss: 0.4578 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7462 - acc: 0.5294 - val_loss: 0.4598 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7377 - acc: 0.5294 - val_loss: 0.4620 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7298 - acc: 0.5294 - val_loss: 0.4636 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7222 - acc: 0.5294 - val_loss: 0.4656 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7141 - acc: 0.5294 - val_loss: 0.4680 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7072 - acc: 0.5490 - val_loss: 0.4699 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7003 - acc: 0.5686 - val_loss: 0.4722 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6930 - acc: 0.5490 - val_loss: 0.4741 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.6864 - acc: 0.5490 - val_loss: 0.4762 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 324us/step - loss: 0.6792 - acc: 0.5686 - val_loss: 0.4781 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6726 - acc: 0.5882 - val_loss: 0.4805 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.6659 - acc: 0.5882 - val_loss: 0.4829 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6599 - acc: 0.6078 - val_loss: 0.4853 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6547 - acc: 0.6275 - val_loss: 0.4873 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6479 - acc: 0.6275 - val_loss: 0.4897 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6425 - acc: 0.6275 - val_loss: 0.4922 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6370 - acc: 0.6275 - val_loss: 0.4943 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6323 - acc: 0.6275 - val_loss: 0.4965 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6272 - acc: 0.6275 - val_loss: 0.4989 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6220 - acc: 0.6471 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.6175 - acc: 0.6471 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6136 - acc: 0.6471 - val_loss: 0.5061 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.6081 - acc: 0.6471 - val_loss: 0.5083 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6037 - acc: 0.6471 - val_loss: 0.5108 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5992 - acc: 0.6667 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5956 - acc: 0.6667 - val_loss: 0.5151 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5908 - acc: 0.6667 - val_loss: 0.5167 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 190us/step - loss: 0.5869 - acc: 0.6863 - val_loss: 0.5189 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5829 - acc: 0.6863 - val_loss: 0.5208 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5790 - acc: 0.6863 - val_loss: 0.5232 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5750 - acc: 0.7059 - val_loss: 0.5249 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5713 - acc: 0.7059 - val_loss: 0.5264 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5680 - acc: 0.7059 - val_loss: 0.5278 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5646 - acc: 0.7059 - val_loss: 0.5302 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.5609 - acc: 0.7451 - val_loss: 0.5325 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5572 - acc: 0.7255 - val_loss: 0.5346 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5541 - acc: 0.7255 - val_loss: 0.5359 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5505 - acc: 0.7255 - val_loss: 0.5371 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5474 - acc: 0.7255 - val_loss: 0.5392 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5438 - acc: 0.7451 - val_loss: 0.5419 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5414 - acc: 0.7451 - val_loss: 0.5424 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5374 - acc: 0.7451 - val_loss: 0.5437 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5345 - acc: 0.7451 - val_loss: 0.5448 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5312 - acc: 0.7451 - val_loss: 0.5481 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5281 - acc: 0.7451 - val_loss: 0.5505 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.5255 - acc: 0.7451 - val_loss: 0.5541 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5222 - acc: 0.7451 - val_loss: 0.5545 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5198 - acc: 0.7451 - val_loss: 0.5556 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5164 - acc: 0.7451 - val_loss: 0.5570 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5132 - acc: 0.7647 - val_loss: 0.5590 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5109 - acc: 0.7647 - val_loss: 0.5601 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5151 - acc: 0.750 - 0s 274us/step - loss: 0.5076 - acc: 0.7647 - val_loss: 0.5623 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5046 - acc: 0.7647 - val_loss: 0.5641 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5021 - acc: 0.7843 - val_loss: 0.5668 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4988 - acc: 0.7647 - val_loss: 0.5696 - val_acc: 0.8000\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 157us/step - loss: 0.4959 - acc: 0.7647 - val_loss: 0.5723 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4930 - acc: 0.7843 - val_loss: 0.5750 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.4903 - acc: 0.7843 - val_loss: 0.5762 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4877 - acc: 0.7843 - val_loss: 0.5788 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4849 - acc: 0.7843 - val_loss: 0.5814 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4826 - acc: 0.7843 - val_loss: 0.5832 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.4804 - acc: 0.7843 - val_loss: 0.5830 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4769 - acc: 0.8039 - val_loss: 0.5855 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4745 - acc: 0.8039 - val_loss: 0.5861 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4721 - acc: 0.8039 - val_loss: 0.5875 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4703 - acc: 0.8039 - val_loss: 0.5878 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4676 - acc: 0.8039 - val_loss: 0.5889 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4649 - acc: 0.8039 - val_loss: 0.5898 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4623 - acc: 0.8039 - val_loss: 0.5919 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4605 - acc: 0.8039 - val_loss: 0.5908 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.4580 - acc: 0.8039 - val_loss: 0.5934 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4555 - acc: 0.8039 - val_loss: 0.5935 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4535 - acc: 0.8039 - val_loss: 0.5951 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 278us/step - loss: 0.4527 - acc: 0.8039 - val_loss: 0.5977 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4490 - acc: 0.8039 - val_loss: 0.5992 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.4470 - acc: 0.8039 - val_loss: 0.6001 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4452 - acc: 0.8039 - val_loss: 0.6020 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4437 - acc: 0.8039 - val_loss: 0.6037 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4417 - acc: 0.8039 - val_loss: 0.6042 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4393 - acc: 0.8039 - val_loss: 0.6038 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4375 - acc: 0.8039 - val_loss: 0.6041 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4359 - acc: 0.8039 - val_loss: 0.6031 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4334 - acc: 0.8039 - val_loss: 0.6042 - val_acc: 0.7000\n",
      "2016-06-07\n",
      "2016-06-08\n",
      "2016-06-13\n",
      "2016-06-14\n",
      "2016-06-15\n",
      "2016-06-16\n",
      "2016-06-17\n",
      "2016-06-20\n",
      "2016-06-21\n",
      "2016-06-22\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.5675 - acc: 0.7451 - val_loss: 0.5336 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.5570 - acc: 0.7647 - val_loss: 0.5326 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5504 - acc: 0.7647 - val_loss: 0.5309 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5458 - acc: 0.7647 - val_loss: 0.5294 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5410 - acc: 0.7647 - val_loss: 0.5279 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.5361 - acc: 0.7647 - val_loss: 0.5274 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5324 - acc: 0.7647 - val_loss: 0.5268 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5284 - acc: 0.7647 - val_loss: 0.5254 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.5241 - acc: 0.7647 - val_loss: 0.5242 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5211 - acc: 0.7647 - val_loss: 0.5241 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.5179 - acc: 0.7647 - val_loss: 0.5232 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5143 - acc: 0.7647 - val_loss: 0.5229 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5124 - acc: 0.7647 - val_loss: 0.5221 - val_acc: 0.9000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5091 - acc: 0.7647 - val_loss: 0.5213 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 185us/step - loss: 0.5055 - acc: 0.7647 - val_loss: 0.5213 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.5031 - acc: 0.7647 - val_loss: 0.5203 - val_acc: 0.9000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4997 - acc: 0.7647 - val_loss: 0.5202 - val_acc: 0.9000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4972 - acc: 0.7647 - val_loss: 0.5201 - val_acc: 0.9000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4953 - acc: 0.7647 - val_loss: 0.5208 - val_acc: 0.9000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4930 - acc: 0.7647 - val_loss: 0.5196 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4906 - acc: 0.7647 - val_loss: 0.5185 - val_acc: 0.9000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4876 - acc: 0.7647 - val_loss: 0.5180 - val_acc: 0.9000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4849 - acc: 0.7843 - val_loss: 0.5178 - val_acc: 0.9000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4820 - acc: 0.7843 - val_loss: 0.5175 - val_acc: 0.9000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4795 - acc: 0.7843 - val_loss: 0.5166 - val_acc: 0.9000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.4777 - acc: 0.7843 - val_loss: 0.5162 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4745 - acc: 0.7843 - val_loss: 0.5153 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4720 - acc: 0.7843 - val_loss: 0.5150 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4701 - acc: 0.7843 - val_loss: 0.5151 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4669 - acc: 0.7843 - val_loss: 0.5145 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4641 - acc: 0.7843 - val_loss: 0.5135 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4618 - acc: 0.7843 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4592 - acc: 0.7843 - val_loss: 0.5129 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4570 - acc: 0.7843 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4543 - acc: 0.8039 - val_loss: 0.5127 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 332us/step - loss: 0.4514 - acc: 0.8039 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4493 - acc: 0.8039 - val_loss: 0.5127 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4465 - acc: 0.8039 - val_loss: 0.5121 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4443 - acc: 0.8039 - val_loss: 0.5125 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4417 - acc: 0.8039 - val_loss: 0.5122 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4389 - acc: 0.8039 - val_loss: 0.5122 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4374 - acc: 0.8235 - val_loss: 0.5124 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4339 - acc: 0.8235 - val_loss: 0.5118 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4315 - acc: 0.8235 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4291 - acc: 0.8235 - val_loss: 0.5111 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.4274 - acc: 0.8235 - val_loss: 0.5109 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4247 - acc: 0.8235 - val_loss: 0.5097 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.4220 - acc: 0.8235 - val_loss: 0.5091 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4211 - acc: 0.8235 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4185 - acc: 0.8235 - val_loss: 0.5071 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4166 - acc: 0.8235 - val_loss: 0.5066 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.4137 - acc: 0.8235 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4122 - acc: 0.8235 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4104 - acc: 0.8235 - val_loss: 0.5058 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4079 - acc: 0.8235 - val_loss: 0.5054 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4060 - acc: 0.8235 - val_loss: 0.5044 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4042 - acc: 0.8235 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4024 - acc: 0.8235 - val_loss: 0.5024 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4001 - acc: 0.8235 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3984 - acc: 0.8235 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3968 - acc: 0.8235 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.3945 - acc: 0.8235 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3933 - acc: 0.8235 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3903 - acc: 0.8235 - val_loss: 0.4990 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3884 - acc: 0.8235 - val_loss: 0.4986 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3870 - acc: 0.8431 - val_loss: 0.4982 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3849 - acc: 0.8431 - val_loss: 0.4976 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3832 - acc: 0.8431 - val_loss: 0.4962 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3817 - acc: 0.8431 - val_loss: 0.4963 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3803 - acc: 0.8431 - val_loss: 0.4960 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3781 - acc: 0.8627 - val_loss: 0.4952 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3757 - acc: 0.8627 - val_loss: 0.4950 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3744 - acc: 0.8627 - val_loss: 0.4943 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3721 - acc: 0.8627 - val_loss: 0.4938 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3711 - acc: 0.8627 - val_loss: 0.4924 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3689 - acc: 0.8627 - val_loss: 0.4917 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3675 - acc: 0.8627 - val_loss: 0.4909 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3655 - acc: 0.8627 - val_loss: 0.4908 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3275 - acc: 0.906 - 0s 197us/step - loss: 0.3636 - acc: 0.8627 - val_loss: 0.4908 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3630 - acc: 0.8627 - val_loss: 0.4901 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3601 - acc: 0.8627 - val_loss: 0.4894 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3588 - acc: 0.8627 - val_loss: 0.4884 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3585 - acc: 0.8627 - val_loss: 0.4878 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3549 - acc: 0.8627 - val_loss: 0.4873 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3535 - acc: 0.8627 - val_loss: 0.4861 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3521 - acc: 0.8627 - val_loss: 0.4859 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3501 - acc: 0.8627 - val_loss: 0.4848 - val_acc: 0.9000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3482 - acc: 0.8627 - val_loss: 0.4840 - val_acc: 0.9000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3469 - acc: 0.8627 - val_loss: 0.4830 - val_acc: 0.9000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3455 - acc: 0.8627 - val_loss: 0.4821 - val_acc: 0.9000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3436 - acc: 0.8627 - val_loss: 0.4819 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3604 - acc: 0.812 - 0s 196us/step - loss: 0.3424 - acc: 0.8627 - val_loss: 0.4807 - val_acc: 0.9000\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 314us/step - loss: 0.3400 - acc: 0.8627 - val_loss: 0.4801 - val_acc: 0.9000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3390 - acc: 0.8627 - val_loss: 0.4797 - val_acc: 0.9000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3369 - acc: 0.8627 - val_loss: 0.4794 - val_acc: 0.9000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.3359 - acc: 0.8824 - val_loss: 0.4784 - val_acc: 0.9000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3349 - acc: 0.8824 - val_loss: 0.4780 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3319 - acc: 0.8824 - val_loss: 0.4775 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3303 - acc: 0.8824 - val_loss: 0.4765 - val_acc: 0.9000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3291 - acc: 0.8824 - val_loss: 0.4760 - val_acc: 0.9000\n",
      "2016-06-23\n",
      "2016-06-24\n",
      "2016-06-27\n",
      "2016-06-28\n",
      "2016-06-29\n",
      "2016-06-30\n",
      "2016-07-01\n",
      "2016-07-04\n",
      "2016-07-05\n",
      "2016-07-06\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.4032 - acc: 0.8431 - val_loss: 0.8584 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3923 - acc: 0.8431 - val_loss: 0.8557 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3864 - acc: 0.8627 - val_loss: 0.8556 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3815 - acc: 0.8627 - val_loss: 0.8572 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3769 - acc: 0.8627 - val_loss: 0.8603 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3739 - acc: 0.8627 - val_loss: 0.8612 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3704 - acc: 0.8627 - val_loss: 0.8611 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3687 - acc: 0.875 - 0s 206us/step - loss: 0.3662 - acc: 0.8627 - val_loss: 0.8635 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3631 - acc: 0.8627 - val_loss: 0.8685 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3600 - acc: 0.8627 - val_loss: 0.8708 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3575 - acc: 0.8627 - val_loss: 0.8703 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3533 - acc: 0.8627 - val_loss: 0.8754 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3502 - acc: 0.8627 - val_loss: 0.8781 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4526 - acc: 0.812 - 0s 373us/step - loss: 0.3477 - acc: 0.8627 - val_loss: 0.8823 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3452 - acc: 0.8627 - val_loss: 0.8883 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3420 - acc: 0.8627 - val_loss: 0.8917 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3395 - acc: 0.8627 - val_loss: 0.8954 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3366 - acc: 0.8627 - val_loss: 0.8987 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3335 - acc: 0.8627 - val_loss: 0.9019 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3309 - acc: 0.8627 - val_loss: 0.9050 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3286 - acc: 0.8627 - val_loss: 0.9094 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3259 - acc: 0.8627 - val_loss: 0.9097 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3242 - acc: 0.8627 - val_loss: 0.9150 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.3211 - acc: 0.8627 - val_loss: 0.9194 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3186 - acc: 0.8627 - val_loss: 0.9215 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3159 - acc: 0.8627 - val_loss: 0.9241 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3146 - acc: 0.8627 - val_loss: 0.9288 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3117 - acc: 0.8627 - val_loss: 0.9309 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3099 - acc: 0.8431 - val_loss: 0.9294 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3069 - acc: 0.8627 - val_loss: 0.9329 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3051 - acc: 0.8627 - val_loss: 0.9325 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3025 - acc: 0.8627 - val_loss: 0.9366 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3006 - acc: 0.8627 - val_loss: 0.9393 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2977 - acc: 0.8627 - val_loss: 0.9437 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2961 - acc: 0.8627 - val_loss: 0.9470 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2940 - acc: 0.8431 - val_loss: 0.9457 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2911 - acc: 0.8627 - val_loss: 0.9482 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2895 - acc: 0.8627 - val_loss: 0.9477 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2870 - acc: 0.8627 - val_loss: 0.9522 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.2850 - acc: 0.8627 - val_loss: 0.9542 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2828 - acc: 0.8627 - val_loss: 0.9561 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2810 - acc: 0.8627 - val_loss: 0.9594 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2788 - acc: 0.8627 - val_loss: 0.9654 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2769 - acc: 0.8627 - val_loss: 0.9667 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2745 - acc: 0.8824 - val_loss: 0.9722 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2728 - acc: 0.8824 - val_loss: 0.9739 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2704 - acc: 0.8824 - val_loss: 0.9801 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2684 - acc: 0.8824 - val_loss: 0.9844 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2667 - acc: 0.8824 - val_loss: 0.9901 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2646 - acc: 0.8824 - val_loss: 0.9936 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2627 - acc: 0.8824 - val_loss: 0.9939 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2604 - acc: 0.9020 - val_loss: 0.9975 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2583 - acc: 0.9020 - val_loss: 1.0007 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2561 - acc: 0.9020 - val_loss: 1.0062 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2550 - acc: 0.9020 - val_loss: 1.0115 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2527 - acc: 0.9020 - val_loss: 1.0159 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.2513 - acc: 0.9020 - val_loss: 1.0168 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2498 - acc: 0.9020 - val_loss: 1.0245 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2486 - acc: 0.9020 - val_loss: 1.0305 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2458 - acc: 0.9020 - val_loss: 1.0326 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2437 - acc: 0.9020 - val_loss: 1.0384 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2423 - acc: 0.8824 - val_loss: 1.0402 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.2408 - acc: 0.9020 - val_loss: 1.0427 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2386 - acc: 0.9020 - val_loss: 1.0467 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2370 - acc: 0.9020 - val_loss: 1.0514 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2360 - acc: 0.8824 - val_loss: 1.0578 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2359 - acc: 0.9020 - val_loss: 1.0651 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2328 - acc: 0.8824 - val_loss: 1.0675 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.2321 - acc: 0.8824 - val_loss: 1.0678 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2299 - acc: 0.9020 - val_loss: 1.0747 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2282 - acc: 0.8824 - val_loss: 1.0801 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2269 - acc: 0.8824 - val_loss: 1.0868 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2252 - acc: 0.8824 - val_loss: 1.0922 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2241 - acc: 0.8824 - val_loss: 1.0987 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2225 - acc: 0.8824 - val_loss: 1.1048 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2216 - acc: 0.9020 - val_loss: 1.1053 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2198 - acc: 0.9020 - val_loss: 1.1131 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2182 - acc: 0.9020 - val_loss: 1.1175 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 486us/step - loss: 0.2174 - acc: 0.9020 - val_loss: 1.1211 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.2164 - acc: 0.9216 - val_loss: 1.1222 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2139 - acc: 0.9216 - val_loss: 1.1276 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2130 - acc: 0.9216 - val_loss: 1.1302 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2116 - acc: 0.9216 - val_loss: 1.1368 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2099 - acc: 0.9216 - val_loss: 1.1442 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2086 - acc: 0.9216 - val_loss: 1.1511 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2072 - acc: 0.9216 - val_loss: 1.1549 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2061 - acc: 0.9216 - val_loss: 1.1630 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2044 - acc: 0.9216 - val_loss: 1.1688 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2032 - acc: 0.9216 - val_loss: 1.1731 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2021 - acc: 0.9216 - val_loss: 1.1799 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2014 - acc: 0.9216 - val_loss: 1.1819 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2000 - acc: 0.9216 - val_loss: 1.1834 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.1980 - acc: 0.9216 - val_loss: 1.1853 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1971 - acc: 0.9216 - val_loss: 1.1939 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1953 - acc: 0.9216 - val_loss: 1.2016 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1940 - acc: 0.9216 - val_loss: 1.2054 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.937 - 0s 314us/step - loss: 0.1929 - acc: 0.9216 - val_loss: 1.2107 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1934 - acc: 0.9216 - val_loss: 1.2128 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1910 - acc: 0.9216 - val_loss: 1.2168 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1893 - acc: 0.9216 - val_loss: 1.2254 - val_acc: 0.7000\n",
      "2016-07-07\n",
      "2016-07-08\n",
      "2016-07-11\n",
      "2016-07-12\n",
      "2016-07-13\n",
      "2016-07-14\n",
      "2016-07-15\n",
      "2016-07-18\n",
      "2016-07-19\n",
      "2016-07-20\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 2.5689 - acc: 0.3725 - val_loss: 0.3570 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 335us/step - loss: 2.4548 - acc: 0.3725 - val_loss: 0.3578 - val_acc: 0.9000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 2.3787 - acc: 0.3725 - val_loss: 0.3576 - val_acc: 0.9000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 2.3174 - acc: 0.3725 - val_loss: 0.3601 - val_acc: 0.9000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 2.2634 - acc: 0.3725 - val_loss: 0.3600 - val_acc: 0.9000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 2.2146 - acc: 0.3922 - val_loss: 0.3611 - val_acc: 0.9000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 2.1686 - acc: 0.3922 - val_loss: 0.3632 - val_acc: 0.9000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.1230 - acc: 0.3922 - val_loss: 0.3647 - val_acc: 0.9000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 2.0792 - acc: 0.4118 - val_loss: 0.3656 - val_acc: 0.9000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 2.0387 - acc: 0.4314 - val_loss: 0.3667 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.9993 - acc: 0.4314 - val_loss: 0.3680 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.9625 - acc: 0.4314 - val_loss: 0.3716 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.9221 - acc: 0.4510 - val_loss: 0.3745 - val_acc: 0.9000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.8850 - acc: 0.4510 - val_loss: 0.3768 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 1.8491 - acc: 0.4510 - val_loss: 0.3771 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.8127 - acc: 0.4706 - val_loss: 0.3786 - val_acc: 0.9000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.7791 - acc: 0.4902 - val_loss: 0.3798 - val_acc: 0.9000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.7438 - acc: 0.5098 - val_loss: 0.3833 - val_acc: 0.9000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.7101 - acc: 0.5098 - val_loss: 0.3865 - val_acc: 0.9000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.6786 - acc: 0.5098 - val_loss: 0.3874 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.6444 - acc: 0.5098 - val_loss: 0.3900 - val_acc: 0.9000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 1.6129 - acc: 0.5098 - val_loss: 0.3919 - val_acc: 0.9000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.5828 - acc: 0.5098 - val_loss: 0.3941 - val_acc: 0.9000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.5516 - acc: 0.5294 - val_loss: 0.3983 - val_acc: 0.9000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.5202 - acc: 0.5294 - val_loss: 0.4014 - val_acc: 0.9000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.4898 - acc: 0.5294 - val_loss: 0.4052 - val_acc: 0.9000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.4630 - acc: 0.5294 - val_loss: 0.4110 - val_acc: 0.9000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.3831 - acc: 0.468 - 0s 275us/step - loss: 1.4331 - acc: 0.5294 - val_loss: 0.4148 - val_acc: 0.9000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.4056 - acc: 0.5294 - val_loss: 0.4179 - val_acc: 0.9000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.3776 - acc: 0.5294 - val_loss: 0.4207 - val_acc: 0.9000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.3524 - acc: 0.5294 - val_loss: 0.4275 - val_acc: 0.9000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.3253 - acc: 0.5294 - val_loss: 0.4312 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.2972 - acc: 0.5294 - val_loss: 0.4380 - val_acc: 0.9000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.2705 - acc: 0.5294 - val_loss: 0.4412 - val_acc: 0.9000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.2456 - acc: 0.5294 - val_loss: 0.4436 - val_acc: 0.9000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 1.2184 - acc: 0.5294 - val_loss: 0.4483 - val_acc: 0.9000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1945 - acc: 0.5490 - val_loss: 0.4533 - val_acc: 0.9000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.1709 - acc: 0.5490 - val_loss: 0.4604 - val_acc: 0.9000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.1471 - acc: 0.5490 - val_loss: 0.4674 - val_acc: 0.9000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1243 - acc: 0.5490 - val_loss: 0.4730 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.1014 - acc: 0.5490 - val_loss: 0.4791 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 208us/step - loss: 1.0775 - acc: 0.5490 - val_loss: 0.4872 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.2343 - acc: 0.500 - 0s 176us/step - loss: 1.0538 - acc: 0.5686 - val_loss: 0.4938 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7134 - acc: 0.625 - 0s 196us/step - loss: 1.0327 - acc: 0.5686 - val_loss: 0.5041 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0093 - acc: 0.5686 - val_loss: 0.5117 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9877 - acc: 0.5882 - val_loss: 0.5184 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.9691 - acc: 0.5882 - val_loss: 0.5272 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.9497 - acc: 0.5882 - val_loss: 0.5366 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.9303 - acc: 0.6078 - val_loss: 0.5450 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9113 - acc: 0.6078 - val_loss: 0.5579 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.8914 - acc: 0.6078 - val_loss: 0.5653 - val_acc: 0.6000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.8733 - acc: 0.6078 - val_loss: 0.5755 - val_acc: 0.6000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8559 - acc: 0.6078 - val_loss: 0.5841 - val_acc: 0.6000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8376 - acc: 0.6275 - val_loss: 0.5949 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8203 - acc: 0.6275 - val_loss: 0.6087 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8050 - acc: 0.6471 - val_loss: 0.6247 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7886 - acc: 0.6667 - val_loss: 0.6363 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7715 - acc: 0.6667 - val_loss: 0.6508 - val_acc: 0.5000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7555 - acc: 0.7059 - val_loss: 0.6654 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7407 - acc: 0.7059 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.7262 - acc: 0.7059 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.7119 - acc: 0.7255 - val_loss: 0.7040 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6981 - acc: 0.7451 - val_loss: 0.7174 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6835 - acc: 0.7647 - val_loss: 0.7344 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6701 - acc: 0.7647 - val_loss: 0.7525 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6566 - acc: 0.7843 - val_loss: 0.7672 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 222us/step - loss: 0.6451 - acc: 0.7843 - val_loss: 0.7877 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6319 - acc: 0.7843 - val_loss: 0.7997 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6200 - acc: 0.7843 - val_loss: 0.8163 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5766 - acc: 0.781 - 0s 236us/step - loss: 0.6082 - acc: 0.7843 - val_loss: 0.8323 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5958 - acc: 0.7843 - val_loss: 0.8496 - val_acc: 0.5000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5848 - acc: 0.7843 - val_loss: 0.8612 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5729 - acc: 0.8039 - val_loss: 0.8792 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5622 - acc: 0.8039 - val_loss: 0.8951 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.5510 - acc: 0.8039 - val_loss: 0.9153 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5405 - acc: 0.8039 - val_loss: 0.9333 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5315 - acc: 0.8039 - val_loss: 0.9462 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5225 - acc: 0.8039 - val_loss: 0.9666 - val_acc: 0.5000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5127 - acc: 0.8039 - val_loss: 0.9801 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5054 - acc: 0.8039 - val_loss: 1.0065 - val_acc: 0.5000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4950 - acc: 0.8039 - val_loss: 1.0258 - val_acc: 0.5000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4867 - acc: 0.8039 - val_loss: 1.0525 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.4771 - acc: 0.8039 - val_loss: 1.0713 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4693 - acc: 0.8039 - val_loss: 1.0948 - val_acc: 0.4000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4647 - acc: 0.843 - 0s 216us/step - loss: 0.4609 - acc: 0.8235 - val_loss: 1.1151 - val_acc: 0.4000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4527 - acc: 0.8431 - val_loss: 1.1325 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4442 - acc: 0.8235 - val_loss: 1.1575 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4361 - acc: 0.8235 - val_loss: 1.1774 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4285 - acc: 0.8235 - val_loss: 1.1963 - val_acc: 0.4000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4214 - acc: 0.8431 - val_loss: 1.2173 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 132us/step - loss: 0.4141 - acc: 0.8431 - val_loss: 1.2376 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4060 - acc: 0.8431 - val_loss: 1.2574 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 212us/step - loss: 0.3992 - acc: 0.8431 - val_loss: 1.2742 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3927 - acc: 0.8431 - val_loss: 1.2918 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3861 - acc: 0.8431 - val_loss: 1.3190 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3803 - acc: 0.8431 - val_loss: 1.3378 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3754 - acc: 0.8431 - val_loss: 1.3675 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3689 - acc: 0.8431 - val_loss: 1.3826 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3629 - acc: 0.8431 - val_loss: 1.3992 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3582 - acc: 0.8431 - val_loss: 1.4150 - val_acc: 0.3000\n",
      "2016-07-21\n",
      "2016-07-22\n",
      "2016-07-25\n",
      "2016-07-26\n",
      "2016-07-27\n",
      "2016-07-28\n",
      "2016-07-29\n",
      "2016-08-01\n",
      "2016-08-02\n",
      "2016-08-03\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.5761 - acc: 0.7059 - val_loss: 0.6009 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5583 - acc: 0.7255 - val_loss: 0.5679 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5466 - acc: 0.7255 - val_loss: 0.5461 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5363 - acc: 0.7255 - val_loss: 0.5196 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5272 - acc: 0.7255 - val_loss: 0.4971 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5194 - acc: 0.7255 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5125 - acc: 0.7451 - val_loss: 0.4596 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5064 - acc: 0.7647 - val_loss: 0.4457 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5000 - acc: 0.7843 - val_loss: 0.4304 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4946 - acc: 0.7843 - val_loss: 0.4179 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4919 - acc: 0.7843 - val_loss: 0.4036 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5439 - acc: 0.718 - 0s 196us/step - loss: 0.4854 - acc: 0.7843 - val_loss: 0.3920 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4810 - acc: 0.7647 - val_loss: 0.3814 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4770 - acc: 0.7647 - val_loss: 0.3732 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4727 - acc: 0.7647 - val_loss: 0.3676 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4689 - acc: 0.7647 - val_loss: 0.3583 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4645 - acc: 0.7647 - val_loss: 0.3475 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4611 - acc: 0.7647 - val_loss: 0.3385 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4583 - acc: 0.7647 - val_loss: 0.3306 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4539 - acc: 0.7647 - val_loss: 0.3259 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4508 - acc: 0.7647 - val_loss: 0.3178 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4468 - acc: 0.7843 - val_loss: 0.3124 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4424 - acc: 0.7843 - val_loss: 0.3054 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4393 - acc: 0.7843 - val_loss: 0.3008 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4362 - acc: 0.7843 - val_loss: 0.2925 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4342 - acc: 0.7843 - val_loss: 0.2921 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4302 - acc: 0.7843 - val_loss: 0.2876 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4267 - acc: 0.7843 - val_loss: 0.2814 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4241 - acc: 0.7843 - val_loss: 0.2779 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4214 - acc: 0.7843 - val_loss: 0.2762 - val_acc: 0.8000\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 392us/step - loss: 0.4195 - acc: 0.7843 - val_loss: 0.2744 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4157 - acc: 0.8039 - val_loss: 0.2704 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4131 - acc: 0.8039 - val_loss: 0.2654 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4108 - acc: 0.8039 - val_loss: 0.2608 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4075 - acc: 0.8039 - val_loss: 0.2565 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4058 - acc: 0.8039 - val_loss: 0.2544 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4032 - acc: 0.8039 - val_loss: 0.2496 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4000 - acc: 0.8039 - val_loss: 0.2468 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 335us/step - loss: 0.3982 - acc: 0.8039 - val_loss: 0.2433 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3956 - acc: 0.8039 - val_loss: 0.2390 - val_acc: 0.9000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3934 - acc: 0.8039 - val_loss: 0.2366 - val_acc: 0.9000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.3910 - acc: 0.8235 - val_loss: 0.2322 - val_acc: 0.9000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3888 - acc: 0.8235 - val_loss: 0.2321 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3864 - acc: 0.8235 - val_loss: 0.2299 - val_acc: 0.9000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3842 - acc: 0.8235 - val_loss: 0.2260 - val_acc: 0.9000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3825 - acc: 0.8431 - val_loss: 0.2241 - val_acc: 0.9000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3799 - acc: 0.8431 - val_loss: 0.2220 - val_acc: 0.9000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3776 - acc: 0.8431 - val_loss: 0.2222 - val_acc: 0.9000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3759 - acc: 0.8431 - val_loss: 0.2211 - val_acc: 0.9000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3732 - acc: 0.8235 - val_loss: 0.2192 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3710 - acc: 0.8431 - val_loss: 0.2156 - val_acc: 0.9000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3691 - acc: 0.8431 - val_loss: 0.2163 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 174us/step - loss: 0.3675 - acc: 0.8431 - val_loss: 0.2115 - val_acc: 0.9000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3639 - acc: 0.8431 - val_loss: 0.2085 - val_acc: 0.9000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3618 - acc: 0.8431 - val_loss: 0.2072 - val_acc: 0.9000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3597 - acc: 0.8431 - val_loss: 0.2070 - val_acc: 0.9000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3586 - acc: 0.8235 - val_loss: 0.2016 - val_acc: 0.9000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3550 - acc: 0.8431 - val_loss: 0.1991 - val_acc: 0.9000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3531 - acc: 0.8235 - val_loss: 0.1980 - val_acc: 0.9000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3515 - acc: 0.8235 - val_loss: 0.1949 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3498 - acc: 0.8431 - val_loss: 0.1910 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3474 - acc: 0.8235 - val_loss: 0.1906 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3450 - acc: 0.8235 - val_loss: 0.1873 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3434 - acc: 0.8235 - val_loss: 0.1836 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3410 - acc: 0.8235 - val_loss: 0.1808 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3197 - acc: 0.843 - 0s 255us/step - loss: 0.3395 - acc: 0.8235 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3372 - acc: 0.8431 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3363 - acc: 0.8235 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 182us/step - loss: 0.3327 - acc: 0.8431 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 208us/step - loss: 0.3309 - acc: 0.8431 - val_loss: 0.1694 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3295 - acc: 0.8235 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3271 - acc: 0.8431 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3252 - acc: 0.8431 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3228 - acc: 0.8235 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3210 - acc: 0.8235 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3190 - acc: 0.8431 - val_loss: 0.1571 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3172 - acc: 0.8431 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3167 - acc: 0.8431 - val_loss: 0.1544 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3139 - acc: 0.8431 - val_loss: 0.1510 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.3115 - acc: 0.8627 - val_loss: 0.1495 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3094 - acc: 0.8627 - val_loss: 0.1484 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3082 - acc: 0.8431 - val_loss: 0.1481 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3062 - acc: 0.8431 - val_loss: 0.1458 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3043 - acc: 0.8431 - val_loss: 0.1435 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3023 - acc: 0.8431 - val_loss: 0.1413 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3010 - acc: 0.8627 - val_loss: 0.1380 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.2986 - acc: 0.8431 - val_loss: 0.1375 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2970 - acc: 0.8431 - val_loss: 0.1369 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2958 - acc: 0.8627 - val_loss: 0.1346 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2933 - acc: 0.8627 - val_loss: 0.1337 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2920 - acc: 0.8627 - val_loss: 0.1319 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2894 - acc: 0.8627 - val_loss: 0.1282 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2873 - acc: 0.8627 - val_loss: 0.1253 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2856 - acc: 0.8627 - val_loss: 0.1232 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2844 - acc: 0.8627 - val_loss: 0.1218 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2821 - acc: 0.8824 - val_loss: 0.1194 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2809 - acc: 0.8627 - val_loss: 0.1195 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2792 - acc: 0.8627 - val_loss: 0.1165 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2771 - acc: 0.8627 - val_loss: 0.1170 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2753 - acc: 0.8627 - val_loss: 0.1141 - val_acc: 1.0000\n",
      "2016-08-04\n",
      "2016-08-05\n",
      "2016-08-08\n",
      "2016-08-09\n",
      "2016-08-10\n",
      "2016-08-11\n",
      "2016-08-12\n",
      "2016-08-15\n",
      "2016-08-16\n",
      "2016-08-17\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.4707 - acc: 0.7451 - val_loss: 1.0668 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4575 - acc: 0.7843 - val_loss: 1.0443 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4478 - acc: 0.8039 - val_loss: 1.0270 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4400 - acc: 0.8235 - val_loss: 1.0130 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4331 - acc: 0.8235 - val_loss: 1.0054 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4276 - acc: 0.8235 - val_loss: 0.9943 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.4229 - acc: 0.8235 - val_loss: 0.9881 - val_acc: 0.4000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.4185 - acc: 0.8235 - val_loss: 0.9805 - val_acc: 0.4000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.4142 - acc: 0.8235 - val_loss: 0.9769 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4091 - acc: 0.8235 - val_loss: 0.9716 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4053 - acc: 0.8235 - val_loss: 0.9673 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4012 - acc: 0.8235 - val_loss: 0.9627 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3983 - acc: 0.8235 - val_loss: 0.9613 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3942 - acc: 0.8235 - val_loss: 0.9587 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3905 - acc: 0.8235 - val_loss: 0.9571 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3861 - acc: 0.8235 - val_loss: 0.9540 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3826 - acc: 0.8235 - val_loss: 0.9507 - val_acc: 0.4000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3810 - acc: 0.8235 - val_loss: 0.9485 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3780 - acc: 0.8235 - val_loss: 0.9438 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3736 - acc: 0.8235 - val_loss: 0.9423 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3705 - acc: 0.8235 - val_loss: 0.9402 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3678 - acc: 0.8235 - val_loss: 0.9376 - val_acc: 0.4000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3647 - acc: 0.8235 - val_loss: 0.9326 - val_acc: 0.4000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3619 - acc: 0.8235 - val_loss: 0.9310 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3601 - acc: 0.8235 - val_loss: 0.9277 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3564 - acc: 0.8235 - val_loss: 0.9237 - val_acc: 0.3000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3549 - acc: 0.8235 - val_loss: 0.9205 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3511 - acc: 0.8235 - val_loss: 0.9173 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3490 - acc: 0.8235 - val_loss: 0.9150 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3477 - acc: 0.8235 - val_loss: 0.9133 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3439 - acc: 0.8431 - val_loss: 0.9108 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 149us/step - loss: 0.3425 - acc: 0.8235 - val_loss: 0.9111 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3393 - acc: 0.8431 - val_loss: 0.9081 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3376 - acc: 0.8431 - val_loss: 0.9091 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3354 - acc: 0.8627 - val_loss: 0.9074 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3327 - acc: 0.8627 - val_loss: 0.9077 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3315 - acc: 0.8627 - val_loss: 0.9070 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3285 - acc: 0.8627 - val_loss: 0.9102 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3258 - acc: 0.8627 - val_loss: 0.9114 - val_acc: 0.6000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3243 - acc: 0.8627 - val_loss: 0.9107 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3213 - acc: 0.8627 - val_loss: 0.9125 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3190 - acc: 0.8627 - val_loss: 0.9120 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3184 - acc: 0.8627 - val_loss: 0.9159 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3149 - acc: 0.8627 - val_loss: 0.9178 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3127 - acc: 0.8627 - val_loss: 0.9192 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3108 - acc: 0.8627 - val_loss: 0.9226 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3095 - acc: 0.8627 - val_loss: 0.9211 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3059 - acc: 0.8627 - val_loss: 0.9196 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3030 - acc: 0.8627 - val_loss: 0.9223 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3022 - acc: 0.8627 - val_loss: 0.9271 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2990 - acc: 0.8627 - val_loss: 0.9284 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2976 - acc: 0.8627 - val_loss: 0.9335 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2953 - acc: 0.8627 - val_loss: 0.9326 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2922 - acc: 0.8627 - val_loss: 0.9384 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2903 - acc: 0.8627 - val_loss: 0.9405 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3070 - acc: 0.843 - 0s 216us/step - loss: 0.2890 - acc: 0.8627 - val_loss: 0.9418 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2859 - acc: 0.8627 - val_loss: 0.9467 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2845 - acc: 0.8627 - val_loss: 0.9489 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2822 - acc: 0.8627 - val_loss: 0.9576 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2816 - acc: 0.8627 - val_loss: 0.9685 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2783 - acc: 0.8627 - val_loss: 0.9779 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2769 - acc: 0.8627 - val_loss: 0.9884 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2746 - acc: 0.8627 - val_loss: 0.9950 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2727 - acc: 0.8627 - val_loss: 0.9982 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2713 - acc: 0.8627 - val_loss: 1.0005 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2695 - acc: 0.8627 - val_loss: 1.0146 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.2664 - acc: 0.8627 - val_loss: 1.0221 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2655 - acc: 0.8627 - val_loss: 1.0296 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2630 - acc: 0.8627 - val_loss: 1.0370 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2611 - acc: 0.8627 - val_loss: 1.0416 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2597 - acc: 0.8627 - val_loss: 1.0586 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2573 - acc: 0.8824 - val_loss: 1.0695 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2565 - acc: 0.8824 - val_loss: 1.0717 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2550 - acc: 0.8824 - val_loss: 1.0747 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.2525 - acc: 0.8824 - val_loss: 1.0848 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2501 - acc: 0.8824 - val_loss: 1.0976 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2479 - acc: 0.8824 - val_loss: 1.1052 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2463 - acc: 0.8824 - val_loss: 1.1223 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2446 - acc: 0.8824 - val_loss: 1.1337 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2425 - acc: 0.8824 - val_loss: 1.1514 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2412 - acc: 0.8824 - val_loss: 1.1702 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2402 - acc: 0.8824 - val_loss: 1.1913 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2386 - acc: 0.8824 - val_loss: 1.2034 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2364 - acc: 0.8824 - val_loss: 1.2156 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2349 - acc: 0.8824 - val_loss: 1.2283 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2342 - acc: 0.8824 - val_loss: 1.2317 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2316 - acc: 0.8824 - val_loss: 1.2491 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.2299 - acc: 0.8824 - val_loss: 1.2614 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2287 - acc: 0.8824 - val_loss: 1.2745 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2273 - acc: 0.8824 - val_loss: 1.2839 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 170us/step - loss: 0.2251 - acc: 0.8824 - val_loss: 1.2970 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2236 - acc: 0.8824 - val_loss: 1.3120 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2221 - acc: 0.8824 - val_loss: 1.3191 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2199 - acc: 0.8824 - val_loss: 1.3378 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2185 - acc: 0.8824 - val_loss: 1.3498 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2169 - acc: 0.8824 - val_loss: 1.3623 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2160 - acc: 0.8824 - val_loss: 1.3705 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2143 - acc: 0.8824 - val_loss: 1.3890 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2128 - acc: 0.8824 - val_loss: 1.3954 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2105 - acc: 0.9020 - val_loss: 1.4154 - val_acc: 0.7000\n",
      "2016-08-18\n",
      "2016-08-19\n",
      "2016-08-22\n",
      "2016-08-23\n",
      "2016-08-24\n",
      "2016-08-25\n",
      "2016-08-26\n",
      "2016-08-29\n",
      "2016-08-30\n",
      "2016-08-31\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.6859 - acc: 0.7647 - val_loss: 5.6193 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 340us/step - loss: 0.6588 - acc: 0.7843 - val_loss: 5.5165 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.6379 - acc: 0.7843 - val_loss: 5.3872 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6225 - acc: 0.7647 - val_loss: 5.2927 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6152 - acc: 0.7647 - val_loss: 5.1993 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6000 - acc: 0.7647 - val_loss: 5.1618 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 278us/step - loss: 0.5901 - acc: 0.7647 - val_loss: 5.1047 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5834 - acc: 0.7647 - val_loss: 5.0645 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5750 - acc: 0.7647 - val_loss: 5.0202 - val_acc: 0.1000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5668 - acc: 0.7647 - val_loss: 4.9672 - val_acc: 0.1000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5554 - acc: 0.7647 - val_loss: 4.9217 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5471 - acc: 0.7647 - val_loss: 4.8586 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5390 - acc: 0.7647 - val_loss: 4.7895 - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.5338 - acc: 0.7647 - val_loss: 4.7107 - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5236 - acc: 0.7647 - val_loss: 4.6891 - val_acc: 0.1000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.5161 - acc: 0.7647 - val_loss: 4.6460 - val_acc: 0.1000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.5080 - acc: 0.7647 - val_loss: 4.6083 - val_acc: 0.1000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5022 - acc: 0.7647 - val_loss: 4.5833 - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4955 - acc: 0.7647 - val_loss: 4.5312 - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4897 - acc: 0.7647 - val_loss: 4.5104 - val_acc: 0.1000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4857 - acc: 0.7647 - val_loss: 4.5058 - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4781 - acc: 0.7647 - val_loss: 4.4684 - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4739 - acc: 0.7647 - val_loss: 4.4316 - val_acc: 0.1000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4703 - acc: 0.7843 - val_loss: 4.3963 - val_acc: 0.1000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4654 - acc: 0.7843 - val_loss: 4.3315 - val_acc: 0.1000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4582 - acc: 0.7843 - val_loss: 4.2922 - val_acc: 0.1000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4557 - acc: 0.7843 - val_loss: 4.2443 - val_acc: 0.1000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4522 - acc: 0.8039 - val_loss: 4.1894 - val_acc: 0.1000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4480 - acc: 0.8235 - val_loss: 4.1700 - val_acc: 0.1000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4420 - acc: 0.8235 - val_loss: 4.1377 - val_acc: 0.1000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4388 - acc: 0.8235 - val_loss: 4.1248 - val_acc: 0.1000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4327 - acc: 0.8235 - val_loss: 4.1109 - val_acc: 0.1000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4283 - acc: 0.8235 - val_loss: 4.0799 - val_acc: 0.1000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4248 - acc: 0.8235 - val_loss: 4.0816 - val_acc: 0.1000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4199 - acc: 0.8431 - val_loss: 4.0742 - val_acc: 0.1000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4159 - acc: 0.8431 - val_loss: 4.0209 - val_acc: 0.1000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.4122 - acc: 0.8431 - val_loss: 3.9905 - val_acc: 0.1000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.4083 - acc: 0.8235 - val_loss: 3.9583 - val_acc: 0.1000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4052 - acc: 0.8235 - val_loss: 3.9380 - val_acc: 0.1000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4004 - acc: 0.8431 - val_loss: 3.9091 - val_acc: 0.1000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.3975 - acc: 0.8235 - val_loss: 3.8870 - val_acc: 0.1000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3954 - acc: 0.8431 - val_loss: 3.8390 - val_acc: 0.1000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3899 - acc: 0.8431 - val_loss: 3.8352 - val_acc: 0.1000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3854 - acc: 0.8431 - val_loss: 3.8283 - val_acc: 0.1000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3818 - acc: 0.8235 - val_loss: 3.8238 - val_acc: 0.1000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3786 - acc: 0.8235 - val_loss: 3.8378 - val_acc: 0.1000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3748 - acc: 0.8235 - val_loss: 3.8384 - val_acc: 0.1000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3717 - acc: 0.8235 - val_loss: 3.8023 - val_acc: 0.1000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3676 - acc: 0.8235 - val_loss: 3.7898 - val_acc: 0.1000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3650 - acc: 0.8235 - val_loss: 3.7566 - val_acc: 0.1000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3624 - acc: 0.8235 - val_loss: 3.7391 - val_acc: 0.1000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3594 - acc: 0.8235 - val_loss: 3.7491 - val_acc: 0.1000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3548 - acc: 0.8235 - val_loss: 3.7265 - val_acc: 0.1000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3519 - acc: 0.8431 - val_loss: 3.7234 - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3492 - acc: 0.8235 - val_loss: 3.7231 - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2685 - acc: 0.875 - 0s 196us/step - loss: 0.3455 - acc: 0.8235 - val_loss: 3.6905 - val_acc: 0.1000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3416 - acc: 0.8235 - val_loss: 3.6771 - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3393 - acc: 0.8235 - val_loss: 3.6696 - val_acc: 0.1000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3363 - acc: 0.8431 - val_loss: 3.6368 - val_acc: 0.1000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3335 - acc: 0.8431 - val_loss: 3.6311 - val_acc: 0.1000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3307 - acc: 0.8431 - val_loss: 3.6188 - val_acc: 0.1000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3281 - acc: 0.8627 - val_loss: 3.6380 - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3245 - acc: 0.8431 - val_loss: 3.6433 - val_acc: 0.1000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3215 - acc: 0.8431 - val_loss: 3.6420 - val_acc: 0.1000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3188 - acc: 0.8431 - val_loss: 3.6315 - val_acc: 0.1000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3170 - acc: 0.8431 - val_loss: 3.6022 - val_acc: 0.1000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3132 - acc: 0.8627 - val_loss: 3.5963 - val_acc: 0.1000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3104 - acc: 0.8627 - val_loss: 3.5607 - val_acc: 0.1000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3081 - acc: 0.8627 - val_loss: 3.5281 - val_acc: 0.1000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3050 - acc: 0.8627 - val_loss: 3.5277 - val_acc: 0.1000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3024 - acc: 0.8627 - val_loss: 3.5385 - val_acc: 0.1000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2996 - acc: 0.8627 - val_loss: 3.5206 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2977 - acc: 0.8627 - val_loss: 3.4969 - val_acc: 0.1000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.2953 - acc: 0.8824 - val_loss: 3.4884 - val_acc: 0.1000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2921 - acc: 0.8824 - val_loss: 3.4738 - val_acc: 0.1000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.2899 - acc: 0.8824 - val_loss: 3.4840 - val_acc: 0.1000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2864 - acc: 0.8824 - val_loss: 3.4630 - val_acc: 0.1000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2865 - acc: 0.8824 - val_loss: 3.4621 - val_acc: 0.1000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2840 - acc: 0.8824 - val_loss: 3.4879 - val_acc: 0.1000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2802 - acc: 0.8824 - val_loss: 3.4873 - val_acc: 0.1000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2784 - acc: 0.8824 - val_loss: 3.4659 - val_acc: 0.1000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2751 - acc: 0.8824 - val_loss: 3.4667 - val_acc: 0.1000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2746 - acc: 0.8824 - val_loss: 3.4891 - val_acc: 0.1000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2708 - acc: 0.9020 - val_loss: 3.4645 - val_acc: 0.1000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2686 - acc: 0.9020 - val_loss: 3.4695 - val_acc: 0.1000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2666 - acc: 0.9020 - val_loss: 3.4653 - val_acc: 0.1000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2660 - acc: 0.9020 - val_loss: 3.4639 - val_acc: 0.1000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2623 - acc: 0.9020 - val_loss: 3.4690 - val_acc: 0.1000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2601 - acc: 0.9020 - val_loss: 3.4658 - val_acc: 0.1000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2580 - acc: 0.9020 - val_loss: 3.4493 - val_acc: 0.1000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2554 - acc: 0.9020 - val_loss: 3.4437 - val_acc: 0.1000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2539 - acc: 0.9216 - val_loss: 3.4532 - val_acc: 0.1000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2509 - acc: 0.9412 - val_loss: 3.4469 - val_acc: 0.1000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2497 - acc: 0.9216 - val_loss: 3.4058 - val_acc: 0.1000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2466 - acc: 0.9412 - val_loss: 3.3864 - val_acc: 0.1000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2450 - acc: 0.9412 - val_loss: 3.3931 - val_acc: 0.1000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.2425 - acc: 0.9412 - val_loss: 3.3856 - val_acc: 0.1000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2397 - acc: 0.9412 - val_loss: 3.3705 - val_acc: 0.1000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 276us/step - loss: 0.2382 - acc: 0.9412 - val_loss: 3.3414 - val_acc: 0.1000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2369 - acc: 0.9412 - val_loss: 3.3585 - val_acc: 0.1000\n",
      "2016-09-01\n",
      "2016-09-02\n",
      "2016-09-05\n",
      "2016-09-06\n",
      "2016-09-07\n",
      "2016-09-08\n",
      "2016-09-09\n",
      "2016-09-12\n",
      "2016-09-13\n",
      "2016-09-14\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 1.7903 - acc: 0.5882 - val_loss: 0.6366 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 782us/step - loss: 1.6963 - acc: 0.5882 - val_loss: 0.6320 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.6326 - acc: 0.5882 - val_loss: 0.6291 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.5816 - acc: 0.5882 - val_loss: 0.6298 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5379 - acc: 0.5882 - val_loss: 0.6277 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.4990 - acc: 0.5882 - val_loss: 0.6264 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.4590 - acc: 0.5882 - val_loss: 0.6239 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.4175 - acc: 0.5882 - val_loss: 0.6222 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3843 - acc: 0.5882 - val_loss: 0.6235 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.3514 - acc: 0.5882 - val_loss: 0.6208 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.3193 - acc: 0.5882 - val_loss: 0.6221 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.2893 - acc: 0.5882 - val_loss: 0.6219 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.2593 - acc: 0.6078 - val_loss: 0.6218 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.2291 - acc: 0.6078 - val_loss: 0.6218 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.2028 - acc: 0.6078 - val_loss: 0.6219 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1739 - acc: 0.6078 - val_loss: 0.6202 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.1468 - acc: 0.6078 - val_loss: 0.6191 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.1193 - acc: 0.6275 - val_loss: 0.6208 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0939 - acc: 0.6275 - val_loss: 0.6221 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.0687 - acc: 0.6275 - val_loss: 0.6231 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9437 - acc: 0.656 - 0s 176us/step - loss: 1.0447 - acc: 0.6275 - val_loss: 0.6233 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.0174 - acc: 0.6275 - val_loss: 0.6239 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9954 - acc: 0.6275 - val_loss: 0.6243 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9723 - acc: 0.6275 - val_loss: 0.6226 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9512 - acc: 0.6275 - val_loss: 0.6248 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9310 - acc: 0.6078 - val_loss: 0.6286 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9151 - acc: 0.6078 - val_loss: 0.6317 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8965 - acc: 0.6078 - val_loss: 0.6344 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8783 - acc: 0.6078 - val_loss: 0.6343 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8595 - acc: 0.6275 - val_loss: 0.6374 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.8432 - acc: 0.6275 - val_loss: 0.6372 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8258 - acc: 0.6275 - val_loss: 0.6386 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8117 - acc: 0.6275 - val_loss: 0.6430 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.7966 - acc: 0.6471 - val_loss: 0.6448 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7839 - acc: 0.6471 - val_loss: 0.6483 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7696 - acc: 0.6471 - val_loss: 0.6544 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7563 - acc: 0.6471 - val_loss: 0.6569 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7448 - acc: 0.6667 - val_loss: 0.6618 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7353 - acc: 0.6667 - val_loss: 0.6627 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7257 - acc: 0.6863 - val_loss: 0.6651 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7110 - acc: 0.6863 - val_loss: 0.6707 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 251us/step - loss: 0.6991 - acc: 0.6863 - val_loss: 0.6746 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.6906 - acc: 0.6863 - val_loss: 0.6794 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6790 - acc: 0.6863 - val_loss: 0.6860 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6700 - acc: 0.6863 - val_loss: 0.6927 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6592 - acc: 0.7059 - val_loss: 0.6985 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6507 - acc: 0.7255 - val_loss: 0.7017 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6131 - acc: 0.781 - 0s 195us/step - loss: 0.6410 - acc: 0.7451 - val_loss: 0.7062 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.6329 - acc: 0.7451 - val_loss: 0.7089 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.6233 - acc: 0.7451 - val_loss: 0.7144 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6147 - acc: 0.7647 - val_loss: 0.7221 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.6077 - acc: 0.7647 - val_loss: 0.7269 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5989 - acc: 0.7647 - val_loss: 0.7352 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5909 - acc: 0.7451 - val_loss: 0.7474 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.5835 - acc: 0.7647 - val_loss: 0.7549 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5767 - acc: 0.7647 - val_loss: 0.7632 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 319us/step - loss: 0.5691 - acc: 0.7843 - val_loss: 0.7729 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5624 - acc: 0.7843 - val_loss: 0.7837 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.5549 - acc: 0.7843 - val_loss: 0.7913 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5482 - acc: 0.7843 - val_loss: 0.7982 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5416 - acc: 0.7843 - val_loss: 0.8028 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5343 - acc: 0.7843 - val_loss: 0.8118 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5317 - acc: 0.7843 - val_loss: 0.8191 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5223 - acc: 0.7843 - val_loss: 0.8211 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5157 - acc: 0.7843 - val_loss: 0.8261 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5101 - acc: 0.7843 - val_loss: 0.8262 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5048 - acc: 0.7843 - val_loss: 0.8353 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4988 - acc: 0.7843 - val_loss: 0.8369 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4938 - acc: 0.7843 - val_loss: 0.8408 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4908 - acc: 0.8039 - val_loss: 0.8406 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4835 - acc: 0.7843 - val_loss: 0.8438 - val_acc: 0.6000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4785 - acc: 0.8039 - val_loss: 0.8453 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4749 - acc: 0.8039 - val_loss: 0.8448 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.4688 - acc: 0.7843 - val_loss: 0.8516 - val_acc: 0.6000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.4649 - acc: 0.8039 - val_loss: 0.8553 - val_acc: 0.6000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4606 - acc: 0.7843 - val_loss: 0.8596 - val_acc: 0.6000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4576 - acc: 0.8039 - val_loss: 0.8583 - val_acc: 0.6000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4520 - acc: 0.8039 - val_loss: 0.8586 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.4494 - acc: 0.7843 - val_loss: 0.8618 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4432 - acc: 0.8039 - val_loss: 0.8609 - val_acc: 0.6000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4396 - acc: 0.8039 - val_loss: 0.8682 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4359 - acc: 0.7843 - val_loss: 0.8746 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4315 - acc: 0.8235 - val_loss: 0.8824 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.4263 - acc: 0.8235 - val_loss: 0.8837 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4229 - acc: 0.8235 - val_loss: 0.8878 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4187 - acc: 0.8431 - val_loss: 0.8887 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4153 - acc: 0.8235 - val_loss: 0.8896 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4233 - acc: 0.812 - 0s 176us/step - loss: 0.4110 - acc: 0.8431 - val_loss: 0.8934 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4104 - acc: 0.8431 - val_loss: 0.8927 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4042 - acc: 0.8431 - val_loss: 0.8930 - val_acc: 0.6000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.4008 - acc: 0.8431 - val_loss: 0.8949 - val_acc: 0.6000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3972 - acc: 0.8235 - val_loss: 0.8949 - val_acc: 0.6000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3927 - acc: 0.8431 - val_loss: 0.8983 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3892 - acc: 0.8431 - val_loss: 0.9015 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3869 - acc: 0.8431 - val_loss: 0.9059 - val_acc: 0.6000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3827 - acc: 0.8431 - val_loss: 0.9011 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 269us/step - loss: 0.3800 - acc: 0.8431 - val_loss: 0.8993 - val_acc: 0.6000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.3759 - acc: 0.8431 - val_loss: 0.8926 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 379us/step - loss: 0.3721 - acc: 0.8235 - val_loss: 0.8897 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3688 - acc: 0.8235 - val_loss: 0.8908 - val_acc: 0.6000\n",
      "2016-09-19\n",
      "2016-09-20\n",
      "2016-09-21\n",
      "2016-09-22\n",
      "2016-09-23\n",
      "2016-09-26\n",
      "2016-09-27\n",
      "2016-09-28\n",
      "2016-09-29\n",
      "2016-09-30\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 1.7214 - acc: 0.6078 - val_loss: 0.9923 - val_acc: 0.4000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 117us/step - loss: 1.6657 - acc: 0.6078 - val_loss: 0.9923 - val_acc: 0.4000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.6240 - acc: 0.6078 - val_loss: 0.9851 - val_acc: 0.4000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.5917 - acc: 0.5882 - val_loss: 0.9802 - val_acc: 0.4000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.5635 - acc: 0.6078 - val_loss: 0.9830 - val_acc: 0.4000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.5352 - acc: 0.6078 - val_loss: 0.9825 - val_acc: 0.4000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5093 - acc: 0.5882 - val_loss: 0.9744 - val_acc: 0.4000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.4839 - acc: 0.5882 - val_loss: 0.9734 - val_acc: 0.4000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.4606 - acc: 0.5882 - val_loss: 0.9709 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.4365 - acc: 0.5882 - val_loss: 0.9689 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.4123 - acc: 0.5882 - val_loss: 0.9695 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 1.3899 - acc: 0.5882 - val_loss: 0.9622 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.3674 - acc: 0.5882 - val_loss: 0.9696 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.3455 - acc: 0.5882 - val_loss: 0.9600 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.3235 - acc: 0.5882 - val_loss: 0.9582 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 1.3019 - acc: 0.5882 - val_loss: 0.9603 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.2808 - acc: 0.5882 - val_loss: 0.9603 - val_acc: 0.4000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.2601 - acc: 0.5882 - val_loss: 0.9596 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.2395 - acc: 0.5882 - val_loss: 0.9574 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.2179 - acc: 0.5882 - val_loss: 0.9591 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 1.1978 - acc: 0.5882 - val_loss: 0.9549 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1778 - acc: 0.5882 - val_loss: 0.9557 - val_acc: 0.4000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.3831 - acc: 0.531 - 0s 334us/step - loss: 1.1604 - acc: 0.5882 - val_loss: 0.9415 - val_acc: 0.4000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 1.1398 - acc: 0.5882 - val_loss: 0.9400 - val_acc: 0.4000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1205 - acc: 0.5882 - val_loss: 0.9402 - val_acc: 0.4000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.1009 - acc: 0.6078 - val_loss: 0.9368 - val_acc: 0.4000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.0821 - acc: 0.6275 - val_loss: 0.9347 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 175us/step - loss: 1.0638 - acc: 0.6275 - val_loss: 0.9336 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.0440 - acc: 0.6275 - val_loss: 0.9223 - val_acc: 0.4000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0276 - acc: 0.6078 - val_loss: 0.9155 - val_acc: 0.4000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.0118 - acc: 0.6078 - val_loss: 0.9168 - val_acc: 0.4000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.9931 - acc: 0.6078 - val_loss: 0.9108 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9758 - acc: 0.6275 - val_loss: 0.9019 - val_acc: 0.4000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.9612 - acc: 0.6275 - val_loss: 0.8973 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.9456 - acc: 0.6275 - val_loss: 0.8863 - val_acc: 0.4000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9308 - acc: 0.6471 - val_loss: 0.8793 - val_acc: 0.4000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.9162 - acc: 0.6471 - val_loss: 0.8644 - val_acc: 0.4000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9019 - acc: 0.6471 - val_loss: 0.8604 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8860 - acc: 0.6275 - val_loss: 0.8488 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8720 - acc: 0.6275 - val_loss: 0.8441 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.8586 - acc: 0.6471 - val_loss: 0.8369 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8439 - acc: 0.6471 - val_loss: 0.8311 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8309 - acc: 0.6471 - val_loss: 0.8212 - val_acc: 0.6000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8187 - acc: 0.6471 - val_loss: 0.8179 - val_acc: 0.6000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8048 - acc: 0.6275 - val_loss: 0.8119 - val_acc: 0.6000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7932 - acc: 0.6471 - val_loss: 0.7978 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7810 - acc: 0.6471 - val_loss: 0.7917 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7710 - acc: 0.6471 - val_loss: 0.7882 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7582 - acc: 0.6275 - val_loss: 0.7709 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6941 - acc: 0.750 - 0s 177us/step - loss: 0.7472 - acc: 0.6667 - val_loss: 0.7635 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7362 - acc: 0.6667 - val_loss: 0.7530 - val_acc: 0.7000\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 235us/step - loss: 0.7261 - acc: 0.6471 - val_loss: 0.7446 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7150 - acc: 0.6471 - val_loss: 0.7304 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7052 - acc: 0.6471 - val_loss: 0.7270 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.6941 - acc: 0.6471 - val_loss: 0.7112 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 530us/step - loss: 0.6847 - acc: 0.6471 - val_loss: 0.6966 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6761 - acc: 0.6471 - val_loss: 0.6911 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6653 - acc: 0.6471 - val_loss: 0.6795 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6565 - acc: 0.6471 - val_loss: 0.6709 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.6465 - acc: 0.6471 - val_loss: 0.6617 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6357 - acc: 0.6471 - val_loss: 0.6488 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6270 - acc: 0.6863 - val_loss: 0.6382 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6177 - acc: 0.6863 - val_loss: 0.6287 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6094 - acc: 0.7059 - val_loss: 0.6123 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6023 - acc: 0.7255 - val_loss: 0.6051 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5929 - acc: 0.7255 - val_loss: 0.5951 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5849 - acc: 0.7059 - val_loss: 0.5774 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5784 - acc: 0.7451 - val_loss: 0.5597 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5700 - acc: 0.7255 - val_loss: 0.5491 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5622 - acc: 0.7647 - val_loss: 0.5426 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5537 - acc: 0.7647 - val_loss: 0.5351 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5464 - acc: 0.8039 - val_loss: 0.5211 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5389 - acc: 0.8039 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5319 - acc: 0.8431 - val_loss: 0.4979 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5252 - acc: 0.8431 - val_loss: 0.4924 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5192 - acc: 0.8431 - val_loss: 0.4821 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5115 - acc: 0.8431 - val_loss: 0.4711 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5051 - acc: 0.8431 - val_loss: 0.4683 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4983 - acc: 0.8431 - val_loss: 0.4614 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4910 - acc: 0.8431 - val_loss: 0.4551 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4855 - acc: 0.8627 - val_loss: 0.4455 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4796 - acc: 0.8627 - val_loss: 0.4353 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4734 - acc: 0.8627 - val_loss: 0.4253 - val_acc: 0.9000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4664 - acc: 0.8627 - val_loss: 0.4231 - val_acc: 0.9000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4617 - acc: 0.8627 - val_loss: 0.4200 - val_acc: 0.9000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4555 - acc: 0.8627 - val_loss: 0.4104 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4508 - acc: 0.8627 - val_loss: 0.4015 - val_acc: 0.9000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4459 - acc: 0.8627 - val_loss: 0.3918 - val_acc: 0.9000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4413 - acc: 0.8627 - val_loss: 0.3866 - val_acc: 0.9000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4361 - acc: 0.8627 - val_loss: 0.3794 - val_acc: 0.9000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4304 - acc: 0.8627 - val_loss: 0.3745 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4249 - acc: 0.8627 - val_loss: 0.3713 - val_acc: 0.9000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4202 - acc: 0.8627 - val_loss: 0.3644 - val_acc: 0.9000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4168 - acc: 0.8627 - val_loss: 0.3661 - val_acc: 0.9000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4107 - acc: 0.8627 - val_loss: 0.3589 - val_acc: 0.9000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4059 - acc: 0.8627 - val_loss: 0.3492 - val_acc: 0.9000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4017 - acc: 0.8627 - val_loss: 0.3486 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3984 - acc: 0.8627 - val_loss: 0.3384 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3929 - acc: 0.9020 - val_loss: 0.3306 - val_acc: 0.9000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3886 - acc: 0.9020 - val_loss: 0.3236 - val_acc: 0.9000\n",
      "2016-10-10\n",
      "2016-10-11\n",
      "2016-10-12\n",
      "2016-10-13\n",
      "2016-10-14\n",
      "2016-10-17\n",
      "2016-10-18\n",
      "2016-10-19\n",
      "2016-10-20\n",
      "2016-10-21\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.4452 - acc: 0.8039 - val_loss: 0.8013 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4179 - acc: 0.8235 - val_loss: 0.7898 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4052 - acc: 0.8235 - val_loss: 0.7832 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3901 - acc: 0.8039 - val_loss: 0.7768 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3815 - acc: 0.8235 - val_loss: 0.7731 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3706 - acc: 0.8235 - val_loss: 0.7678 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3625 - acc: 0.8039 - val_loss: 0.7634 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3540 - acc: 0.8039 - val_loss: 0.7603 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3478 - acc: 0.8235 - val_loss: 0.7589 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3409 - acc: 0.8039 - val_loss: 0.7563 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3341 - acc: 0.8039 - val_loss: 0.7559 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3285 - acc: 0.8039 - val_loss: 0.7531 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3237 - acc: 0.8039 - val_loss: 0.7504 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3163 - acc: 0.8039 - val_loss: 0.7494 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3124 - acc: 0.8235 - val_loss: 0.7473 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3065 - acc: 0.8431 - val_loss: 0.7456 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3572 - acc: 0.750 - 0s 176us/step - loss: 0.2999 - acc: 0.8235 - val_loss: 0.7459 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2951 - acc: 0.8235 - val_loss: 0.7441 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2899 - acc: 0.8235 - val_loss: 0.7433 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2854 - acc: 0.8431 - val_loss: 0.7428 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2797 - acc: 0.8235 - val_loss: 0.7414 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2743 - acc: 0.8431 - val_loss: 0.7431 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2703 - acc: 0.8431 - val_loss: 0.7433 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2649 - acc: 0.8431 - val_loss: 0.7420 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2570 - acc: 0.843 - 0s 353us/step - loss: 0.2604 - acc: 0.8431 - val_loss: 0.7433 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2561 - acc: 0.8431 - val_loss: 0.7460 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2526 - acc: 0.8431 - val_loss: 0.7458 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2481 - acc: 0.8627 - val_loss: 0.7456 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.2437 - acc: 0.8627 - val_loss: 0.7454 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2398 - acc: 0.8627 - val_loss: 0.7450 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2360 - acc: 0.8627 - val_loss: 0.7459 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2305 - acc: 0.9020 - val_loss: 0.7468 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.2267 - acc: 0.9020 - val_loss: 0.7493 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2231 - acc: 0.9216 - val_loss: 0.7532 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2195 - acc: 0.9216 - val_loss: 0.7555 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2158 - acc: 0.9216 - val_loss: 0.7578 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2134 - acc: 0.9216 - val_loss: 0.7592 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2093 - acc: 0.9216 - val_loss: 0.7608 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2052 - acc: 0.9216 - val_loss: 0.7619 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2017 - acc: 0.9216 - val_loss: 0.7663 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1994 - acc: 0.9216 - val_loss: 0.7677 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.1953 - acc: 0.9412 - val_loss: 0.7716 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1934 - acc: 0.9412 - val_loss: 0.7753 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1895 - acc: 0.9412 - val_loss: 0.7785 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1871 - acc: 0.9412 - val_loss: 0.7808 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1834 - acc: 0.9608 - val_loss: 0.7870 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1805 - acc: 0.9608 - val_loss: 0.7914 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1784 - acc: 0.9608 - val_loss: 0.7957 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1746 - acc: 0.9608 - val_loss: 0.8034 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1717 - acc: 0.9608 - val_loss: 0.8067 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1688 - acc: 0.9608 - val_loss: 0.8076 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1658 - acc: 0.9608 - val_loss: 0.8144 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1641 - acc: 0.9608 - val_loss: 0.8183 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1606 - acc: 0.9608 - val_loss: 0.8188 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1589 - acc: 0.9804 - val_loss: 0.8278 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 210us/step - loss: 0.1556 - acc: 0.9804 - val_loss: 0.8269 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1528 - acc: 0.9804 - val_loss: 0.8329 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1505 - acc: 0.9804 - val_loss: 0.8327 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1482 - acc: 0.9804 - val_loss: 0.8420 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.1463 - acc: 0.9804 - val_loss: 0.8464 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1440 - acc: 0.9804 - val_loss: 0.8503 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1421 - acc: 0.9804 - val_loss: 0.8516 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1388 - acc: 0.9804 - val_loss: 0.8572 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1388 - acc: 0.9804 - val_loss: 0.8584 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1353 - acc: 0.9804 - val_loss: 0.8670 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1328 - acc: 0.9804 - val_loss: 0.8714 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1312 - acc: 0.9804 - val_loss: 0.8748 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1290 - acc: 0.9804 - val_loss: 0.8793 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1274 - acc: 0.9804 - val_loss: 0.8901 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1248 - acc: 0.9804 - val_loss: 0.8951 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1237 - acc: 0.9804 - val_loss: 0.8979 - val_acc: 0.7000\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 255us/step - loss: 0.1217 - acc: 0.9804 - val_loss: 0.9005 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1197 - acc: 0.9804 - val_loss: 0.9116 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1179 - acc: 0.9804 - val_loss: 0.9161 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 345us/step - loss: 0.1164 - acc: 0.9804 - val_loss: 0.9179 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1156 - acc: 0.9804 - val_loss: 0.9322 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1129 - acc: 0.9804 - val_loss: 0.9391 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1114 - acc: 0.9804 - val_loss: 0.9405 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1095 - acc: 0.9804 - val_loss: 0.9506 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1082 - acc: 0.9804 - val_loss: 0.9545 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1064 - acc: 0.9804 - val_loss: 0.9568 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1045 - acc: 0.9804 - val_loss: 0.9609 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.1035 - acc: 0.9804 - val_loss: 0.9681 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 361us/step - loss: 0.1014 - acc: 0.9804 - val_loss: 0.9801 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1001 - acc: 0.9804 - val_loss: 0.9866 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0995 - acc: 0.9804 - val_loss: 0.9849 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0969 - acc: 0.9804 - val_loss: 0.9930 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0958 - acc: 0.9804 - val_loss: 1.0033 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.0944 - acc: 0.9804 - val_loss: 1.0049 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.0943 - acc: 0.9804 - val_loss: 1.0068 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.0917 - acc: 0.9804 - val_loss: 1.0093 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.0909 - acc: 0.9804 - val_loss: 1.0173 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0895 - acc: 1.0000 - val_loss: 1.0176 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0877 - acc: 1.0000 - val_loss: 1.0279 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.0869 - acc: 0.9804 - val_loss: 1.0381 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0854 - acc: 1.0000 - val_loss: 1.0530 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0847 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1071 - acc: 1.000 - 0s 412us/step - loss: 0.0829 - acc: 1.0000 - val_loss: 1.0653 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.0823 - acc: 1.0000 - val_loss: 1.0742 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0808 - acc: 1.0000 - val_loss: 1.0775 - val_acc: 0.7000\n",
      "2016-10-24\n",
      "2016-10-25\n",
      "2016-10-26\n",
      "2016-10-27\n",
      "2016-10-28\n",
      "2016-10-31\n",
      "2016-11-01\n",
      "2016-11-02\n",
      "2016-11-03\n",
      "2016-11-04\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.4680 - acc: 0.8824 - val_loss: 1.0658 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4329 - acc: 0.8824 - val_loss: 1.0660 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4083 - acc: 0.9020 - val_loss: 1.0664 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3900 - acc: 0.9020 - val_loss: 1.0665 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3708 - acc: 0.9216 - val_loss: 1.0671 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3581 - acc: 0.9216 - val_loss: 1.0687 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3482 - acc: 0.9020 - val_loss: 1.0694 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3324 - acc: 0.9216 - val_loss: 1.0703 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3216 - acc: 0.9216 - val_loss: 1.0715 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3123 - acc: 0.9216 - val_loss: 1.0722 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3026 - acc: 0.9216 - val_loss: 1.0733 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2940 - acc: 0.9608 - val_loss: 1.0745 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2861 - acc: 0.9608 - val_loss: 1.0759 - val_acc: 0.6000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2778 - acc: 0.9608 - val_loss: 1.0766 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2699 - acc: 0.9608 - val_loss: 1.0778 - val_acc: 0.6000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2631 - acc: 0.9608 - val_loss: 1.0786 - val_acc: 0.6000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2561 - acc: 0.9608 - val_loss: 1.0798 - val_acc: 0.6000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2501 - acc: 0.9608 - val_loss: 1.0804 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.2434 - acc: 0.9608 - val_loss: 1.0805 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 332us/step - loss: 0.2382 - acc: 0.9608 - val_loss: 1.0814 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2332 - acc: 0.9608 - val_loss: 1.0829 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2293 - acc: 0.9608 - val_loss: 1.0845 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2247 - acc: 0.9608 - val_loss: 1.0857 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2203 - acc: 0.9608 - val_loss: 1.0870 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 247us/step - loss: 0.2163 - acc: 0.9608 - val_loss: 1.0890 - val_acc: 0.6000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2132 - acc: 0.9608 - val_loss: 1.0909 - val_acc: 0.6000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2102 - acc: 0.9608 - val_loss: 1.0935 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2046 - acc: 0.9608 - val_loss: 1.0956 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2011 - acc: 0.9608 - val_loss: 1.0987 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.1977 - acc: 0.9608 - val_loss: 1.1012 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1946 - acc: 0.9608 - val_loss: 1.1038 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1922 - acc: 0.9608 - val_loss: 1.1063 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1908 - acc: 0.9608 - val_loss: 1.1108 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1875 - acc: 0.9608 - val_loss: 1.1133 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0693 - acc: 1.000 - 0s 373us/step - loss: 0.1865 - acc: 0.9608 - val_loss: 1.1154 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1816 - acc: 0.9608 - val_loss: 1.1189 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1795 - acc: 0.9608 - val_loss: 1.1199 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1774 - acc: 0.9608 - val_loss: 1.1234 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1758 - acc: 0.9804 - val_loss: 1.1253 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.1734 - acc: 0.9804 - val_loss: 1.1277 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1711 - acc: 0.9804 - val_loss: 1.1310 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 312us/step - loss: 0.1686 - acc: 0.9804 - val_loss: 1.1342 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.1659 - acc: 0.9804 - val_loss: 1.1351 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1653 - acc: 0.9804 - val_loss: 1.1376 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.1632 - acc: 0.9804 - val_loss: 1.1402 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1618 - acc: 0.9804 - val_loss: 1.1433 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1591 - acc: 0.9804 - val_loss: 1.1432 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0616 - acc: 1.000 - 0s 196us/step - loss: 0.1586 - acc: 0.9804 - val_loss: 1.1465 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2080 - acc: 0.968 - 0s 275us/step - loss: 0.1570 - acc: 0.9804 - val_loss: 1.1484 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.1555 - acc: 0.9804 - val_loss: 1.1507 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.1540 - acc: 0.9804 - val_loss: 1.1502 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1541 - acc: 0.9804 - val_loss: 1.1514 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1520 - acc: 0.9804 - val_loss: 1.1544 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1508 - acc: 0.9804 - val_loss: 1.1563 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1501 - acc: 0.9804 - val_loss: 1.1552 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 330us/step - loss: 0.1489 - acc: 0.9804 - val_loss: 1.1583 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1487 - acc: 0.9804 - val_loss: 1.1585 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1857 - acc: 0.968 - 0s 412us/step - loss: 0.1478 - acc: 0.9804 - val_loss: 1.1601 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1462 - acc: 0.9804 - val_loss: 1.1633 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1459 - acc: 0.9804 - val_loss: 1.1645 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1443 - acc: 0.9804 - val_loss: 1.1670 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1437 - acc: 0.9804 - val_loss: 1.1702 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1415 - acc: 0.9804 - val_loss: 1.1685 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1407 - acc: 0.9804 - val_loss: 1.1699 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1405 - acc: 0.9804 - val_loss: 1.1720 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1388 - acc: 0.9804 - val_loss: 1.1731 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1384 - acc: 0.9804 - val_loss: 1.1756 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1368 - acc: 0.9804 - val_loss: 1.1776 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1359 - acc: 0.9804 - val_loss: 1.1801 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1658 - acc: 0.968 - 0s 157us/step - loss: 0.1359 - acc: 0.9804 - val_loss: 1.1810 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1344 - acc: 0.9804 - val_loss: 1.1841 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1345 - acc: 0.9804 - val_loss: 1.1857 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1328 - acc: 0.9804 - val_loss: 1.1853 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1318 - acc: 0.9804 - val_loss: 1.1870 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.1310 - acc: 0.9804 - val_loss: 1.1879 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1303 - acc: 0.9804 - val_loss: 1.1909 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1293 - acc: 0.9804 - val_loss: 1.1935 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1292 - acc: 0.9804 - val_loss: 1.1961 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1275 - acc: 0.9804 - val_loss: 1.1958 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1273 - acc: 0.9804 - val_loss: 1.1977 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 363us/step - loss: 0.1264 - acc: 0.9804 - val_loss: 1.1986 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1262 - acc: 0.9804 - val_loss: 1.1995 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1244 - acc: 0.9804 - val_loss: 1.2016 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.1257 - acc: 0.9804 - val_loss: 1.2041 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1231 - acc: 0.9804 - val_loss: 1.2064 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1224 - acc: 0.9804 - val_loss: 1.2074 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1216 - acc: 0.9804 - val_loss: 1.2094 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1208 - acc: 0.9804 - val_loss: 1.2116 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1206 - acc: 0.9804 - val_loss: 1.2132 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1196 - acc: 0.9804 - val_loss: 1.2162 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1200 - acc: 0.9804 - val_loss: 1.2195 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1181 - acc: 0.9804 - val_loss: 1.2221 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1172 - acc: 0.9804 - val_loss: 1.2200 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1166 - acc: 0.9804 - val_loss: 1.2214 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1162 - acc: 0.9804 - val_loss: 1.2221 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1149 - acc: 0.9804 - val_loss: 1.2226 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1150 - acc: 0.9804 - val_loss: 1.2221 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1137 - acc: 0.9804 - val_loss: 1.2234 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1138 - acc: 0.9804 - val_loss: 1.2258 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1124 - acc: 0.9804 - val_loss: 1.2261 - val_acc: 0.8000\n",
      "2016-11-07\n",
      "2016-11-08\n",
      "2016-11-09\n",
      "2016-11-10\n",
      "2016-11-11\n",
      "2016-11-14\n",
      "2016-11-15\n",
      "2016-11-16\n",
      "2016-11-17\n",
      "2016-11-18\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.6469 - acc: 0.7647 - val_loss: 0.1427 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6088 - acc: 0.8039 - val_loss: 0.1369 - val_acc: 0.9000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5865 - acc: 0.8039 - val_loss: 0.1296 - val_acc: 0.9000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 304us/step - loss: 0.5688 - acc: 0.8039 - val_loss: 0.1251 - val_acc: 0.9000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5540 - acc: 0.8039 - val_loss: 0.1196 - val_acc: 0.9000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5400 - acc: 0.8039 - val_loss: 0.1135 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5246 - acc: 0.8039 - val_loss: 0.1092 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5119 - acc: 0.8039 - val_loss: 0.1043 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5009 - acc: 0.8039 - val_loss: 0.1014 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4902 - acc: 0.8039 - val_loss: 0.0971 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4804 - acc: 0.8039 - val_loss: 0.0957 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4706 - acc: 0.8039 - val_loss: 0.0921 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4620 - acc: 0.8431 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4532 - acc: 0.8431 - val_loss: 0.0868 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4446 - acc: 0.8431 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4366 - acc: 0.8431 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4303 - acc: 0.8627 - val_loss: 0.0799 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4230 - acc: 0.8627 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4152 - acc: 0.8824 - val_loss: 0.0752 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4091 - acc: 0.8824 - val_loss: 0.0742 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4033 - acc: 0.8824 - val_loss: 0.0738 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3955 - acc: 0.9020 - val_loss: 0.0711 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3890 - acc: 0.9020 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3830 - acc: 0.9020 - val_loss: 0.0686 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.3780 - acc: 0.9020 - val_loss: 0.0673 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3726 - acc: 0.9020 - val_loss: 0.0661 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3680 - acc: 0.9020 - val_loss: 0.0652 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3623 - acc: 0.9020 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3588 - acc: 0.9020 - val_loss: 0.0655 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3538 - acc: 0.9020 - val_loss: 0.0647 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3494 - acc: 0.9020 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3453 - acc: 0.9020 - val_loss: 0.0643 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 0.3407 - acc: 0.9020 - val_loss: 0.0626 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 266us/step - loss: 0.3356 - acc: 0.9020 - val_loss: 0.0626 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3321 - acc: 0.9020 - val_loss: 0.0621 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3279 - acc: 0.9020 - val_loss: 0.0625 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3249 - acc: 0.9020 - val_loss: 0.0640 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3204 - acc: 0.9020 - val_loss: 0.0632 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3170 - acc: 0.9020 - val_loss: 0.0632 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3139 - acc: 0.9020 - val_loss: 0.0635 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3094 - acc: 0.9020 - val_loss: 0.0639 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3068 - acc: 0.9020 - val_loss: 0.0647 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3041 - acc: 0.9020 - val_loss: 0.0641 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3017 - acc: 0.9216 - val_loss: 0.0664 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2977 - acc: 0.9216 - val_loss: 0.0659 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2941 - acc: 0.9216 - val_loss: 0.0655 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2912 - acc: 0.9412 - val_loss: 0.0660 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2892 - acc: 0.9412 - val_loss: 0.0660 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2858 - acc: 0.9412 - val_loss: 0.0665 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2827 - acc: 0.9412 - val_loss: 0.0677 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2800 - acc: 0.9412 - val_loss: 0.0699 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2774 - acc: 0.9412 - val_loss: 0.0719 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2752 - acc: 0.9412 - val_loss: 0.0739 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2718 - acc: 0.9412 - val_loss: 0.0735 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2684 - acc: 0.9412 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2658 - acc: 0.9412 - val_loss: 0.0775 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 201us/step - loss: 0.2634 - acc: 0.9412 - val_loss: 0.0806 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2598 - acc: 0.9412 - val_loss: 0.0824 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3271 - acc: 0.937 - 0s 215us/step - loss: 0.2579 - acc: 0.9412 - val_loss: 0.0840 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2552 - acc: 0.9412 - val_loss: 0.0868 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2522 - acc: 0.9412 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2497 - acc: 0.9412 - val_loss: 0.0901 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 242us/step - loss: 0.2471 - acc: 0.9412 - val_loss: 0.0933 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2445 - acc: 0.9412 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2417 - acc: 0.9412 - val_loss: 0.0971 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.2389 - acc: 0.9412 - val_loss: 0.0980 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.2370 - acc: 0.9412 - val_loss: 0.0988 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2346 - acc: 0.9412 - val_loss: 0.0990 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2328 - acc: 0.9412 - val_loss: 0.1023 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2307 - acc: 0.9412 - val_loss: 0.1052 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 0.2277 - acc: 0.9412 - val_loss: 0.1079 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2256 - acc: 0.9412 - val_loss: 0.1117 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2226 - acc: 0.9412 - val_loss: 0.1141 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2213 - acc: 0.9412 - val_loss: 0.1173 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2180 - acc: 0.9412 - val_loss: 0.1185 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 189us/step - loss: 0.2160 - acc: 0.9608 - val_loss: 0.1216 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2135 - acc: 0.9608 - val_loss: 0.1217 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2113 - acc: 0.9608 - val_loss: 0.1225 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2094 - acc: 0.9608 - val_loss: 0.1236 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2085 - acc: 0.9608 - val_loss: 0.1235 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2059 - acc: 0.9608 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2035 - acc: 0.9608 - val_loss: 0.1313 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2016 - acc: 0.9608 - val_loss: 0.1339 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2008 - acc: 0.9608 - val_loss: 0.1404 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1984 - acc: 0.9608 - val_loss: 0.1452 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1967 - acc: 0.9608 - val_loss: 0.1480 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1948 - acc: 0.9608 - val_loss: 0.1523 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.1923 - acc: 0.9608 - val_loss: 0.1551 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1912 - acc: 0.9608 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1902 - acc: 0.9608 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1875 - acc: 0.9608 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1855 - acc: 0.9608 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1838 - acc: 0.9608 - val_loss: 0.1757 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1822 - acc: 0.9608 - val_loss: 0.1814 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1814 - acc: 0.9608 - val_loss: 0.1867 - val_acc: 0.9000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1788 - acc: 0.9608 - val_loss: 0.1923 - val_acc: 0.9000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1771 - acc: 0.9804 - val_loss: 0.1960 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1751 - acc: 0.9804 - val_loss: 0.1995 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1738 - acc: 0.9804 - val_loss: 0.2071 - val_acc: 0.9000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1723 - acc: 0.9804 - val_loss: 0.2053 - val_acc: 0.9000\n",
      "2016-11-21\n",
      "2016-11-22\n",
      "2016-11-23\n",
      "2016-11-24\n",
      "2016-11-25\n",
      "2016-11-28\n",
      "2016-11-29\n",
      "2016-11-30\n",
      "2016-12-01\n",
      "2016-12-02\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.5821 - acc: 0.8235 - val_loss: 6.2260 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 550us/step - loss: 0.5353 - acc: 0.8235 - val_loss: 6.3242 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5033 - acc: 0.8431 - val_loss: 6.4270 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4775 - acc: 0.8431 - val_loss: 6.4919 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4558 - acc: 0.8431 - val_loss: 6.5580 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4367 - acc: 0.8431 - val_loss: 6.6221 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4188 - acc: 0.8627 - val_loss: 6.6726 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4021 - acc: 0.8627 - val_loss: 6.7349 - val_acc: 0.2000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3865 - acc: 0.8627 - val_loss: 6.7956 - val_acc: 0.2000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3719 - acc: 0.8627 - val_loss: 6.8531 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3578 - acc: 0.8627 - val_loss: 6.9123 - val_acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3435 - acc: 0.8627 - val_loss: 6.9711 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 276us/step - loss: 0.3313 - acc: 0.8627 - val_loss: 7.0066 - val_acc: 0.2000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3219 - acc: 0.8627 - val_loss: 7.0448 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3119 - acc: 0.8627 - val_loss: 7.1003 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3011 - acc: 0.8627 - val_loss: 7.1324 - val_acc: 0.2000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2930 - acc: 0.8627 - val_loss: 7.1672 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2851 - acc: 0.8627 - val_loss: 7.2064 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2756 - acc: 0.8824 - val_loss: 7.2344 - val_acc: 0.2000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2686 - acc: 0.8824 - val_loss: 7.2611 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2620 - acc: 0.8824 - val_loss: 7.2965 - val_acc: 0.2000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2539 - acc: 0.8824 - val_loss: 7.3273 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2484 - acc: 0.9020 - val_loss: 7.3568 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2421 - acc: 0.9020 - val_loss: 7.3877 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2359 - acc: 0.9020 - val_loss: 7.4163 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2306 - acc: 0.9020 - val_loss: 7.4456 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2251 - acc: 0.9020 - val_loss: 7.4748 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2208 - acc: 0.9020 - val_loss: 7.4913 - val_acc: 0.2000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2173 - acc: 0.9020 - val_loss: 7.5230 - val_acc: 0.2000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2129 - acc: 0.9216 - val_loss: 7.5368 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2090 - acc: 0.9412 - val_loss: 7.5544 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2054 - acc: 0.9412 - val_loss: 7.5765 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2025 - acc: 0.9412 - val_loss: 7.5951 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2000 - acc: 0.9412 - val_loss: 7.6192 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1979 - acc: 0.9412 - val_loss: 7.6446 - val_acc: 0.2000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1784 - acc: 0.937 - 0s 216us/step - loss: 0.1963 - acc: 0.9412 - val_loss: 7.6479 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1935 - acc: 0.9412 - val_loss: 7.6605 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1919 - acc: 0.9412 - val_loss: 7.6719 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1900 - acc: 0.9412 - val_loss: 7.6992 - val_acc: 0.2000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1878 - acc: 0.9412 - val_loss: 7.7207 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1864 - acc: 0.9412 - val_loss: 7.7237 - val_acc: 0.2000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1860 - acc: 0.9412 - val_loss: 7.7223 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1844 - acc: 0.9412 - val_loss: 7.7421 - val_acc: 0.2000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1822 - acc: 0.9412 - val_loss: 7.7580 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1810 - acc: 0.9412 - val_loss: 7.7661 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1804 - acc: 0.9412 - val_loss: 7.7700 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1794 - acc: 0.9412 - val_loss: 7.7889 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1777 - acc: 0.9412 - val_loss: 7.8028 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1762 - acc: 0.9412 - val_loss: 7.8184 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.1754 - acc: 0.9412 - val_loss: 7.8389 - val_acc: 0.2000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1735 - acc: 0.9412 - val_loss: 7.8472 - val_acc: 0.2000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1722 - acc: 0.9412 - val_loss: 7.8671 - val_acc: 0.2000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1717 - acc: 0.9412 - val_loss: 7.8887 - val_acc: 0.2000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 251us/step - loss: 0.1703 - acc: 0.9412 - val_loss: 7.9025 - val_acc: 0.2000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1703 - acc: 0.9412 - val_loss: 7.9014 - val_acc: 0.2000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1681 - acc: 0.9412 - val_loss: 7.9139 - val_acc: 0.2000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1685 - acc: 0.9412 - val_loss: 7.9395 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1669 - acc: 0.9412 - val_loss: 7.9563 - val_acc: 0.2000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 0.1654 - acc: 0.9608 - val_loss: 7.9597 - val_acc: 0.2000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1641 - acc: 0.9608 - val_loss: 7.9626 - val_acc: 0.2000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1638 - acc: 0.9608 - val_loss: 7.9687 - val_acc: 0.2000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1621 - acc: 0.9608 - val_loss: 7.9767 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1614 - acc: 0.9608 - val_loss: 7.9926 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1608 - acc: 0.9608 - val_loss: 8.0214 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1598 - acc: 0.9608 - val_loss: 8.0244 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1582 - acc: 0.9608 - val_loss: 8.0346 - val_acc: 0.2000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1950 - acc: 0.937 - 0s 196us/step - loss: 0.1576 - acc: 0.9608 - val_loss: 8.0314 - val_acc: 0.2000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1567 - acc: 0.9608 - val_loss: 8.0529 - val_acc: 0.2000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1556 - acc: 0.9608 - val_loss: 8.0611 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1549 - acc: 0.9608 - val_loss: 8.0660 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1532 - acc: 0.9608 - val_loss: 8.0659 - val_acc: 0.2000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1524 - acc: 0.9608 - val_loss: 8.0773 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1516 - acc: 0.9608 - val_loss: 8.0798 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1509 - acc: 0.9608 - val_loss: 8.1099 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1499 - acc: 0.9608 - val_loss: 8.1110 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1487 - acc: 0.9608 - val_loss: 8.1221 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1476 - acc: 0.9608 - val_loss: 8.1507 - val_acc: 0.2000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1476 - acc: 0.9608 - val_loss: 8.1667 - val_acc: 0.2000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1460 - acc: 0.9608 - val_loss: 8.1702 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1448 - acc: 0.9608 - val_loss: 8.1887 - val_acc: 0.2000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1439 - acc: 0.9608 - val_loss: 8.2083 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 648us/step - loss: 0.1429 - acc: 0.9608 - val_loss: 8.2165 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1418 - acc: 0.9608 - val_loss: 8.2359 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1411 - acc: 0.9608 - val_loss: 8.2442 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1402 - acc: 0.9608 - val_loss: 8.2500 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1390 - acc: 0.9608 - val_loss: 8.2740 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1383 - acc: 0.9608 - val_loss: 8.2793 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1371 - acc: 0.9608 - val_loss: 8.2970 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1360 - acc: 0.9608 - val_loss: 8.3151 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1354 - acc: 0.9608 - val_loss: 8.3085 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1343 - acc: 0.9608 - val_loss: 8.3261 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1336 - acc: 0.9608 - val_loss: 8.3532 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.1329 - acc: 0.9608 - val_loss: 8.3802 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1316 - acc: 0.9608 - val_loss: 8.3868 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1306 - acc: 0.9608 - val_loss: 8.4006 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1299 - acc: 0.9608 - val_loss: 8.4186 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1290 - acc: 0.9608 - val_loss: 8.4539 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1266 - acc: 0.968 - 0s 176us/step - loss: 0.1280 - acc: 0.9608 - val_loss: 8.4677 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1281 - acc: 0.9608 - val_loss: 8.4935 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1262 - acc: 0.9608 - val_loss: 8.5032 - val_acc: 0.2000\n",
      "2016-12-05\n",
      "2016-12-06\n",
      "2016-12-07\n",
      "2016-12-08\n",
      "2016-12-09\n",
      "2016-12-12\n",
      "2016-12-13\n",
      "2016-12-14\n",
      "2016-12-15\n",
      "2016-12-16\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.8482 - acc: 0.1961 - val_loss: 1.3443 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 3.6913 - acc: 0.2157 - val_loss: 1.3599 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 3.5783 - acc: 0.2353 - val_loss: 1.3672 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 3.4854 - acc: 0.2353 - val_loss: 1.3768 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 3.3993 - acc: 0.2353 - val_loss: 1.3900 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 3.3210 - acc: 0.2353 - val_loss: 1.4009 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 3.2507 - acc: 0.2353 - val_loss: 1.4082 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 3.1874 - acc: 0.2549 - val_loss: 1.4227 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 3.1262 - acc: 0.2549 - val_loss: 1.4382 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 3.0671 - acc: 0.2941 - val_loss: 1.4508 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 3.0110 - acc: 0.2941 - val_loss: 1.4614 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.9579 - acc: 0.2941 - val_loss: 1.4727 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 2.9064 - acc: 0.2941 - val_loss: 1.4802 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.8534 - acc: 0.2941 - val_loss: 1.4923 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.8036 - acc: 0.2941 - val_loss: 1.5013 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 2.7553 - acc: 0.3137 - val_loss: 1.5112 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.7083 - acc: 0.3137 - val_loss: 1.5307 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 2.6601 - acc: 0.3137 - val_loss: 1.5523 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 2.6104 - acc: 0.3137 - val_loss: 1.5632 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 2.5660 - acc: 0.3137 - val_loss: 1.5721 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.5207 - acc: 0.3137 - val_loss: 1.5904 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 2.4750 - acc: 0.3137 - val_loss: 1.6108 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.4336 - acc: 0.3137 - val_loss: 1.6192 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 2.3934 - acc: 0.3137 - val_loss: 1.6305 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.3517 - acc: 0.3137 - val_loss: 1.6482 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.3108 - acc: 0.3137 - val_loss: 1.6594 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 2.2759 - acc: 0.3333 - val_loss: 1.6693 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 2.2410 - acc: 0.3333 - val_loss: 1.6801 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 2.0442 - acc: 0.343 - 0s 157us/step - loss: 2.2051 - acc: 0.3333 - val_loss: 1.6968 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 2.1698 - acc: 0.3333 - val_loss: 1.7066 - val_acc: 0.7000\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 275us/step - loss: 2.1354 - acc: 0.3333 - val_loss: 1.7192 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 2.0990 - acc: 0.3333 - val_loss: 1.7330 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 2.0644 - acc: 0.3333 - val_loss: 1.7414 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.0308 - acc: 0.3333 - val_loss: 1.7498 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.9968 - acc: 0.3333 - val_loss: 1.7570 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.9604 - acc: 0.3333 - val_loss: 1.7639 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.9276 - acc: 0.3333 - val_loss: 1.7717 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.8945 - acc: 0.3333 - val_loss: 1.7847 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.8627 - acc: 0.3333 - val_loss: 1.7963 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.8310 - acc: 0.3333 - val_loss: 1.8063 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.8011 - acc: 0.3333 - val_loss: 1.8211 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.7722 - acc: 0.3333 - val_loss: 1.8309 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.7483 - acc: 0.3333 - val_loss: 1.8374 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.7211 - acc: 0.3333 - val_loss: 1.8529 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.6945 - acc: 0.3333 - val_loss: 1.8633 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.8960 - acc: 0.312 - 0s 236us/step - loss: 1.6687 - acc: 0.3333 - val_loss: 1.8749 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.6433 - acc: 0.3529 - val_loss: 1.8797 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.6173 - acc: 0.3333 - val_loss: 1.8889 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5920 - acc: 0.3529 - val_loss: 1.9031 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.5659 - acc: 0.3529 - val_loss: 1.9142 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.5413 - acc: 0.3725 - val_loss: 1.9183 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 261us/step - loss: 1.5163 - acc: 0.3725 - val_loss: 1.9211 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.4922 - acc: 0.3725 - val_loss: 1.9258 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.5614 - acc: 0.281 - 0s 196us/step - loss: 1.4682 - acc: 0.3725 - val_loss: 1.9287 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.4465 - acc: 0.3725 - val_loss: 1.9372 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.4240 - acc: 0.3725 - val_loss: 1.9424 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.4036 - acc: 0.3725 - val_loss: 1.9479 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.3818 - acc: 0.3725 - val_loss: 1.9567 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.3609 - acc: 0.3725 - val_loss: 1.9657 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.3397 - acc: 0.3725 - val_loss: 1.9729 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 288us/step - loss: 1.3188 - acc: 0.3725 - val_loss: 1.9773 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.2989 - acc: 0.3725 - val_loss: 1.9874 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.3110 - acc: 0.406 - 0s 196us/step - loss: 1.2787 - acc: 0.3725 - val_loss: 1.9923 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.2579 - acc: 0.3725 - val_loss: 1.9931 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.2363 - acc: 0.3725 - val_loss: 2.0016 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.2156 - acc: 0.3725 - val_loss: 2.0132 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1965 - acc: 0.3922 - val_loss: 2.0210 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 1.1781 - acc: 0.3922 - val_loss: 2.0298 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1599 - acc: 0.3922 - val_loss: 2.0337 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.1451 - acc: 0.3922 - val_loss: 2.0358 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 178us/step - loss: 1.1295 - acc: 0.3922 - val_loss: 2.0392 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1141 - acc: 0.3922 - val_loss: 2.0397 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0979 - acc: 0.3922 - val_loss: 2.0425 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0812 - acc: 0.3922 - val_loss: 2.0460 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0664 - acc: 0.3922 - val_loss: 2.0483 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.0521 - acc: 0.3922 - val_loss: 2.0505 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 178us/step - loss: 1.0373 - acc: 0.3922 - val_loss: 2.0559 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.0227 - acc: 0.3922 - val_loss: 2.0609 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0085 - acc: 0.3922 - val_loss: 2.0643 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.9943 - acc: 0.3922 - val_loss: 2.0687 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9811 - acc: 0.4118 - val_loss: 2.0728 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.9668 - acc: 0.4510 - val_loss: 2.0755 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.9544 - acc: 0.4510 - val_loss: 2.0804 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9418 - acc: 0.4510 - val_loss: 2.0871 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.9302 - acc: 0.4510 - val_loss: 2.0899 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.9187 - acc: 0.4706 - val_loss: 2.0954 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9072 - acc: 0.4706 - val_loss: 2.0990 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8947 - acc: 0.4706 - val_loss: 2.1046 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8832 - acc: 0.4706 - val_loss: 2.1106 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8728 - acc: 0.4706 - val_loss: 2.1175 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8618 - acc: 0.4706 - val_loss: 2.1214 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8516 - acc: 0.4706 - val_loss: 2.1255 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.8410 - acc: 0.4706 - val_loss: 2.1297 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 647us/step - loss: 0.8305 - acc: 0.4706 - val_loss: 2.1358 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.8212 - acc: 0.4706 - val_loss: 2.1424 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8118 - acc: 0.4706 - val_loss: 2.1513 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.8030 - acc: 0.4706 - val_loss: 2.1604 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7943 - acc: 0.4706 - val_loss: 2.1689 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7860 - acc: 0.4902 - val_loss: 2.1758 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.7771 - acc: 0.4902 - val_loss: 2.1796 - val_acc: 0.8000\n",
      "2016-12-19\n",
      "2016-12-20\n",
      "2016-12-21\n",
      "2016-12-22\n",
      "2016-12-23\n",
      "2016-12-26\n",
      "2016-12-27\n",
      "2016-12-28\n",
      "2016-12-29\n",
      "2016-12-30\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.9395 - acc: 0.6078 - val_loss: 4.7638 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.9182 - acc: 0.6275 - val_loss: 4.7287 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.9013 - acc: 0.6471 - val_loss: 4.6975 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8868 - acc: 0.7059 - val_loss: 4.6813 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.8777 - acc: 0.7059 - val_loss: 4.6542 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8659 - acc: 0.7059 - val_loss: 4.6285 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8729 - acc: 0.781 - 0s 216us/step - loss: 0.8567 - acc: 0.7059 - val_loss: 4.6056 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8500 - acc: 0.7059 - val_loss: 4.5790 - val_acc: 0.2000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8411 - acc: 0.7059 - val_loss: 4.5756 - val_acc: 0.2000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8341 - acc: 0.7059 - val_loss: 4.5693 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8275 - acc: 0.7059 - val_loss: 4.5460 - val_acc: 0.2000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.8201 - acc: 0.7059 - val_loss: 4.5339 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8148 - acc: 0.7059 - val_loss: 4.5090 - val_acc: 0.2000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.8072 - acc: 0.7059 - val_loss: 4.4984 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8020 - acc: 0.7059 - val_loss: 4.4899 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7976 - acc: 0.7059 - val_loss: 4.4628 - val_acc: 0.2000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7891 - acc: 0.7059 - val_loss: 4.4502 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7837 - acc: 0.7059 - val_loss: 4.4425 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7790 - acc: 0.7059 - val_loss: 4.4174 - val_acc: 0.2000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7712 - acc: 0.7059 - val_loss: 4.4072 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7654 - acc: 0.7059 - val_loss: 4.3983 - val_acc: 0.2000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.7602 - acc: 0.7059 - val_loss: 4.3837 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.7526 - acc: 0.7059 - val_loss: 4.3794 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7462 - acc: 0.7059 - val_loss: 4.3599 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7385 - acc: 0.7059 - val_loss: 4.3524 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.7345 - acc: 0.7059 - val_loss: 4.3519 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 286us/step - loss: 0.7283 - acc: 0.7059 - val_loss: 4.3296 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7210 - acc: 0.7059 - val_loss: 4.3275 - val_acc: 0.2000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7159 - acc: 0.7255 - val_loss: 4.3217 - val_acc: 0.2000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7107 - acc: 0.7255 - val_loss: 4.3050 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7043 - acc: 0.7255 - val_loss: 4.3012 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6989 - acc: 0.7255 - val_loss: 4.2834 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6925 - acc: 0.7255 - val_loss: 4.2774 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6877 - acc: 0.7255 - val_loss: 4.2724 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6836 - acc: 0.7255 - val_loss: 4.2535 - val_acc: 0.2000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 193us/step - loss: 0.6778 - acc: 0.7255 - val_loss: 4.2328 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6713 - acc: 0.7255 - val_loss: 4.2300 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6664 - acc: 0.7255 - val_loss: 4.2270 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6617 - acc: 0.7255 - val_loss: 4.2177 - val_acc: 0.2000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6570 - acc: 0.7255 - val_loss: 4.2005 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6515 - acc: 0.7255 - val_loss: 4.1815 - val_acc: 0.2000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6453 - acc: 0.7255 - val_loss: 4.1664 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.6394 - acc: 0.7255 - val_loss: 4.1607 - val_acc: 0.2000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6348 - acc: 0.7255 - val_loss: 4.1586 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6312 - acc: 0.7451 - val_loss: 4.1406 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6251 - acc: 0.7451 - val_loss: 4.1243 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6192 - acc: 0.7451 - val_loss: 4.1171 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6159 - acc: 0.7451 - val_loss: 4.0996 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6098 - acc: 0.7451 - val_loss: 4.0941 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.6054 - acc: 0.7451 - val_loss: 4.0896 - val_acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6007 - acc: 0.7451 - val_loss: 4.0837 - val_acc: 0.2000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5967 - acc: 0.7451 - val_loss: 4.0824 - val_acc: 0.2000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5927 - acc: 0.7451 - val_loss: 4.0754 - val_acc: 0.2000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5881 - acc: 0.7451 - val_loss: 4.0551 - val_acc: 0.2000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5815 - acc: 0.7451 - val_loss: 4.0497 - val_acc: 0.2000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5769 - acc: 0.7647 - val_loss: 4.0461 - val_acc: 0.2000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5737 - acc: 0.7647 - val_loss: 4.0247 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 377us/step - loss: 0.5670 - acc: 0.7647 - val_loss: 4.0237 - val_acc: 0.2000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5625 - acc: 0.7647 - val_loss: 4.0203 - val_acc: 0.2000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5592 - acc: 0.7647 - val_loss: 4.0009 - val_acc: 0.2000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5531 - acc: 0.7647 - val_loss: 3.9873 - val_acc: 0.2000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 117us/step - loss: 0.5484 - acc: 0.7647 - val_loss: 3.9831 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5443 - acc: 0.7647 - val_loss: 3.9802 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5405 - acc: 0.7647 - val_loss: 3.9642 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5353 - acc: 0.7647 - val_loss: 3.9588 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5322 - acc: 0.7647 - val_loss: 3.9572 - val_acc: 0.2000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5286 - acc: 0.7647 - val_loss: 3.9530 - val_acc: 0.2000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5252 - acc: 0.7647 - val_loss: 3.9466 - val_acc: 0.2000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5218 - acc: 0.7647 - val_loss: 3.9374 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5182 - acc: 0.7647 - val_loss: 3.9266 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5146 - acc: 0.7647 - val_loss: 3.9129 - val_acc: 0.2000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5115 - acc: 0.7647 - val_loss: 3.9037 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5078 - acc: 0.7647 - val_loss: 3.8948 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5042 - acc: 0.7647 - val_loss: 3.8861 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5009 - acc: 0.7647 - val_loss: 3.8756 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4988 - acc: 0.7647 - val_loss: 3.8500 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4941 - acc: 0.7647 - val_loss: 3.8465 - val_acc: 0.2000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4908 - acc: 0.7647 - val_loss: 3.8423 - val_acc: 0.2000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4881 - acc: 0.7647 - val_loss: 3.8227 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4845 - acc: 0.7647 - val_loss: 3.8155 - val_acc: 0.2000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4826 - acc: 0.7647 - val_loss: 3.7953 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 288us/step - loss: 0.4786 - acc: 0.7647 - val_loss: 3.7872 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4763 - acc: 0.7647 - val_loss: 3.7868 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4738 - acc: 0.7647 - val_loss: 3.7750 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4711 - acc: 0.7843 - val_loss: 3.7644 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4693 - acc: 0.7843 - val_loss: 3.7621 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4667 - acc: 0.7843 - val_loss: 3.7568 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4645 - acc: 0.7843 - val_loss: 3.7428 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4615 - acc: 0.7843 - val_loss: 3.7404 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4590 - acc: 0.7843 - val_loss: 3.7377 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4565 - acc: 0.7843 - val_loss: 3.7356 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4546 - acc: 0.7843 - val_loss: 3.7188 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4514 - acc: 0.7843 - val_loss: 3.7120 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4490 - acc: 0.7843 - val_loss: 3.7140 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4471 - acc: 0.7843 - val_loss: 3.6964 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4442 - acc: 0.7843 - val_loss: 3.6863 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4423 - acc: 0.7843 - val_loss: 3.6812 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4401 - acc: 0.7843 - val_loss: 3.6757 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4376 - acc: 0.7843 - val_loss: 3.6652 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4353 - acc: 0.7843 - val_loss: 3.6635 - val_acc: 0.2000\n",
      "2017-01-03\n",
      "2017-01-04\n",
      "2017-01-05\n",
      "2017-01-06\n",
      "2017-01-09\n",
      "2017-01-10\n",
      "2017-01-11\n",
      "2017-01-12\n",
      "2017-01-13\n",
      "2017-01-16\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 0.9410 - acc: 0.7059 - val_loss: 0.5947 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.8922 - acc: 0.7255 - val_loss: 0.5945 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8618 - acc: 0.7255 - val_loss: 0.5945 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8345 - acc: 0.7451 - val_loss: 0.5946 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8119 - acc: 0.7451 - val_loss: 0.5947 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7926 - acc: 0.7647 - val_loss: 0.5948 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7743 - acc: 0.7843 - val_loss: 0.5946 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.7582 - acc: 0.7843 - val_loss: 0.5948 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7428 - acc: 0.7843 - val_loss: 0.5950 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7277 - acc: 0.7843 - val_loss: 0.5952 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7134 - acc: 0.7843 - val_loss: 0.5952 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6982 - acc: 0.7843 - val_loss: 0.5952 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6831 - acc: 0.7843 - val_loss: 0.5953 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6646 - acc: 0.7843 - val_loss: 0.5953 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6457 - acc: 0.7843 - val_loss: 0.5954 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6291 - acc: 0.7843 - val_loss: 0.5955 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6116 - acc: 0.7843 - val_loss: 0.5955 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.5971 - acc: 0.8039 - val_loss: 0.5957 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5840 - acc: 0.8039 - val_loss: 0.5957 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5708 - acc: 0.8039 - val_loss: 0.5959 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5578 - acc: 0.8235 - val_loss: 0.5959 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5399 - acc: 0.8235 - val_loss: 0.5957 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5209 - acc: 0.8235 - val_loss: 0.5960 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5061 - acc: 0.8431 - val_loss: 0.5962 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4921 - acc: 0.8431 - val_loss: 0.5963 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4798 - acc: 0.8627 - val_loss: 0.5963 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4678 - acc: 0.8627 - val_loss: 0.5961 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4531 - acc: 0.8627 - val_loss: 0.5960 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4367 - acc: 0.8627 - val_loss: 0.5959 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4218 - acc: 0.8627 - val_loss: 0.5958 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4083 - acc: 0.8627 - val_loss: 0.5953 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3977 - acc: 0.8627 - val_loss: 0.5953 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3883 - acc: 0.8627 - val_loss: 0.5954 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3785 - acc: 0.8627 - val_loss: 0.5953 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 154us/step - loss: 0.3694 - acc: 0.8627 - val_loss: 0.5950 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3616 - acc: 0.8627 - val_loss: 0.5950 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3526 - acc: 0.8824 - val_loss: 0.5945 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3460 - acc: 0.8824 - val_loss: 0.5938 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3397 - acc: 0.8824 - val_loss: 0.5932 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3328 - acc: 0.8824 - val_loss: 0.5925 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3266 - acc: 0.8824 - val_loss: 0.5919 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3218 - acc: 0.9020 - val_loss: 0.5916 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3162 - acc: 0.9020 - val_loss: 0.5913 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3111 - acc: 0.9020 - val_loss: 0.5911 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3063 - acc: 0.9020 - val_loss: 0.5909 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3026 - acc: 0.9020 - val_loss: 0.5904 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2994 - acc: 0.9020 - val_loss: 0.5899 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2962 - acc: 0.9020 - val_loss: 0.5897 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2923 - acc: 0.9020 - val_loss: 0.5891 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2887 - acc: 0.9020 - val_loss: 0.5883 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2852 - acc: 0.9020 - val_loss: 0.5880 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2819 - acc: 0.9020 - val_loss: 0.5875 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2788 - acc: 0.9020 - val_loss: 0.5869 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2753 - acc: 0.9020 - val_loss: 0.5864 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2725 - acc: 0.9216 - val_loss: 0.5860 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2698 - acc: 0.9216 - val_loss: 0.5856 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2670 - acc: 0.9216 - val_loss: 0.5850 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2643 - acc: 0.9216 - val_loss: 0.5844 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2619 - acc: 0.9216 - val_loss: 0.5838 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2585 - acc: 0.9216 - val_loss: 0.5831 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2563 - acc: 0.9216 - val_loss: 0.5823 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2532 - acc: 0.9216 - val_loss: 0.5818 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2513 - acc: 0.9216 - val_loss: 0.5810 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2489 - acc: 0.9216 - val_loss: 0.5809 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2466 - acc: 0.9216 - val_loss: 0.5803 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2443 - acc: 0.9216 - val_loss: 0.5798 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2422 - acc: 0.9216 - val_loss: 0.5792 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2407 - acc: 0.9216 - val_loss: 0.5786 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2376 - acc: 0.9216 - val_loss: 0.5780 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2362 - acc: 0.9216 - val_loss: 0.5777 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2338 - acc: 0.9216 - val_loss: 0.5770 - val_acc: 0.8000\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 255us/step - loss: 0.2318 - acc: 0.9216 - val_loss: 0.5768 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2296 - acc: 0.9216 - val_loss: 0.5762 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2285 - acc: 0.9216 - val_loss: 0.5757 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2262 - acc: 0.9216 - val_loss: 0.5754 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1996 - acc: 0.937 - 0s 353us/step - loss: 0.2246 - acc: 0.9216 - val_loss: 0.5752 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2230 - acc: 0.9216 - val_loss: 0.5748 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2216 - acc: 0.9216 - val_loss: 0.5749 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2196 - acc: 0.9216 - val_loss: 0.5747 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.2177 - acc: 0.9216 - val_loss: 0.5745 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2162 - acc: 0.9216 - val_loss: 0.5742 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2147 - acc: 0.9020 - val_loss: 0.5737 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2128 - acc: 0.9216 - val_loss: 0.5736 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2110 - acc: 0.9020 - val_loss: 0.5728 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 607us/step - loss: 0.2088 - acc: 0.9020 - val_loss: 0.5725 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 765us/step - loss: 0.2072 - acc: 0.9020 - val_loss: 0.5722 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2056 - acc: 0.9020 - val_loss: 0.5718 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2049 - acc: 0.9020 - val_loss: 0.5711 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.2028 - acc: 0.9020 - val_loss: 0.5711 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2013 - acc: 0.9020 - val_loss: 0.5715 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 344us/step - loss: 0.1994 - acc: 0.9020 - val_loss: 0.5716 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1976 - acc: 0.9020 - val_loss: 0.5712 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1954 - acc: 0.9020 - val_loss: 0.5707 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1939 - acc: 0.9020 - val_loss: 0.5711 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.1930 - acc: 0.9020 - val_loss: 0.5702 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1912 - acc: 0.9020 - val_loss: 0.5704 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1890 - acc: 0.9020 - val_loss: 0.5699 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 403us/step - loss: 0.1878 - acc: 0.9020 - val_loss: 0.5700 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1863 - acc: 0.9020 - val_loss: 0.5697 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1858 - acc: 0.9020 - val_loss: 0.5700 - val_acc: 0.8000\n",
      "2017-01-17\n",
      "2017-01-18\n",
      "2017-01-19\n",
      "2017-01-20\n",
      "2017-01-23\n",
      "2017-01-24\n",
      "2017-01-25\n",
      "2017-01-26\n",
      "2017-02-03\n",
      "2017-02-06\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 0.2918 - acc: 0.8235 - val_loss: 0.6491 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2784 - acc: 0.8431 - val_loss: 0.6458 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2724 - acc: 0.8431 - val_loss: 0.6443 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.2664 - acc: 0.8627 - val_loss: 0.6436 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 0.2634 - acc: 0.8627 - val_loss: 0.6427 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2570 - acc: 0.8627 - val_loss: 0.6397 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2541 - acc: 0.8627 - val_loss: 0.6387 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2510 - acc: 0.8627 - val_loss: 0.6368 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2487 - acc: 0.8627 - val_loss: 0.6367 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2455 - acc: 0.8627 - val_loss: 0.6358 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2423 - acc: 0.8627 - val_loss: 0.6339 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.2412 - acc: 0.8627 - val_loss: 0.6321 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2387 - acc: 0.8627 - val_loss: 0.6321 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2363 - acc: 0.8824 - val_loss: 0.6318 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2333 - acc: 0.9020 - val_loss: 0.6320 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2321 - acc: 0.9020 - val_loss: 0.6308 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2302 - acc: 0.9020 - val_loss: 0.6289 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2277 - acc: 0.9020 - val_loss: 0.6284 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2255 - acc: 0.9020 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.2241 - acc: 0.9020 - val_loss: 0.6282 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2231 - acc: 0.9020 - val_loss: 0.6285 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2208 - acc: 0.9020 - val_loss: 0.6293 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2192 - acc: 0.9020 - val_loss: 0.6286 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.2184 - acc: 0.9020 - val_loss: 0.6296 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2160 - acc: 0.9020 - val_loss: 0.6301 - val_acc: 0.6000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2150 - acc: 0.9020 - val_loss: 0.6287 - val_acc: 0.6000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2134 - acc: 0.9020 - val_loss: 0.6306 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.2130 - acc: 0.9216 - val_loss: 0.6309 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2112 - acc: 0.9216 - val_loss: 0.6301 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2092 - acc: 0.9216 - val_loss: 0.6323 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2086 - acc: 0.9216 - val_loss: 0.6314 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2075 - acc: 0.9412 - val_loss: 0.6337 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2067 - acc: 0.9412 - val_loss: 0.6342 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1774 - acc: 0.937 - 0s 274us/step - loss: 0.2053 - acc: 0.9412 - val_loss: 0.6340 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2037 - acc: 0.9412 - val_loss: 0.6363 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2030 - acc: 0.9608 - val_loss: 0.6358 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2017 - acc: 0.9608 - val_loss: 0.6380 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2004 - acc: 0.9608 - val_loss: 0.6400 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1993 - acc: 0.9608 - val_loss: 0.6393 - val_acc: 0.6000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1983 - acc: 0.9608 - val_loss: 0.6410 - val_acc: 0.6000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1966 - acc: 0.9608 - val_loss: 0.6414 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1964 - acc: 0.9608 - val_loss: 0.6431 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1950 - acc: 0.9412 - val_loss: 0.6437 - val_acc: 0.6000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.1943 - acc: 0.9412 - val_loss: 0.6435 - val_acc: 0.6000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1933 - acc: 0.9412 - val_loss: 0.6445 - val_acc: 0.6000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1923 - acc: 0.9412 - val_loss: 0.6450 - val_acc: 0.6000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1908 - acc: 0.9412 - val_loss: 0.6449 - val_acc: 0.6000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1903 - acc: 0.9412 - val_loss: 0.6462 - val_acc: 0.6000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1894 - acc: 0.9412 - val_loss: 0.6471 - val_acc: 0.6000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1888 - acc: 0.9412 - val_loss: 0.6496 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1875 - acc: 0.9412 - val_loss: 0.6503 - val_acc: 0.6000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1867 - acc: 0.9412 - val_loss: 0.6486 - val_acc: 0.6000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1861 - acc: 0.9412 - val_loss: 0.6503 - val_acc: 0.6000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1851 - acc: 0.9412 - val_loss: 0.6503 - val_acc: 0.6000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1841 - acc: 0.9412 - val_loss: 0.6517 - val_acc: 0.6000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 286us/step - loss: 0.1832 - acc: 0.9412 - val_loss: 0.6513 - val_acc: 0.6000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1829 - acc: 0.9412 - val_loss: 0.6523 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1821 - acc: 0.9412 - val_loss: 0.6531 - val_acc: 0.6000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1808 - acc: 0.9412 - val_loss: 0.6524 - val_acc: 0.6000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1804 - acc: 0.9412 - val_loss: 0.6550 - val_acc: 0.6000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1798 - acc: 0.9412 - val_loss: 0.6552 - val_acc: 0.6000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1786 - acc: 0.9412 - val_loss: 0.6527 - val_acc: 0.6000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1775 - acc: 0.9412 - val_loss: 0.6545 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1771 - acc: 0.9412 - val_loss: 0.6528 - val_acc: 0.6000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.1762 - acc: 0.9412 - val_loss: 0.6526 - val_acc: 0.6000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1747 - acc: 0.9412 - val_loss: 0.6550 - val_acc: 0.6000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1747 - acc: 0.9412 - val_loss: 0.6544 - val_acc: 0.6000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1740 - acc: 0.9412 - val_loss: 0.6559 - val_acc: 0.6000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.1730 - acc: 0.9412 - val_loss: 0.6584 - val_acc: 0.6000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1723 - acc: 0.9412 - val_loss: 0.6590 - val_acc: 0.6000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.1711 - acc: 0.9412 - val_loss: 0.6602 - val_acc: 0.6000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.1704 - acc: 0.9412 - val_loss: 0.6618 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1699 - acc: 0.9412 - val_loss: 0.6589 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1686 - acc: 0.9412 - val_loss: 0.6603 - val_acc: 0.6000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1677 - acc: 0.9412 - val_loss: 0.6624 - val_acc: 0.6000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1673 - acc: 0.9412 - val_loss: 0.6614 - val_acc: 0.6000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.1659 - acc: 0.9412 - val_loss: 0.6612 - val_acc: 0.6000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1652 - acc: 0.9412 - val_loss: 0.6607 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1647 - acc: 0.9412 - val_loss: 0.6625 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.1643 - acc: 0.9412 - val_loss: 0.6624 - val_acc: 0.6000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1630 - acc: 0.9412 - val_loss: 0.6635 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1624 - acc: 0.9412 - val_loss: 0.6629 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.1615 - acc: 0.9412 - val_loss: 0.6665 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1609 - acc: 0.9412 - val_loss: 0.6667 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1606 - acc: 0.9412 - val_loss: 0.6675 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1596 - acc: 0.9412 - val_loss: 0.6726 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1595 - acc: 0.9412 - val_loss: 0.6692 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1587 - acc: 0.9412 - val_loss: 0.6690 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1585 - acc: 0.9412 - val_loss: 0.6718 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1579 - acc: 0.9412 - val_loss: 0.6735 - val_acc: 0.6000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1572 - acc: 0.9412 - val_loss: 0.6747 - val_acc: 0.6000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1565 - acc: 0.9412 - val_loss: 0.6743 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1562 - acc: 0.9412 - val_loss: 0.6766 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1550 - acc: 0.9412 - val_loss: 0.6805 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1549 - acc: 0.9412 - val_loss: 0.6797 - val_acc: 0.6000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1542 - acc: 0.9412 - val_loss: 0.6828 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1536 - acc: 0.9412 - val_loss: 0.6836 - val_acc: 0.6000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 357us/step - loss: 0.1536 - acc: 0.9412 - val_loss: 0.6875 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.1528 - acc: 0.9412 - val_loss: 0.6866 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.1520 - acc: 0.9412 - val_loss: 0.6864 - val_acc: 0.6000\n",
      "2017-02-07\n",
      "2017-02-08\n",
      "2017-02-09\n",
      "2017-02-10\n",
      "2017-02-13\n",
      "2017-02-14\n",
      "2017-02-15\n",
      "2017-02-16\n",
      "2017-02-17\n",
      "2017-02-20\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 0.4982 - acc: 0.8235 - val_loss: 2.2168 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4849 - acc: 0.8235 - val_loss: 2.1891 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4732 - acc: 0.8235 - val_loss: 2.1799 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4691 - acc: 0.8235 - val_loss: 2.1599 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4620 - acc: 0.8235 - val_loss: 2.1540 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4577 - acc: 0.8235 - val_loss: 2.1397 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4536 - acc: 0.8431 - val_loss: 2.1330 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4504 - acc: 0.8235 - val_loss: 2.1346 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4471 - acc: 0.8235 - val_loss: 2.1189 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.4426 - acc: 0.8431 - val_loss: 2.1146 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4371 - acc: 0.8431 - val_loss: 2.1048 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4345 - acc: 0.8431 - val_loss: 2.0988 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.4302 - acc: 0.8431 - val_loss: 2.0903 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.4272 - acc: 0.8431 - val_loss: 2.0912 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4235 - acc: 0.8431 - val_loss: 2.0803 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4185 - acc: 0.8431 - val_loss: 2.0720 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 450us/step - loss: 0.4152 - acc: 0.8431 - val_loss: 2.0694 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.4113 - acc: 0.8431 - val_loss: 2.0636 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4089 - acc: 0.8431 - val_loss: 2.0648 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4064 - acc: 0.8431 - val_loss: 2.0721 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4020 - acc: 0.8431 - val_loss: 2.0740 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.3997 - acc: 0.8431 - val_loss: 2.0699 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3977 - acc: 0.8431 - val_loss: 2.0752 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3945 - acc: 0.8431 - val_loss: 2.0778 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.3922 - acc: 0.8431 - val_loss: 2.0762 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3898 - acc: 0.8431 - val_loss: 2.0668 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3861 - acc: 0.8431 - val_loss: 2.0658 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3837 - acc: 0.8431 - val_loss: 2.0574 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3804 - acc: 0.8431 - val_loss: 2.0532 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3779 - acc: 0.8627 - val_loss: 2.0559 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3763 - acc: 0.8431 - val_loss: 2.0548 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3736 - acc: 0.8627 - val_loss: 2.0494 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3724 - acc: 0.8627 - val_loss: 2.0540 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3705 - acc: 0.8627 - val_loss: 2.0514 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3686 - acc: 0.8627 - val_loss: 2.0440 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3659 - acc: 0.8627 - val_loss: 2.0377 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3640 - acc: 0.8627 - val_loss: 2.0348 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 78us/step - loss: 0.3623 - acc: 0.8627 - val_loss: 2.0391 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 228us/step - loss: 0.3607 - acc: 0.8627 - val_loss: 2.0402 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3601 - acc: 0.8627 - val_loss: 2.0420 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3584 - acc: 0.8627 - val_loss: 2.0477 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3561 - acc: 0.8627 - val_loss: 2.0431 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3551 - acc: 0.8627 - val_loss: 2.0444 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3537 - acc: 0.8627 - val_loss: 2.0359 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3527 - acc: 0.8627 - val_loss: 2.0312 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3504 - acc: 0.8627 - val_loss: 2.0334 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3489 - acc: 0.8627 - val_loss: 2.0290 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3482 - acc: 0.8627 - val_loss: 2.0256 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3458 - acc: 0.8627 - val_loss: 2.0276 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3450 - acc: 0.8627 - val_loss: 2.0364 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3436 - acc: 0.8627 - val_loss: 2.0356 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3421 - acc: 0.8627 - val_loss: 2.0373 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3410 - acc: 0.8627 - val_loss: 2.0407 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3411 - acc: 0.8627 - val_loss: 2.0436 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3384 - acc: 0.8627 - val_loss: 2.0497 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3374 - acc: 0.8627 - val_loss: 2.0481 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.3361 - acc: 0.8627 - val_loss: 2.0449 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3357 - acc: 0.8627 - val_loss: 2.0454 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3345 - acc: 0.8627 - val_loss: 2.0527 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.3326 - acc: 0.8627 - val_loss: 2.0593 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3318 - acc: 0.8627 - val_loss: 2.0521 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3305 - acc: 0.8627 - val_loss: 2.0521 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3292 - acc: 0.8627 - val_loss: 2.0582 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3279 - acc: 0.8627 - val_loss: 2.0592 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3268 - acc: 0.8627 - val_loss: 2.0679 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3260 - acc: 0.8627 - val_loss: 2.0803 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3255 - acc: 0.8627 - val_loss: 2.0805 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3237 - acc: 0.8824 - val_loss: 2.0800 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3233 - acc: 0.8627 - val_loss: 2.0837 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3220 - acc: 0.8627 - val_loss: 2.0862 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3203 - acc: 0.8824 - val_loss: 2.0836 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3197 - acc: 0.8824 - val_loss: 2.0807 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3183 - acc: 0.8824 - val_loss: 2.0730 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.3168 - acc: 0.8824 - val_loss: 2.0763 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3174 - acc: 0.8824 - val_loss: 2.0686 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.3149 - acc: 0.8627 - val_loss: 2.0657 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3139 - acc: 0.8824 - val_loss: 2.0772 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3132 - acc: 0.8627 - val_loss: 2.0746 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3124 - acc: 0.8824 - val_loss: 2.0860 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3125 - acc: 0.8627 - val_loss: 2.0874 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3102 - acc: 0.8824 - val_loss: 2.0995 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3093 - acc: 0.8824 - val_loss: 2.0986 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3082 - acc: 0.8824 - val_loss: 2.1010 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3078 - acc: 0.8824 - val_loss: 2.0952 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3064 - acc: 0.8824 - val_loss: 2.1013 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3052 - acc: 0.8824 - val_loss: 2.1051 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3044 - acc: 0.8824 - val_loss: 2.1139 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3036 - acc: 0.8824 - val_loss: 2.0987 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3025 - acc: 0.8824 - val_loss: 2.1018 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3017 - acc: 0.8824 - val_loss: 2.1121 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.3003 - acc: 0.8824 - val_loss: 2.1224 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3464 - acc: 0.875 - 0s 177us/step - loss: 0.2995 - acc: 0.8824 - val_loss: 2.1254 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2983 - acc: 0.8824 - val_loss: 2.1332 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.2993 - acc: 0.8824 - val_loss: 2.1122 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.2971 - acc: 0.8824 - val_loss: 2.1202 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2960 - acc: 0.8824 - val_loss: 2.1169 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2950 - acc: 0.8824 - val_loss: 2.1174 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2950 - acc: 0.8824 - val_loss: 2.1143 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2932 - acc: 0.8824 - val_loss: 2.1145 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2923 - acc: 0.8824 - val_loss: 2.1217 - val_acc: 0.0000e+00\n",
      "2017-02-21\n",
      "2017-02-22\n",
      "2017-02-23\n",
      "2017-02-24\n",
      "2017-02-27\n",
      "2017-02-28\n",
      "2017-03-01\n",
      "2017-03-02\n",
      "2017-03-03\n",
      "2017-03-06\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 0.7025 - acc: 0.6471 - val_loss: 0.8033 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.6723 - acc: 0.6275 - val_loss: 0.7743 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6527 - acc: 0.6471 - val_loss: 0.7588 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.6384 - acc: 0.6471 - val_loss: 0.7432 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6242 - acc: 0.6471 - val_loss: 0.7307 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.6123 - acc: 0.6667 - val_loss: 0.7183 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6025 - acc: 0.6275 - val_loss: 0.7072 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5919 - acc: 0.6471 - val_loss: 0.6985 - val_acc: 0.7000\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 255us/step - loss: 0.5852 - acc: 0.6471 - val_loss: 0.6876 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.5743 - acc: 0.6667 - val_loss: 0.6789 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5678 - acc: 0.6667 - val_loss: 0.6693 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5593 - acc: 0.6667 - val_loss: 0.6629 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5518 - acc: 0.6667 - val_loss: 0.6561 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 273us/step - loss: 0.5459 - acc: 0.6667 - val_loss: 0.6508 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5387 - acc: 0.6667 - val_loss: 0.6447 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5328 - acc: 0.6667 - val_loss: 0.6373 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5274 - acc: 0.6667 - val_loss: 0.6318 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.5208 - acc: 0.6863 - val_loss: 0.6246 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5155 - acc: 0.6863 - val_loss: 0.6200 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5136 - acc: 0.6863 - val_loss: 0.6154 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.5077 - acc: 0.6863 - val_loss: 0.6102 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5032 - acc: 0.6863 - val_loss: 0.6029 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4987 - acc: 0.6863 - val_loss: 0.5979 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4948 - acc: 0.7059 - val_loss: 0.5931 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4911 - acc: 0.7059 - val_loss: 0.5862 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4873 - acc: 0.7059 - val_loss: 0.5822 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4852 - acc: 0.6863 - val_loss: 0.5787 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4811 - acc: 0.6863 - val_loss: 0.5746 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 362us/step - loss: 0.4798 - acc: 0.6863 - val_loss: 0.5717 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4747 - acc: 0.6863 - val_loss: 0.5689 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4723 - acc: 0.6863 - val_loss: 0.5646 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4685 - acc: 0.6863 - val_loss: 0.5618 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4650 - acc: 0.6863 - val_loss: 0.5591 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4626 - acc: 0.6863 - val_loss: 0.5565 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4602 - acc: 0.7059 - val_loss: 0.5535 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4561 - acc: 0.7059 - val_loss: 0.5512 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4541 - acc: 0.7059 - val_loss: 0.5492 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4515 - acc: 0.7059 - val_loss: 0.5468 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4490 - acc: 0.7255 - val_loss: 0.5453 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4469 - acc: 0.7451 - val_loss: 0.5433 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4442 - acc: 0.7451 - val_loss: 0.5409 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4416 - acc: 0.7451 - val_loss: 0.5382 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4387 - acc: 0.7843 - val_loss: 0.5361 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4372 - acc: 0.8039 - val_loss: 0.5347 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4346 - acc: 0.8039 - val_loss: 0.5337 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4339 - acc: 0.8235 - val_loss: 0.5323 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4312 - acc: 0.8235 - val_loss: 0.5294 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4289 - acc: 0.8235 - val_loss: 0.5267 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.4272 - acc: 0.8235 - val_loss: 0.5240 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4251 - acc: 0.8235 - val_loss: 0.5236 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4228 - acc: 0.8235 - val_loss: 0.5222 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4210 - acc: 0.8431 - val_loss: 0.5203 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4182 - acc: 0.8431 - val_loss: 0.5181 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.4157 - acc: 0.8431 - val_loss: 0.5171 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4148 - acc: 0.8235 - val_loss: 0.5173 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4123 - acc: 0.8627 - val_loss: 0.5170 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4102 - acc: 0.8431 - val_loss: 0.5165 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4087 - acc: 0.8431 - val_loss: 0.5160 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4069 - acc: 0.8431 - val_loss: 0.5147 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4058 - acc: 0.8431 - val_loss: 0.5117 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4036 - acc: 0.8431 - val_loss: 0.5095 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4023 - acc: 0.8431 - val_loss: 0.5085 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4010 - acc: 0.8431 - val_loss: 0.5060 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.3988 - acc: 0.8431 - val_loss: 0.5046 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3978 - acc: 0.8627 - val_loss: 0.5023 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3959 - acc: 0.8627 - val_loss: 0.5013 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.3951 - acc: 0.8627 - val_loss: 0.4987 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.3935 - acc: 0.8627 - val_loss: 0.4986 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 225us/step - loss: 0.3914 - acc: 0.8627 - val_loss: 0.4968 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3897 - acc: 0.8627 - val_loss: 0.4964 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3883 - acc: 0.8627 - val_loss: 0.4969 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3864 - acc: 0.8627 - val_loss: 0.4966 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3847 - acc: 0.8627 - val_loss: 0.4951 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3842 - acc: 0.8627 - val_loss: 0.4958 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3823 - acc: 0.8627 - val_loss: 0.4942 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3810 - acc: 0.8627 - val_loss: 0.4924 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3795 - acc: 0.8627 - val_loss: 0.4919 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3793 - acc: 0.8627 - val_loss: 0.4898 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3765 - acc: 0.8627 - val_loss: 0.4893 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3758 - acc: 0.8627 - val_loss: 0.4874 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3742 - acc: 0.8627 - val_loss: 0.4880 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3728 - acc: 0.8627 - val_loss: 0.4857 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3713 - acc: 0.8627 - val_loss: 0.4849 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3698 - acc: 0.8627 - val_loss: 0.4838 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3682 - acc: 0.8627 - val_loss: 0.4830 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3673 - acc: 0.8824 - val_loss: 0.4818 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3663 - acc: 0.8627 - val_loss: 0.4798 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3652 - acc: 0.8824 - val_loss: 0.4788 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3631 - acc: 0.8824 - val_loss: 0.4790 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3619 - acc: 0.8824 - val_loss: 0.4794 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.3609 - acc: 0.8824 - val_loss: 0.4786 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3603 - acc: 0.8824 - val_loss: 0.4798 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3578 - acc: 0.8824 - val_loss: 0.4799 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3573 - acc: 0.8824 - val_loss: 0.4810 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3557 - acc: 0.8824 - val_loss: 0.4798 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3542 - acc: 0.8824 - val_loss: 0.4795 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3531 - acc: 0.9020 - val_loss: 0.4785 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.3521 - acc: 0.9020 - val_loss: 0.4785 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3511 - acc: 0.9020 - val_loss: 0.4798 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3496 - acc: 0.9020 - val_loss: 0.4786 - val_acc: 0.7000\n",
      "2017-03-07\n",
      "2017-03-08\n",
      "2017-03-09\n",
      "2017-03-10\n",
      "2017-03-13\n",
      "2017-03-14\n",
      "2017-03-15\n",
      "2017-03-16\n",
      "2017-03-17\n",
      "2017-03-20\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 0.7596 - acc: 0.5882 - val_loss: 0.9922 - val_acc: 0.4000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.7351 - acc: 0.5882 - val_loss: 0.9781 - val_acc: 0.4000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7239 - acc: 0.5882 - val_loss: 0.9660 - val_acc: 0.4000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7093 - acc: 0.5882 - val_loss: 0.9568 - val_acc: 0.4000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7004 - acc: 0.5882 - val_loss: 0.9485 - val_acc: 0.4000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6909 - acc: 0.5882 - val_loss: 0.9398 - val_acc: 0.4000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6841 - acc: 0.5882 - val_loss: 0.9329 - val_acc: 0.4000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6739 - acc: 0.5882 - val_loss: 0.9266 - val_acc: 0.4000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.6678 - acc: 0.5882 - val_loss: 0.9223 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6610 - acc: 0.5882 - val_loss: 0.9172 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6540 - acc: 0.5882 - val_loss: 0.9121 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6480 - acc: 0.5882 - val_loss: 0.9070 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6413 - acc: 0.5882 - val_loss: 0.9027 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6337 - acc: 0.6078 - val_loss: 0.8967 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6275 - acc: 0.6275 - val_loss: 0.8910 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.6195 - acc: 0.6275 - val_loss: 0.8901 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6148 - acc: 0.6275 - val_loss: 0.8890 - val_acc: 0.4000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6083 - acc: 0.6275 - val_loss: 0.8867 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.6029 - acc: 0.6275 - val_loss: 0.8837 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5973 - acc: 0.6275 - val_loss: 0.8798 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5901 - acc: 0.6471 - val_loss: 0.8767 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.5844 - acc: 0.6667 - val_loss: 0.8710 - val_acc: 0.4000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5783 - acc: 0.6863 - val_loss: 0.8678 - val_acc: 0.4000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5722 - acc: 0.6863 - val_loss: 0.8661 - val_acc: 0.4000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.5661 - acc: 0.7059 - val_loss: 0.8660 - val_acc: 0.4000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5606 - acc: 0.7059 - val_loss: 0.8649 - val_acc: 0.4000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5563 - acc: 0.7255 - val_loss: 0.8632 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5506 - acc: 0.7059 - val_loss: 0.8622 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5451 - acc: 0.7255 - val_loss: 0.8634 - val_acc: 0.4000\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 235us/step - loss: 0.5411 - acc: 0.7255 - val_loss: 0.8635 - val_acc: 0.4000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5367 - acc: 0.7255 - val_loss: 0.8633 - val_acc: 0.4000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5321 - acc: 0.7451 - val_loss: 0.8635 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5291 - acc: 0.7451 - val_loss: 0.8644 - val_acc: 0.4000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5234 - acc: 0.7451 - val_loss: 0.8653 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5196 - acc: 0.7451 - val_loss: 0.8659 - val_acc: 0.4000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5148 - acc: 0.7451 - val_loss: 0.8674 - val_acc: 0.4000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.5105 - acc: 0.7451 - val_loss: 0.8687 - val_acc: 0.4000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5072 - acc: 0.7647 - val_loss: 0.8703 - val_acc: 0.4000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5028 - acc: 0.7647 - val_loss: 0.8706 - val_acc: 0.4000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4988 - acc: 0.7843 - val_loss: 0.8726 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4946 - acc: 0.8039 - val_loss: 0.8746 - val_acc: 0.4000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4903 - acc: 0.8039 - val_loss: 0.8766 - val_acc: 0.4000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4857 - acc: 0.7843 - val_loss: 0.8780 - val_acc: 0.4000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4809 - acc: 0.8039 - val_loss: 0.8809 - val_acc: 0.4000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4771 - acc: 0.8039 - val_loss: 0.8806 - val_acc: 0.4000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4722 - acc: 0.8235 - val_loss: 0.8836 - val_acc: 0.4000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4681 - acc: 0.8235 - val_loss: 0.8863 - val_acc: 0.4000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4645 - acc: 0.8235 - val_loss: 0.8882 - val_acc: 0.4000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4608 - acc: 0.8235 - val_loss: 0.8905 - val_acc: 0.4000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4580 - acc: 0.8235 - val_loss: 0.8931 - val_acc: 0.4000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 396us/step - loss: 0.4550 - acc: 0.8235 - val_loss: 0.8960 - val_acc: 0.4000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.4509 - acc: 0.8235 - val_loss: 0.8974 - val_acc: 0.4000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4481 - acc: 0.8235 - val_loss: 0.9017 - val_acc: 0.4000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4454 - acc: 0.8235 - val_loss: 0.9051 - val_acc: 0.4000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.4424 - acc: 0.8235 - val_loss: 0.9094 - val_acc: 0.4000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4406 - acc: 0.8235 - val_loss: 0.9135 - val_acc: 0.4000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4383 - acc: 0.8235 - val_loss: 0.9143 - val_acc: 0.4000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4366 - acc: 0.8235 - val_loss: 0.9174 - val_acc: 0.4000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4348 - acc: 0.8235 - val_loss: 0.9194 - val_acc: 0.4000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4329 - acc: 0.8235 - val_loss: 0.9214 - val_acc: 0.4000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4322 - acc: 0.8235 - val_loss: 0.9246 - val_acc: 0.4000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4289 - acc: 0.8235 - val_loss: 0.9269 - val_acc: 0.4000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 549us/step - loss: 0.4284 - acc: 0.8235 - val_loss: 0.9302 - val_acc: 0.4000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4257 - acc: 0.8235 - val_loss: 0.9315 - val_acc: 0.4000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.4242 - acc: 0.8235 - val_loss: 0.9350 - val_acc: 0.4000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4219 - acc: 0.8235 - val_loss: 0.9363 - val_acc: 0.4000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4204 - acc: 0.8235 - val_loss: 0.9383 - val_acc: 0.4000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4191 - acc: 0.8235 - val_loss: 0.9408 - val_acc: 0.4000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4183 - acc: 0.8235 - val_loss: 0.9423 - val_acc: 0.4000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4161 - acc: 0.8235 - val_loss: 0.9464 - val_acc: 0.4000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4147 - acc: 0.8431 - val_loss: 0.9502 - val_acc: 0.4000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4133 - acc: 0.8431 - val_loss: 0.9539 - val_acc: 0.4000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4118 - acc: 0.8431 - val_loss: 0.9570 - val_acc: 0.4000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4098 - acc: 0.8431 - val_loss: 0.9606 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4086 - acc: 0.8431 - val_loss: 0.9658 - val_acc: 0.4000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4071 - acc: 0.8431 - val_loss: 0.9691 - val_acc: 0.4000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4057 - acc: 0.8431 - val_loss: 0.9725 - val_acc: 0.4000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4055 - acc: 0.8431 - val_loss: 0.9753 - val_acc: 0.4000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4033 - acc: 0.8431 - val_loss: 0.9791 - val_acc: 0.4000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4020 - acc: 0.8431 - val_loss: 0.9841 - val_acc: 0.4000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4018 - acc: 0.8431 - val_loss: 0.9881 - val_acc: 0.4000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3994 - acc: 0.8431 - val_loss: 0.9909 - val_acc: 0.4000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3977 - acc: 0.8431 - val_loss: 0.9956 - val_acc: 0.4000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3977 - acc: 0.8431 - val_loss: 1.0007 - val_acc: 0.4000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3953 - acc: 0.8627 - val_loss: 1.0044 - val_acc: 0.4000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4245 - acc: 0.843 - 0s 177us/step - loss: 0.3939 - acc: 0.8627 - val_loss: 1.0094 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.3931 - acc: 0.8627 - val_loss: 1.0123 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3912 - acc: 0.8627 - val_loss: 1.0160 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3911 - acc: 0.8627 - val_loss: 1.0181 - val_acc: 0.4000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3514 - acc: 0.906 - 0s 333us/step - loss: 0.3891 - acc: 0.8627 - val_loss: 1.0218 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3883 - acc: 0.8627 - val_loss: 1.0237 - val_acc: 0.4000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.3865 - acc: 0.8627 - val_loss: 1.0275 - val_acc: 0.4000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3851 - acc: 0.8627 - val_loss: 1.0318 - val_acc: 0.4000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3840 - acc: 0.8627 - val_loss: 1.0376 - val_acc: 0.4000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3852 - acc: 0.8627 - val_loss: 1.0406 - val_acc: 0.4000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.3817 - acc: 0.8627 - val_loss: 1.0431 - val_acc: 0.4000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 223us/step - loss: 0.3803 - acc: 0.8627 - val_loss: 1.0473 - val_acc: 0.4000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.3791 - acc: 0.8627 - val_loss: 1.0507 - val_acc: 0.4000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3783 - acc: 0.8627 - val_loss: 1.0567 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3763 - acc: 0.8627 - val_loss: 1.0630 - val_acc: 0.4000\n",
      "2017-03-21\n",
      "2017-03-22\n",
      "2017-03-23\n",
      "2017-03-24\n",
      "2017-03-27\n",
      "2017-03-28\n",
      "2017-03-29\n",
      "2017-03-30\n",
      "2017-03-31\n",
      "2017-04-05\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.2409 - acc: 0.5294 - val_loss: 0.7006 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1893 - acc: 0.5490 - val_loss: 0.6991 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1578 - acc: 0.5490 - val_loss: 0.6979 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.1314 - acc: 0.5490 - val_loss: 0.6967 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1086 - acc: 0.5490 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 245us/step - loss: 1.0886 - acc: 0.5490 - val_loss: 0.6919 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0690 - acc: 0.5490 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.0518 - acc: 0.5490 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.0341 - acc: 0.5490 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.0159 - acc: 0.5490 - val_loss: 0.6871 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.9985 - acc: 0.5490 - val_loss: 0.6847 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.9813 - acc: 0.5490 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.9627 - acc: 0.5490 - val_loss: 0.6820 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9447 - acc: 0.5490 - val_loss: 0.6820 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.9268 - acc: 0.5490 - val_loss: 0.6802 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 189us/step - loss: 0.9082 - acc: 0.5490 - val_loss: 0.6775 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8900 - acc: 0.5490 - val_loss: 0.6758 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8739 - acc: 0.5490 - val_loss: 0.6751 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.8593 - acc: 0.5490 - val_loss: 0.6737 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.8450 - acc: 0.5490 - val_loss: 0.6719 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8284 - acc: 0.5490 - val_loss: 0.6702 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.8146 - acc: 0.5490 - val_loss: 0.6679 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.8017 - acc: 0.5490 - val_loss: 0.6660 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7865 - acc: 0.5686 - val_loss: 0.6642 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7717 - acc: 0.5686 - val_loss: 0.6628 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7585 - acc: 0.5686 - val_loss: 0.6623 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7453 - acc: 0.5686 - val_loss: 0.6618 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7329 - acc: 0.5686 - val_loss: 0.6617 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7221 - acc: 0.5490 - val_loss: 0.6604 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7106 - acc: 0.6078 - val_loss: 0.6600 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7008 - acc: 0.6078 - val_loss: 0.6611 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6902 - acc: 0.6275 - val_loss: 0.6605 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6797 - acc: 0.6275 - val_loss: 0.6593 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.6725 - acc: 0.6275 - val_loss: 0.6600 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6613 - acc: 0.6275 - val_loss: 0.6593 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6525 - acc: 0.6275 - val_loss: 0.6582 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6445 - acc: 0.6275 - val_loss: 0.6573 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6365 - acc: 0.6275 - val_loss: 0.6558 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6287 - acc: 0.6275 - val_loss: 0.6537 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6193 - acc: 0.6275 - val_loss: 0.6515 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.6086 - acc: 0.6275 - val_loss: 0.6518 - val_acc: 0.5000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5990 - acc: 0.6275 - val_loss: 0.6511 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 344us/step - loss: 0.5905 - acc: 0.6275 - val_loss: 0.6496 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5808 - acc: 0.6275 - val_loss: 0.6483 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.5719 - acc: 0.6275 - val_loss: 0.6494 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5643 - acc: 0.6275 - val_loss: 0.6498 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.5568 - acc: 0.6471 - val_loss: 0.6494 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 237us/step - loss: 0.5501 - acc: 0.6471 - val_loss: 0.6481 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5428 - acc: 0.6471 - val_loss: 0.6492 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5350 - acc: 0.6471 - val_loss: 0.6494 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5297 - acc: 0.6667 - val_loss: 0.6483 - val_acc: 0.5000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5222 - acc: 0.6863 - val_loss: 0.6492 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5163 - acc: 0.6863 - val_loss: 0.6499 - val_acc: 0.5000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5119 - acc: 0.6863 - val_loss: 0.6513 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 164us/step - loss: 0.5064 - acc: 0.6863 - val_loss: 0.6527 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5011 - acc: 0.6863 - val_loss: 0.6521 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4954 - acc: 0.6863 - val_loss: 0.6519 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4899 - acc: 0.6863 - val_loss: 0.6538 - val_acc: 0.4000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4858 - acc: 0.6863 - val_loss: 0.6555 - val_acc: 0.4000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4810 - acc: 0.6863 - val_loss: 0.6552 - val_acc: 0.4000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4764 - acc: 0.7059 - val_loss: 0.6563 - val_acc: 0.4000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4721 - acc: 0.7255 - val_loss: 0.6572 - val_acc: 0.4000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4675 - acc: 0.7255 - val_loss: 0.6589 - val_acc: 0.4000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 229us/step - loss: 0.4632 - acc: 0.7255 - val_loss: 0.6580 - val_acc: 0.4000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4588 - acc: 0.7255 - val_loss: 0.6587 - val_acc: 0.4000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4547 - acc: 0.7255 - val_loss: 0.6598 - val_acc: 0.4000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4518 - acc: 0.7255 - val_loss: 0.6623 - val_acc: 0.4000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4466 - acc: 0.7255 - val_loss: 0.6621 - val_acc: 0.4000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 250us/step - loss: 0.4438 - acc: 0.7255 - val_loss: 0.6647 - val_acc: 0.4000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4401 - acc: 0.7451 - val_loss: 0.6654 - val_acc: 0.4000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4363 - acc: 0.7451 - val_loss: 0.6657 - val_acc: 0.4000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4334 - acc: 0.7451 - val_loss: 0.6668 - val_acc: 0.4000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4302 - acc: 0.7451 - val_loss: 0.6683 - val_acc: 0.4000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.4254 - acc: 0.7451 - val_loss: 0.6695 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4221 - acc: 0.7451 - val_loss: 0.6693 - val_acc: 0.4000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4191 - acc: 0.7451 - val_loss: 0.6682 - val_acc: 0.4000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4156 - acc: 0.7451 - val_loss: 0.6688 - val_acc: 0.4000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4137 - acc: 0.7451 - val_loss: 0.6688 - val_acc: 0.4000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4122 - acc: 0.7451 - val_loss: 0.6703 - val_acc: 0.4000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.4070 - acc: 0.7451 - val_loss: 0.6711 - val_acc: 0.4000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4046 - acc: 0.7451 - val_loss: 0.6714 - val_acc: 0.4000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.4025 - acc: 0.7451 - val_loss: 0.6699 - val_acc: 0.4000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 474us/step - loss: 0.3999 - acc: 0.7451 - val_loss: 0.6694 - val_acc: 0.4000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3974 - acc: 0.7451 - val_loss: 0.6704 - val_acc: 0.4000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3951 - acc: 0.7451 - val_loss: 0.6711 - val_acc: 0.4000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3927 - acc: 0.7451 - val_loss: 0.6722 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3901 - acc: 0.7451 - val_loss: 0.6726 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.3881 - acc: 0.7451 - val_loss: 0.6731 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3859 - acc: 0.7647 - val_loss: 0.6740 - val_acc: 0.4000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3845 - acc: 0.7647 - val_loss: 0.6749 - val_acc: 0.4000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3817 - acc: 0.7451 - val_loss: 0.6755 - val_acc: 0.4000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.3797 - acc: 0.7451 - val_loss: 0.6754 - val_acc: 0.4000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3788 - acc: 0.7451 - val_loss: 0.6735 - val_acc: 0.4000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3755 - acc: 0.7647 - val_loss: 0.6728 - val_acc: 0.4000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3737 - acc: 0.7647 - val_loss: 0.6730 - val_acc: 0.4000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3718 - acc: 0.7647 - val_loss: 0.6734 - val_acc: 0.4000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3701 - acc: 0.7647 - val_loss: 0.6735 - val_acc: 0.4000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3687 - acc: 0.7843 - val_loss: 0.6715 - val_acc: 0.4000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3672 - acc: 0.7843 - val_loss: 0.6695 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.3658 - acc: 0.7843 - val_loss: 0.6678 - val_acc: 0.4000\n",
      "2017-04-06\n",
      "2017-04-07\n",
      "2017-04-10\n",
      "2017-04-11\n",
      "2017-04-12\n",
      "2017-04-13\n",
      "2017-04-14\n",
      "2017-04-17\n",
      "2017-04-18\n",
      "2017-04-19\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.4182 - acc: 0.3725 - val_loss: 0.1897 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.3323 - acc: 0.3725 - val_loss: 0.1844 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.2687 - acc: 0.3725 - val_loss: 0.1815 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.2224 - acc: 0.3725 - val_loss: 0.1791 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1805 - acc: 0.3725 - val_loss: 0.1767 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1388 - acc: 0.4118 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0972 - acc: 0.3922 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.0624 - acc: 0.4314 - val_loss: 0.1673 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0364 - acc: 0.4510 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0068 - acc: 0.4510 - val_loss: 0.1657 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9783 - acc: 0.4510 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.9500 - acc: 0.4510 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9260 - acc: 0.4510 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 136us/step - loss: 0.9027 - acc: 0.4510 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.8801 - acc: 0.4510 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.8579 - acc: 0.4510 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.8349 - acc: 0.4314 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8099 - acc: 0.4314 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7863 - acc: 0.4314 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.7642 - acc: 0.4510 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7463 - acc: 0.4510 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7280 - acc: 0.4510 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.7125 - acc: 0.4510 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6955 - acc: 0.4706 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6787 - acc: 0.4902 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.6650 - acc: 0.4902 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6529 - acc: 0.4902 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6403 - acc: 0.5098 - val_loss: 0.1564 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6270 - acc: 0.5098 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6171 - acc: 0.5294 - val_loss: 0.1549 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6081 - acc: 0.5294 - val_loss: 0.1544 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5964 - acc: 0.5098 - val_loss: 0.1559 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5866 - acc: 0.5294 - val_loss: 0.1550 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5770 - acc: 0.5686 - val_loss: 0.1556 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 569us/step - loss: 0.5683 - acc: 0.5686 - val_loss: 0.1553 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5589 - acc: 0.5686 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5524 - acc: 0.5686 - val_loss: 0.1553 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5451 - acc: 0.5882 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5380 - acc: 0.5882 - val_loss: 0.1564 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.5316 - acc: 0.5882 - val_loss: 0.1549 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5250 - acc: 0.6078 - val_loss: 0.1569 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5192 - acc: 0.6078 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.5132 - acc: 0.6471 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5073 - acc: 0.6275 - val_loss: 0.1570 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5011 - acc: 0.6275 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4957 - acc: 0.6275 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4896 - acc: 0.6667 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.4848 - acc: 0.6471 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4804 - acc: 0.6471 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4752 - acc: 0.6471 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4707 - acc: 0.6471 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4662 - acc: 0.6471 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4616 - acc: 0.6471 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4578 - acc: 0.6471 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4545 - acc: 0.6471 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4500 - acc: 0.6471 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4458 - acc: 0.6471 - val_loss: 0.1693 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4425 - acc: 0.6471 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4380 - acc: 0.6471 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4346 - acc: 0.6667 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4300 - acc: 0.6863 - val_loss: 0.1738 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4264 - acc: 0.6863 - val_loss: 0.1765 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4697 - acc: 0.593 - 0s 255us/step - loss: 0.4231 - acc: 0.6863 - val_loss: 0.1761 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4194 - acc: 0.6863 - val_loss: 0.1752 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.4165 - acc: 0.6863 - val_loss: 0.1779 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4135 - acc: 0.7059 - val_loss: 0.1820 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4098 - acc: 0.7059 - val_loss: 0.1832 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4063 - acc: 0.7059 - val_loss: 0.1863 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4119 - acc: 0.656 - 0s 196us/step - loss: 0.4032 - acc: 0.7255 - val_loss: 0.1876 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3996 - acc: 0.7255 - val_loss: 0.1900 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3969 - acc: 0.7255 - val_loss: 0.1910 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3952 - acc: 0.7255 - val_loss: 0.1905 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3917 - acc: 0.7255 - val_loss: 0.1947 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3892 - acc: 0.7255 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.3864 - acc: 0.7255 - val_loss: 0.2063 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3843 - acc: 0.7255 - val_loss: 0.2110 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3813 - acc: 0.7255 - val_loss: 0.2130 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3786 - acc: 0.7255 - val_loss: 0.2165 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3762 - acc: 0.7451 - val_loss: 0.2198 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3738 - acc: 0.7255 - val_loss: 0.2303 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3714 - acc: 0.7451 - val_loss: 0.2370 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3691 - acc: 0.7451 - val_loss: 0.2384 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 282us/step - loss: 0.3664 - acc: 0.7451 - val_loss: 0.2411 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3642 - acc: 0.7451 - val_loss: 0.2458 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3612 - acc: 0.7451 - val_loss: 0.2551 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.3588 - acc: 0.7451 - val_loss: 0.2635 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3570 - acc: 0.7451 - val_loss: 0.2625 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3548 - acc: 0.7255 - val_loss: 0.2713 - val_acc: 0.9000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3519 - acc: 0.7255 - val_loss: 0.2747 - val_acc: 0.9000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3510 - acc: 0.7451 - val_loss: 0.2935 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3473 - acc: 0.7451 - val_loss: 0.3091 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3445 - acc: 0.7647 - val_loss: 0.3148 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3405 - acc: 0.7843 - val_loss: 0.3258 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3382 - acc: 0.7843 - val_loss: 0.3405 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3348 - acc: 0.7647 - val_loss: 0.3521 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3322 - acc: 0.7647 - val_loss: 0.3612 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3302 - acc: 0.7647 - val_loss: 0.3640 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3287 - acc: 0.7647 - val_loss: 0.3738 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3256 - acc: 0.7647 - val_loss: 0.3979 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3228 - acc: 0.7647 - val_loss: 0.3969 - val_acc: 0.8000\n",
      "2017-04-20\n",
      "2017-04-21\n",
      "2017-04-24\n",
      "2017-04-25\n",
      "2017-04-26\n",
      "2017-04-27\n",
      "2017-04-28\n",
      "2017-05-02\n",
      "2017-05-03\n",
      "2017-05-04\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 0.5283 - acc: 0.7059 - val_loss: 2.4275 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 0.5030 - acc: 0.7255 - val_loss: 2.3500 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4877 - acc: 0.7255 - val_loss: 2.2829 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4748 - acc: 0.7255 - val_loss: 2.2321 - val_acc: 0.3000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4659 - acc: 0.7255 - val_loss: 2.1812 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4559 - acc: 0.7255 - val_loss: 2.1385 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4488 - acc: 0.7451 - val_loss: 2.1220 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4438 - acc: 0.7451 - val_loss: 2.0770 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4362 - acc: 0.7647 - val_loss: 2.0587 - val_acc: 0.3000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4311 - acc: 0.7843 - val_loss: 2.0471 - val_acc: 0.3000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.4254 - acc: 0.8039 - val_loss: 2.0345 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4209 - acc: 0.8039 - val_loss: 1.9959 - val_acc: 0.3000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4147 - acc: 0.8039 - val_loss: 1.9555 - val_acc: 0.3000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4097 - acc: 0.8039 - val_loss: 1.9227 - val_acc: 0.3000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4047 - acc: 0.8039 - val_loss: 1.9152 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.4024 - acc: 0.8039 - val_loss: 1.8729 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 338us/step - loss: 0.3949 - acc: 0.8039 - val_loss: 1.8426 - val_acc: 0.3000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3896 - acc: 0.8039 - val_loss: 1.8346 - val_acc: 0.3000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3861 - acc: 0.8039 - val_loss: 1.8179 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3815 - acc: 0.8039 - val_loss: 1.7965 - val_acc: 0.3000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3772 - acc: 0.8235 - val_loss: 1.7711 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3726 - acc: 0.8235 - val_loss: 1.7632 - val_acc: 0.4000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3696 - acc: 0.8235 - val_loss: 1.7657 - val_acc: 0.4000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3666 - acc: 0.8235 - val_loss: 1.7489 - val_acc: 0.4000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3621 - acc: 0.8235 - val_loss: 1.7332 - val_acc: 0.4000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.3576 - acc: 0.8235 - val_loss: 1.7290 - val_acc: 0.4000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3535 - acc: 0.8235 - val_loss: 1.7192 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3498 - acc: 0.8235 - val_loss: 1.7090 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3450 - acc: 0.8235 - val_loss: 1.7098 - val_acc: 0.4000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3416 - acc: 0.8431 - val_loss: 1.7129 - val_acc: 0.4000\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 255us/step - loss: 0.3391 - acc: 0.8431 - val_loss: 1.7063 - val_acc: 0.4000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3351 - acc: 0.8627 - val_loss: 1.6952 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3317 - acc: 0.8627 - val_loss: 1.6825 - val_acc: 0.4000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3289 - acc: 0.8824 - val_loss: 1.6856 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3250 - acc: 0.8824 - val_loss: 1.6780 - val_acc: 0.4000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3226 - acc: 0.8824 - val_loss: 1.6879 - val_acc: 0.4000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3199 - acc: 0.8824 - val_loss: 1.6985 - val_acc: 0.4000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.3184 - acc: 0.8824 - val_loss: 1.7031 - val_acc: 0.4000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2848 - acc: 0.875 - 0s 236us/step - loss: 0.3148 - acc: 0.8824 - val_loss: 1.7113 - val_acc: 0.4000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 174us/step - loss: 0.3123 - acc: 0.9020 - val_loss: 1.7023 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3092 - acc: 0.9020 - val_loss: 1.7076 - val_acc: 0.4000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3076 - acc: 0.9020 - val_loss: 1.7093 - val_acc: 0.4000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3057 - acc: 0.9020 - val_loss: 1.7001 - val_acc: 0.4000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3025 - acc: 0.9020 - val_loss: 1.7124 - val_acc: 0.4000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3004 - acc: 0.9020 - val_loss: 1.7110 - val_acc: 0.4000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2981 - acc: 0.9020 - val_loss: 1.7108 - val_acc: 0.4000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2963 - acc: 0.9020 - val_loss: 1.7210 - val_acc: 0.4000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2945 - acc: 0.9020 - val_loss: 1.7273 - val_acc: 0.4000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2921 - acc: 0.9020 - val_loss: 1.7352 - val_acc: 0.4000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2908 - acc: 0.9020 - val_loss: 1.7302 - val_acc: 0.4000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2878 - acc: 0.9020 - val_loss: 1.7393 - val_acc: 0.4000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2860 - acc: 0.9020 - val_loss: 1.7532 - val_acc: 0.4000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 230us/step - loss: 0.2839 - acc: 0.9020 - val_loss: 1.7680 - val_acc: 0.4000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2821 - acc: 0.9020 - val_loss: 1.7821 - val_acc: 0.4000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2818 - acc: 0.9020 - val_loss: 1.7905 - val_acc: 0.4000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2783 - acc: 0.9020 - val_loss: 1.7943 - val_acc: 0.4000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2764 - acc: 0.9020 - val_loss: 1.7979 - val_acc: 0.4000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 343us/step - loss: 0.2746 - acc: 0.9020 - val_loss: 1.8052 - val_acc: 0.4000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2763 - acc: 0.875 - 0s 314us/step - loss: 0.2728 - acc: 0.9020 - val_loss: 1.8128 - val_acc: 0.4000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2716 - acc: 0.9020 - val_loss: 1.8294 - val_acc: 0.4000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2694 - acc: 0.9216 - val_loss: 1.8322 - val_acc: 0.4000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.2675 - acc: 0.9216 - val_loss: 1.8332 - val_acc: 0.4000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2660 - acc: 0.9216 - val_loss: 1.8420 - val_acc: 0.4000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2643 - acc: 0.9216 - val_loss: 1.8512 - val_acc: 0.4000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2631 - acc: 0.9412 - val_loss: 1.8496 - val_acc: 0.4000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.2621 - acc: 0.9412 - val_loss: 1.8551 - val_acc: 0.4000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2596 - acc: 0.9412 - val_loss: 1.8704 - val_acc: 0.4000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 383us/step - loss: 0.2585 - acc: 0.9412 - val_loss: 1.8912 - val_acc: 0.4000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2565 - acc: 0.9412 - val_loss: 1.9021 - val_acc: 0.4000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2548 - acc: 0.9412 - val_loss: 1.9115 - val_acc: 0.4000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2534 - acc: 0.9412 - val_loss: 1.9238 - val_acc: 0.4000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2514 - acc: 0.9412 - val_loss: 1.9291 - val_acc: 0.4000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2506 - acc: 0.9412 - val_loss: 1.9432 - val_acc: 0.4000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 408us/step - loss: 0.2483 - acc: 0.9412 - val_loss: 1.9524 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2472 - acc: 0.9412 - val_loss: 1.9668 - val_acc: 0.4000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2457 - acc: 0.9412 - val_loss: 1.9750 - val_acc: 0.4000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2436 - acc: 0.9412 - val_loss: 1.9813 - val_acc: 0.4000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2428 - acc: 0.9412 - val_loss: 1.9988 - val_acc: 0.4000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2411 - acc: 0.9412 - val_loss: 2.0122 - val_acc: 0.4000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2400 - acc: 0.9412 - val_loss: 2.0247 - val_acc: 0.4000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2393 - acc: 0.9412 - val_loss: 2.0267 - val_acc: 0.4000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.2378 - acc: 0.9412 - val_loss: 2.0336 - val_acc: 0.4000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2365 - acc: 0.9412 - val_loss: 2.0338 - val_acc: 0.4000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2351 - acc: 0.9412 - val_loss: 2.0471 - val_acc: 0.4000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2341 - acc: 0.9412 - val_loss: 2.0486 - val_acc: 0.4000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2341 - acc: 0.9412 - val_loss: 2.0581 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2320 - acc: 0.9412 - val_loss: 2.0605 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2310 - acc: 0.9412 - val_loss: 2.0681 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2298 - acc: 0.9412 - val_loss: 2.0821 - val_acc: 0.4000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2288 - acc: 0.9412 - val_loss: 2.1041 - val_acc: 0.4000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2277 - acc: 0.9412 - val_loss: 2.1026 - val_acc: 0.4000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2262 - acc: 0.9412 - val_loss: 2.1176 - val_acc: 0.4000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2261 - acc: 0.9412 - val_loss: 2.1435 - val_acc: 0.4000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.2243 - acc: 0.9412 - val_loss: 2.1589 - val_acc: 0.4000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2231 - acc: 0.9412 - val_loss: 2.1732 - val_acc: 0.4000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 326us/step - loss: 0.2223 - acc: 0.9412 - val_loss: 2.1727 - val_acc: 0.4000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2209 - acc: 0.9412 - val_loss: 2.1944 - val_acc: 0.4000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 279us/step - loss: 0.2208 - acc: 0.9412 - val_loss: 2.2048 - val_acc: 0.4000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2181 - acc: 0.9412 - val_loss: 2.2187 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.2173 - acc: 0.9412 - val_loss: 2.2474 - val_acc: 0.4000\n",
      "2017-05-05\n",
      "2017-05-08\n",
      "2017-05-09\n",
      "2017-05-10\n",
      "2017-05-11\n",
      "2017-05-12\n",
      "2017-05-15\n",
      "2017-05-16\n",
      "2017-05-17\n",
      "2017-05-18\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 0.6294 - acc: 0.7059 - val_loss: 4.2394 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.5746 - acc: 0.7255 - val_loss: 4.0697 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5354 - acc: 0.7451 - val_loss: 3.9629 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.5060 - acc: 0.7647 - val_loss: 3.8931 - val_acc: 0.3000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4859 - acc: 0.7843 - val_loss: 3.8320 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.4657 - acc: 0.7843 - val_loss: 3.7666 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.4480 - acc: 0.8039 - val_loss: 3.7047 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4319 - acc: 0.8235 - val_loss: 3.6462 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 266us/step - loss: 0.4189 - acc: 0.8235 - val_loss: 3.5863 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4046 - acc: 0.8235 - val_loss: 3.5307 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3923 - acc: 0.8431 - val_loss: 3.4876 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3825 - acc: 0.8431 - val_loss: 3.4529 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3729 - acc: 0.8431 - val_loss: 3.4120 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3652 - acc: 0.8431 - val_loss: 3.3898 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 411us/step - loss: 0.3567 - acc: 0.8431 - val_loss: 3.3599 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3487 - acc: 0.8431 - val_loss: 3.3258 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3407 - acc: 0.8627 - val_loss: 3.2857 - val_acc: 0.4000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3338 - acc: 0.8627 - val_loss: 3.2468 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3262 - acc: 0.8824 - val_loss: 3.2109 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3198 - acc: 0.9020 - val_loss: 3.1842 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3139 - acc: 0.9020 - val_loss: 3.1540 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3088 - acc: 0.9020 - val_loss: 3.1365 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 296us/step - loss: 0.3047 - acc: 0.9020 - val_loss: 3.1175 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3000 - acc: 0.9020 - val_loss: 3.0949 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2965 - acc: 0.9020 - val_loss: 3.0620 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2803 - acc: 0.906 - 0s 215us/step - loss: 0.2903 - acc: 0.9020 - val_loss: 3.0593 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2863 - acc: 0.9020 - val_loss: 3.0388 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2821 - acc: 0.9020 - val_loss: 3.0282 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2783 - acc: 0.9020 - val_loss: 3.0127 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.2759 - acc: 0.9020 - val_loss: 2.9949 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2724 - acc: 0.9020 - val_loss: 2.9913 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2691 - acc: 0.9020 - val_loss: 2.9812 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2664 - acc: 0.9020 - val_loss: 2.9626 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2635 - acc: 0.9020 - val_loss: 2.9467 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2618 - acc: 0.9020 - val_loss: 2.9275 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2584 - acc: 0.9020 - val_loss: 2.9184 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2562 - acc: 0.906 - 0s 317us/step - loss: 0.2565 - acc: 0.8824 - val_loss: 2.9069 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2556 - acc: 0.8824 - val_loss: 2.9023 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.2536 - acc: 0.9020 - val_loss: 2.8981 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2516 - acc: 0.9020 - val_loss: 2.8884 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2500 - acc: 0.9020 - val_loss: 2.8861 - val_acc: 0.5000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2486 - acc: 0.8824 - val_loss: 2.8918 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 169us/step - loss: 0.2471 - acc: 0.8824 - val_loss: 2.8815 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2463 - acc: 0.8824 - val_loss: 2.8613 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2445 - acc: 0.8824 - val_loss: 2.8558 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2429 - acc: 0.8824 - val_loss: 2.8513 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2421 - acc: 0.9020 - val_loss: 2.8396 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2405 - acc: 0.9020 - val_loss: 2.8359 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2394 - acc: 0.9020 - val_loss: 2.8222 - val_acc: 0.5000\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 216us/step - loss: 0.2375 - acc: 0.9020 - val_loss: 2.8177 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2363 - acc: 0.9020 - val_loss: 2.7974 - val_acc: 0.5000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2351 - acc: 0.9020 - val_loss: 2.7915 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2335 - acc: 0.9020 - val_loss: 2.7805 - val_acc: 0.5000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2324 - acc: 0.9020 - val_loss: 2.7682 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2308 - acc: 0.9020 - val_loss: 2.7569 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2302 - acc: 0.9020 - val_loss: 2.7384 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2286 - acc: 0.9020 - val_loss: 2.7235 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.2278 - acc: 0.9020 - val_loss: 2.7076 - val_acc: 0.5000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2261 - acc: 0.9216 - val_loss: 2.6874 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2244 - acc: 0.9216 - val_loss: 2.6757 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2233 - acc: 0.9216 - val_loss: 2.6609 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2221 - acc: 0.9216 - val_loss: 2.6563 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2209 - acc: 0.9216 - val_loss: 2.6384 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2205 - acc: 0.9216 - val_loss: 2.6282 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2187 - acc: 0.9216 - val_loss: 2.6213 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2174 - acc: 0.9216 - val_loss: 2.6189 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2159 - acc: 0.9216 - val_loss: 2.6192 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 0.2140 - acc: 0.9216 - val_loss: 2.6195 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2144 - acc: 0.9216 - val_loss: 2.6028 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2119 - acc: 0.9216 - val_loss: 2.6044 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2110 - acc: 0.9216 - val_loss: 2.6000 - val_acc: 0.5000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2099 - acc: 0.9216 - val_loss: 2.5982 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2090 - acc: 0.9216 - val_loss: 2.5928 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2080 - acc: 0.9216 - val_loss: 2.5826 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2068 - acc: 0.9216 - val_loss: 2.5764 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2061 - acc: 0.9216 - val_loss: 2.5739 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2050 - acc: 0.9216 - val_loss: 2.5681 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2043 - acc: 0.9216 - val_loss: 2.5590 - val_acc: 0.5000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2038 - acc: 0.9216 - val_loss: 2.5562 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2017 - acc: 0.9216 - val_loss: 2.5551 - val_acc: 0.5000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2010 - acc: 0.9216 - val_loss: 2.5364 - val_acc: 0.5000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1993 - acc: 0.9216 - val_loss: 2.5329 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1982 - acc: 0.9216 - val_loss: 2.5248 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1966 - acc: 0.9216 - val_loss: 2.5411 - val_acc: 0.5000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1956 - acc: 0.9216 - val_loss: 2.5461 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1941 - acc: 0.9216 - val_loss: 2.5506 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1931 - acc: 0.9216 - val_loss: 2.5429 - val_acc: 0.5000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.1915 - acc: 0.9216 - val_loss: 2.5350 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1907 - acc: 0.9216 - val_loss: 2.5266 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1907 - acc: 0.9216 - val_loss: 2.5209 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1886 - acc: 0.9216 - val_loss: 2.5336 - val_acc: 0.5000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1876 - acc: 0.9216 - val_loss: 2.5363 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.1867 - acc: 0.9216 - val_loss: 2.5322 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1862 - acc: 0.9216 - val_loss: 2.5270 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1856 - acc: 0.9216 - val_loss: 2.5206 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1848 - acc: 0.9216 - val_loss: 2.5187 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1843 - acc: 0.9216 - val_loss: 2.5179 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1827 - acc: 0.9216 - val_loss: 2.5236 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.1821 - acc: 0.9216 - val_loss: 2.5147 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1806 - acc: 0.9216 - val_loss: 2.5094 - val_acc: 0.5000\n",
      "2017-05-19\n",
      "2017-05-22\n",
      "2017-05-23\n",
      "2017-05-24\n",
      "2017-05-25\n",
      "2017-05-26\n",
      "2017-05-31\n",
      "2017-06-01\n",
      "2017-06-02\n",
      "2017-06-05\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 0.5149 - acc: 0.8627 - val_loss: 2.4364 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.4808 - acc: 0.8627 - val_loss: 2.5639 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4591 - acc: 0.8627 - val_loss: 2.6360 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 210us/step - loss: 0.4431 - acc: 0.8627 - val_loss: 2.7203 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.4301 - acc: 0.8627 - val_loss: 2.7761 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4185 - acc: 0.8627 - val_loss: 2.8299 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.4088 - acc: 0.8627 - val_loss: 2.8832 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3995 - acc: 0.8627 - val_loss: 2.9328 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5096 - acc: 0.812 - 0s 176us/step - loss: 0.3885 - acc: 0.8627 - val_loss: 3.0103 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3794 - acc: 0.8627 - val_loss: 3.0655 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 304us/step - loss: 0.3689 - acc: 0.8627 - val_loss: 3.1306 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3580 - acc: 0.8627 - val_loss: 3.2117 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3457 - acc: 0.8627 - val_loss: 3.2682 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3357 - acc: 0.8627 - val_loss: 3.3395 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3268 - acc: 0.8627 - val_loss: 3.4044 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3194 - acc: 0.8627 - val_loss: 3.4388 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 442us/step - loss: 0.3105 - acc: 0.8627 - val_loss: 3.5078 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3026 - acc: 0.8627 - val_loss: 3.5790 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2931 - acc: 0.8431 - val_loss: 3.6272 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2856 - acc: 0.8431 - val_loss: 3.6612 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2799 - acc: 0.8431 - val_loss: 3.7224 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.2744 - acc: 0.8431 - val_loss: 3.7532 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2698 - acc: 0.8431 - val_loss: 3.7847 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2667 - acc: 0.8431 - val_loss: 3.8491 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2588 - acc: 0.8431 - val_loss: 3.8630 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2534 - acc: 0.8431 - val_loss: 3.8994 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2487 - acc: 0.8431 - val_loss: 3.9413 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2431 - acc: 0.8431 - val_loss: 3.9734 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2416 - acc: 0.8431 - val_loss: 3.9812 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2371 - acc: 0.8431 - val_loss: 4.0121 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2332 - acc: 0.8627 - val_loss: 4.0645 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1579 - acc: 0.937 - 0s 196us/step - loss: 0.2306 - acc: 0.8627 - val_loss: 4.0794 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2263 - acc: 0.8627 - val_loss: 4.1120 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2232 - acc: 0.8627 - val_loss: 4.1529 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2207 - acc: 0.8627 - val_loss: 4.1747 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.2186 - acc: 0.8627 - val_loss: 4.1849 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2142 - acc: 0.8627 - val_loss: 4.2396 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2110 - acc: 0.8627 - val_loss: 4.2854 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2071 - acc: 0.8627 - val_loss: 4.3255 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2034 - acc: 0.8627 - val_loss: 4.3437 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2019 - acc: 0.8627 - val_loss: 4.3931 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1986 - acc: 0.8627 - val_loss: 4.4346 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1947 - acc: 0.8627 - val_loss: 4.4538 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1935 - acc: 0.8627 - val_loss: 4.4411 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1904 - acc: 0.8627 - val_loss: 4.4495 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1899 - acc: 0.8627 - val_loss: 4.4412 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1866 - acc: 0.8627 - val_loss: 4.4401 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1842 - acc: 0.8627 - val_loss: 4.4654 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 338us/step - loss: 0.1834 - acc: 0.8627 - val_loss: 4.5051 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1399 - acc: 0.906 - 0s 216us/step - loss: 0.1806 - acc: 0.8627 - val_loss: 4.5230 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1778 - acc: 0.8627 - val_loss: 4.5348 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1760 - acc: 0.8627 - val_loss: 4.5511 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1737 - acc: 0.8824 - val_loss: 4.5441 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1727 - acc: 0.8824 - val_loss: 4.5265 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1698 - acc: 0.8824 - val_loss: 4.5354 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1692 - acc: 0.8824 - val_loss: 4.5111 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1672 - acc: 0.8824 - val_loss: 4.5256 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1659 - acc: 0.8824 - val_loss: 4.4982 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1633 - acc: 0.8824 - val_loss: 4.5009 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1616 - acc: 0.8824 - val_loss: 4.4998 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1596 - acc: 0.8824 - val_loss: 4.5189 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1588 - acc: 0.8824 - val_loss: 4.5441 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1573 - acc: 0.8824 - val_loss: 4.5484 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1552 - acc: 0.9020 - val_loss: 4.5292 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1544 - acc: 0.8824 - val_loss: 4.5476 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1531 - acc: 0.9020 - val_loss: 4.5187 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1539 - acc: 0.906 - 0s 333us/step - loss: 0.1507 - acc: 0.9020 - val_loss: 4.5335 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.1493 - acc: 0.9216 - val_loss: 4.5383 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1486 - acc: 0.9020 - val_loss: 4.5529 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1479 - acc: 0.9216 - val_loss: 4.5712 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1462 - acc: 0.9412 - val_loss: 4.5795 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1444 - acc: 0.9412 - val_loss: 4.5507 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1428 - acc: 0.9412 - val_loss: 4.5490 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1402 - acc: 0.9412 - val_loss: 4.5654 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1382 - acc: 0.9412 - val_loss: 4.5672 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1366 - acc: 0.9412 - val_loss: 4.5292 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1345 - acc: 0.9412 - val_loss: 4.5558 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1325 - acc: 0.9608 - val_loss: 4.5476 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1308 - acc: 0.9608 - val_loss: 4.5304 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1288 - acc: 0.9608 - val_loss: 4.5212 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1270 - acc: 0.9608 - val_loss: 4.5487 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1256 - acc: 0.9608 - val_loss: 4.5398 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1237 - acc: 0.9412 - val_loss: 4.5804 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1216 - acc: 0.9608 - val_loss: 4.5961 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1204 - acc: 0.9608 - val_loss: 4.6197 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1187 - acc: 0.9608 - val_loss: 4.6337 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1177 - acc: 0.9608 - val_loss: 4.6167 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1151 - acc: 0.9412 - val_loss: 4.6441 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1120 - acc: 0.9608 - val_loss: 4.6473 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1096 - acc: 0.9608 - val_loss: 4.6561 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.9608 - val_loss: 4.6350 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 454us/step - loss: 0.1053 - acc: 0.9608 - val_loss: 4.6354 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1035 - acc: 0.9608 - val_loss: 4.6662 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1013 - acc: 0.9608 - val_loss: 4.6801 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1003 - acc: 0.9608 - val_loss: 4.7091 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0974 - acc: 0.9608 - val_loss: 4.7122 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0948 - acc: 0.9608 - val_loss: 4.6955 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0911 - acc: 0.9608 - val_loss: 4.7113 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.0894 - acc: 0.9608 - val_loss: 4.7052 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1126 - acc: 0.968 - 0s 196us/step - loss: 0.0861 - acc: 0.9804 - val_loss: 4.7202 - val_acc: 0.0000e+00\n",
      "2017-06-06\n",
      "2017-06-07\n",
      "2017-06-08\n",
      "2017-06-09\n",
      "2017-06-12\n",
      "2017-06-13\n",
      "2017-06-14\n",
      "2017-06-15\n",
      "2017-06-16\n",
      "2017-06-19\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 1.6978 - acc: 0.6275 - val_loss: 11.4125 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 1.6138 - acc: 0.6471 - val_loss: 11.4362 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 1.5665 - acc: 0.6471 - val_loss: 11.4433 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5277 - acc: 0.6471 - val_loss: 11.4639 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.5033 - acc: 0.6471 - val_loss: 11.4701 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.4607 - acc: 0.6667 - val_loss: 11.4779 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.4262 - acc: 0.6863 - val_loss: 11.4861 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3882 - acc: 0.6863 - val_loss: 11.4814 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.3548 - acc: 0.6667 - val_loss: 11.4916 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3260 - acc: 0.6667 - val_loss: 11.4986 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9759 - acc: 0.718 - 0s 197us/step - loss: 1.2969 - acc: 0.6863 - val_loss: 11.5058 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 1.2657 - acc: 0.6863 - val_loss: 11.5129 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.2415 - acc: 0.6863 - val_loss: 11.5226 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.2100 - acc: 0.6863 - val_loss: 11.5250 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.1810 - acc: 0.6863 - val_loss: 11.5382 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.1559 - acc: 0.6863 - val_loss: 11.5510 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.1319 - acc: 0.6863 - val_loss: 11.5593 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1083 - acc: 0.6863 - val_loss: 11.5652 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0838 - acc: 0.6863 - val_loss: 11.5708 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.0598 - acc: 0.6863 - val_loss: 11.5762 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0406 - acc: 0.7059 - val_loss: 11.5807 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.0120 - acc: 0.7059 - val_loss: 11.5760 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9919 - acc: 0.7059 - val_loss: 11.5600 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 549us/step - loss: 0.9714 - acc: 0.7059 - val_loss: 11.5546 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.9552 - acc: 0.7059 - val_loss: 11.5418 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9376 - acc: 0.7059 - val_loss: 11.5301 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9216 - acc: 0.7059 - val_loss: 11.5210 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 133us/step - loss: 0.9053 - acc: 0.7059 - val_loss: 11.5156 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8914 - acc: 0.7059 - val_loss: 11.5103 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8755 - acc: 0.7059 - val_loss: 11.5055 - val_acc: 0.1000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8643 - acc: 0.7059 - val_loss: 11.5062 - val_acc: 0.1000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.8499 - acc: 0.7059 - val_loss: 11.5031 - val_acc: 0.1000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8327 - acc: 0.7059 - val_loss: 11.4936 - val_acc: 0.1000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.8193 - acc: 0.7059 - val_loss: 11.4791 - val_acc: 0.1000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 238us/step - loss: 0.8045 - acc: 0.7059 - val_loss: 11.4632 - val_acc: 0.1000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7906 - acc: 0.7255 - val_loss: 11.4655 - val_acc: 0.1000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.7771 - acc: 0.7059 - val_loss: 11.4544 - val_acc: 0.1000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7627 - acc: 0.7059 - val_loss: 11.4460 - val_acc: 0.1000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7472 - acc: 0.7451 - val_loss: 11.4329 - val_acc: 0.1000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7332 - acc: 0.7451 - val_loss: 11.4275 - val_acc: 0.1000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7199 - acc: 0.7451 - val_loss: 11.4143 - val_acc: 0.1000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 649us/step - loss: 0.7085 - acc: 0.7451 - val_loss: 11.4079 - val_acc: 0.1000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6955 - acc: 0.7647 - val_loss: 11.4032 - val_acc: 0.1000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.6863 - acc: 0.7451 - val_loss: 11.3851 - val_acc: 0.1000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6760 - acc: 0.7647 - val_loss: 11.3676 - val_acc: 0.1000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 168us/step - loss: 0.6607 - acc: 0.7647 - val_loss: 11.3701 - val_acc: 0.1000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6479 - acc: 0.7647 - val_loss: 11.3609 - val_acc: 0.1000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6362 - acc: 0.7843 - val_loss: 11.3468 - val_acc: 0.1000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 324us/step - loss: 0.6238 - acc: 0.7843 - val_loss: 11.3147 - val_acc: 0.1000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6117 - acc: 0.7843 - val_loss: 11.2943 - val_acc: 0.1000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 269us/step - loss: 0.6035 - acc: 0.7843 - val_loss: 11.2856 - val_acc: 0.1000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.5946 - acc: 0.7843 - val_loss: 11.2739 - val_acc: 0.1000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5858 - acc: 0.8039 - val_loss: 11.2472 - val_acc: 0.1000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.5739 - acc: 0.8039 - val_loss: 11.2251 - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5630 - acc: 0.8039 - val_loss: 11.2048 - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5526 - acc: 0.8039 - val_loss: 11.1756 - val_acc: 0.1000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5404 - acc: 0.8039 - val_loss: 11.1688 - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.5305 - acc: 0.8039 - val_loss: 11.1473 - val_acc: 0.1000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5209 - acc: 0.8235 - val_loss: 11.1133 - val_acc: 0.1000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5092 - acc: 0.8235 - val_loss: 11.1026 - val_acc: 0.1000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4995 - acc: 0.8235 - val_loss: 11.0752 - val_acc: 0.1000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4899 - acc: 0.8235 - val_loss: 11.0513 - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4820 - acc: 0.8235 - val_loss: 11.0310 - val_acc: 0.1000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4753 - acc: 0.8235 - val_loss: 11.0003 - val_acc: 0.1000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4648 - acc: 0.8235 - val_loss: 10.9642 - val_acc: 0.1000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4550 - acc: 0.8235 - val_loss: 10.9403 - val_acc: 0.1000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4485 - acc: 0.8235 - val_loss: 10.9017 - val_acc: 0.1000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4403 - acc: 0.8235 - val_loss: 10.8658 - val_acc: 0.1000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4336 - acc: 0.8235 - val_loss: 10.8578 - val_acc: 0.1000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4243 - acc: 0.8431 - val_loss: 10.8237 - val_acc: 0.1000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4187 - acc: 0.8627 - val_loss: 10.8237 - val_acc: 0.1000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4112 - acc: 0.8824 - val_loss: 10.7942 - val_acc: 0.1000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4029 - acc: 0.8824 - val_loss: 10.7775 - val_acc: 0.1000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3979 - acc: 0.8824 - val_loss: 10.7660 - val_acc: 0.1000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3907 - acc: 0.9020 - val_loss: 10.7281 - val_acc: 0.1000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3839 - acc: 0.9020 - val_loss: 10.6892 - val_acc: 0.1000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3758 - acc: 0.8627 - val_loss: 10.6650 - val_acc: 0.1000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3719 - acc: 0.8627 - val_loss: 10.6592 - val_acc: 0.1000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3650 - acc: 0.8824 - val_loss: 10.6451 - val_acc: 0.1000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3599 - acc: 0.8824 - val_loss: 10.6403 - val_acc: 0.1000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3529 - acc: 0.9020 - val_loss: 10.6329 - val_acc: 0.1000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3447 - acc: 0.9020 - val_loss: 10.6012 - val_acc: 0.1000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3387 - acc: 0.9020 - val_loss: 10.5568 - val_acc: 0.1000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3274 - acc: 0.9020 - val_loss: 10.5492 - val_acc: 0.1000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3221 - acc: 0.9020 - val_loss: 10.5243 - val_acc: 0.1000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3167 - acc: 0.9020 - val_loss: 10.5061 - val_acc: 0.1000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3131 - acc: 0.9020 - val_loss: 10.4988 - val_acc: 0.1000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3077 - acc: 0.9020 - val_loss: 10.4510 - val_acc: 0.1000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2987 - acc: 0.9020 - val_loss: 10.4281 - val_acc: 0.1000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2959 - acc: 0.9020 - val_loss: 10.3771 - val_acc: 0.1000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2883 - acc: 0.9020 - val_loss: 10.3370 - val_acc: 0.1000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2840 - acc: 0.9020 - val_loss: 10.3023 - val_acc: 0.1000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 363us/step - loss: 0.2777 - acc: 0.9020 - val_loss: 10.2931 - val_acc: 0.1000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2743 - acc: 0.9020 - val_loss: 10.2618 - val_acc: 0.1000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2682 - acc: 0.9020 - val_loss: 10.2417 - val_acc: 0.1000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2631 - acc: 0.9020 - val_loss: 10.2162 - val_acc: 0.1000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2582 - acc: 0.9020 - val_loss: 10.1962 - val_acc: 0.1000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2543 - acc: 0.9020 - val_loss: 10.1956 - val_acc: 0.1000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2500 - acc: 0.9020 - val_loss: 10.1900 - val_acc: 0.1000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.2465 - acc: 0.9412 - val_loss: 10.1618 - val_acc: 0.1000\n",
      "2017-06-20\n",
      "2017-06-21\n",
      "2017-06-22\n",
      "2017-06-23\n",
      "2017-06-26\n",
      "2017-06-27\n",
      "2017-06-28\n",
      "2017-06-29\n",
      "2017-06-30\n",
      "2017-07-03\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.0068 - acc: 0.6863 - val_loss: 0.0394 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.9119 - acc: 0.6863 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8523 - acc: 0.6863 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8011 - acc: 0.7059 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7593 - acc: 0.7059 - val_loss: 0.0546 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7065 - acc: 0.718 - 0s 305us/step - loss: 0.7242 - acc: 0.7059 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6928 - acc: 0.7255 - val_loss: 0.0626 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6637 - acc: 0.7255 - val_loss: 0.0658 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6423 - acc: 0.7255 - val_loss: 0.0687 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.6185 - acc: 0.7451 - val_loss: 0.0724 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5965 - acc: 0.7647 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 320us/step - loss: 0.5724 - acc: 0.7647 - val_loss: 0.0809 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.5532 - acc: 0.7647 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5336 - acc: 0.8039 - val_loss: 0.0891 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5141 - acc: 0.8235 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4959 - acc: 0.8235 - val_loss: 0.0979 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4815 - acc: 0.8235 - val_loss: 0.1029 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.4653 - acc: 0.8235 - val_loss: 0.1072 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4544 - acc: 0.8235 - val_loss: 0.1117 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.4362 - acc: 0.8431 - val_loss: 0.1170 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4239 - acc: 0.8431 - val_loss: 0.1227 - val_acc: 0.9000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4107 - acc: 0.8431 - val_loss: 0.1293 - val_acc: 0.9000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3977 - acc: 0.8431 - val_loss: 0.1355 - val_acc: 0.9000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3840 - acc: 0.8431 - val_loss: 0.1418 - val_acc: 0.9000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3722 - acc: 0.8431 - val_loss: 0.1488 - val_acc: 0.9000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.3588 - acc: 0.8431 - val_loss: 0.1529 - val_acc: 0.9000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3496 - acc: 0.8431 - val_loss: 0.1573 - val_acc: 0.9000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3386 - acc: 0.8627 - val_loss: 0.1639 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3286 - acc: 0.8627 - val_loss: 0.1689 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3184 - acc: 0.8627 - val_loss: 0.1759 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3081 - acc: 0.8627 - val_loss: 0.1793 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2977 - acc: 0.8627 - val_loss: 0.1831 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2888 - acc: 0.8627 - val_loss: 0.1862 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.2830 - acc: 0.8627 - val_loss: 0.1893 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2724 - acc: 0.8627 - val_loss: 0.1942 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2629 - acc: 0.8627 - val_loss: 0.1971 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2565 - acc: 0.8627 - val_loss: 0.2006 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2499 - acc: 0.8627 - val_loss: 0.2042 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2431 - acc: 0.8627 - val_loss: 0.2065 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2364 - acc: 0.8627 - val_loss: 0.2108 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2292 - acc: 0.8627 - val_loss: 0.2128 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2227 - acc: 0.8824 - val_loss: 0.2163 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2196 - acc: 0.9020 - val_loss: 0.2180 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2133 - acc: 0.9020 - val_loss: 0.2233 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2080 - acc: 0.9020 - val_loss: 0.2264 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2206 - acc: 0.906 - 0s 216us/step - loss: 0.2024 - acc: 0.9216 - val_loss: 0.2303 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1975 - acc: 0.9216 - val_loss: 0.2331 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1936 - acc: 0.9216 - val_loss: 0.2350 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1894 - acc: 0.9216 - val_loss: 0.2389 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1853 - acc: 0.9216 - val_loss: 0.2413 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1811 - acc: 0.9216 - val_loss: 0.2419 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1769 - acc: 0.9216 - val_loss: 0.2449 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.1713 - acc: 0.9216 - val_loss: 0.2476 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1669 - acc: 0.9216 - val_loss: 0.2506 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.1628 - acc: 0.9608 - val_loss: 0.2518 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1573 - acc: 0.9608 - val_loss: 0.2532 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.1524 - acc: 0.9608 - val_loss: 0.2578 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1465 - acc: 0.9608 - val_loss: 0.2592 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.1429 - acc: 0.9608 - val_loss: 0.2627 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1392 - acc: 0.9804 - val_loss: 0.2655 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.1347 - acc: 0.9608 - val_loss: 0.2660 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 250us/step - loss: 0.1315 - acc: 0.9804 - val_loss: 0.2702 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1289 - acc: 0.9804 - val_loss: 0.2737 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1250 - acc: 0.9804 - val_loss: 0.2758 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1221 - acc: 0.9804 - val_loss: 0.2773 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1196 - acc: 0.9804 - val_loss: 0.2789 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1165 - acc: 0.9804 - val_loss: 0.2820 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1147 - acc: 0.9804 - val_loss: 0.2818 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1114 - acc: 0.9804 - val_loss: 0.2852 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1095 - acc: 0.9804 - val_loss: 0.2872 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 273us/step - loss: 0.1066 - acc: 1.0000 - val_loss: 0.2871 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1036 - acc: 0.9804 - val_loss: 0.2899 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1010 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0994 - acc: 0.9804 - val_loss: 0.3000 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 237us/step - loss: 0.0961 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0958 - acc: 0.9804 - val_loss: 0.3095 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.0920 - acc: 1.0000 - val_loss: 0.3168 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.0906 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0873 - acc: 1.0000 - val_loss: 0.3287 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0859 - acc: 1.0000 - val_loss: 0.3372 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.0830 - acc: 1.0000 - val_loss: 0.3481 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.0806 - acc: 1.0000 - val_loss: 0.3559 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0779 - acc: 1.0000 - val_loss: 0.3614 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0762 - acc: 1.0000 - val_loss: 0.3639 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0738 - acc: 1.0000 - val_loss: 0.3688 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.0719 - acc: 1.0000 - val_loss: 0.3711 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.0707 - acc: 1.0000 - val_loss: 0.3728 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0690 - acc: 1.0000 - val_loss: 0.3778 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.0670 - acc: 1.0000 - val_loss: 0.3838 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.0654 - acc: 1.0000 - val_loss: 0.3909 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.0637 - acc: 1.0000 - val_loss: 0.3971 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0621 - acc: 1.0000 - val_loss: 0.4055 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.0604 - acc: 1.0000 - val_loss: 0.4171 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.0592 - acc: 1.0000 - val_loss: 0.4304 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.0582 - acc: 1.0000 - val_loss: 0.4375 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.0562 - acc: 1.0000 - val_loss: 0.4483 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.4573 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0535 - acc: 1.0000 - val_loss: 0.4659 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.0528 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 0.0515 - acc: 1.0000 - val_loss: 0.4757 - val_acc: 0.8000\n",
      "2017-07-04\n",
      "2017-07-05\n",
      "2017-07-06\n",
      "2017-07-07\n",
      "2017-07-10\n",
      "2017-07-11\n",
      "2017-07-12\n",
      "2017-07-13\n",
      "2017-07-14\n",
      "2017-07-17\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 0.1274 - acc: 0.9804 - val_loss: 2.5077 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1155 - acc: 0.9804 - val_loss: 2.5387 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1058 - acc: 0.9804 - val_loss: 2.5589 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.1015 - acc: 0.9804 - val_loss: 2.5827 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.0981 - acc: 0.9804 - val_loss: 2.6061 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0950 - acc: 0.9804 - val_loss: 2.6298 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0916 - acc: 0.9804 - val_loss: 2.6486 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.0888 - acc: 0.9804 - val_loss: 2.6679 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.0870 - acc: 0.9804 - val_loss: 2.6830 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0847 - acc: 0.9804 - val_loss: 2.6998 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.0850 - acc: 0.9804 - val_loss: 2.7107 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0834 - acc: 0.9804 - val_loss: 2.7280 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.0812 - acc: 0.9804 - val_loss: 2.7439 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0795 - acc: 0.9804 - val_loss: 2.7592 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0778 - acc: 0.9804 - val_loss: 2.7760 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0766 - acc: 0.9804 - val_loss: 2.7920 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0750 - acc: 0.9804 - val_loss: 2.8063 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.0737 - acc: 0.9804 - val_loss: 2.8210 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0755 - acc: 0.9804 - val_loss: 2.8332 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.0719 - acc: 0.9804 - val_loss: 2.8412 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.0705 - acc: 0.9804 - val_loss: 2.8500 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0695 - acc: 0.9804 - val_loss: 2.8574 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0685 - acc: 0.9804 - val_loss: 2.8650 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0670 - acc: 0.9804 - val_loss: 2.8710 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 269us/step - loss: 0.0673 - acc: 0.9804 - val_loss: 2.8772 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0647 - acc: 0.9804 - val_loss: 2.8839 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 2.8906 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.0629 - acc: 1.0000 - val_loss: 2.8995 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.0631 - acc: 1.0000 - val_loss: 2.9051 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0618 - acc: 1.0000 - val_loss: 2.9114 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0508 - acc: 1.000 - 0s 66us/step - loss: 0.0602 - acc: 1.0000 - val_loss: 2.9220 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0605 - acc: 1.0000 - val_loss: 2.9279 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0581 - acc: 1.0000 - val_loss: 2.9376 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.0569 - acc: 1.0000 - val_loss: 2.9442 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0577 - acc: 1.0000 - val_loss: 2.9505 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0552 - acc: 1.0000 - val_loss: 2.9570 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0545 - acc: 1.0000 - val_loss: 2.9645 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0541 - acc: 1.0000 - val_loss: 2.9727 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0529 - acc: 1.0000 - val_loss: 2.9799 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.0520 - acc: 1.0000 - val_loss: 2.9854 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0550 - acc: 1.000 - 0s 235us/step - loss: 0.0511 - acc: 1.0000 - val_loss: 2.9930 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0510 - acc: 1.0000 - val_loss: 3.0020 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.0502 - acc: 1.0000 - val_loss: 3.0057 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0500 - acc: 1.0000 - val_loss: 3.0099 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0394 - acc: 1.000 - 0s 197us/step - loss: 0.0494 - acc: 1.0000 - val_loss: 3.0179 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0476 - acc: 1.0000 - val_loss: 3.0241 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0468 - acc: 1.0000 - val_loss: 3.0327 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0480 - acc: 1.0000 - val_loss: 3.0369 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0455 - acc: 1.0000 - val_loss: 3.0438 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.0452 - acc: 1.0000 - val_loss: 3.0508 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0450 - acc: 1.0000 - val_loss: 3.0582 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 3.0651 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0428 - acc: 1.0000 - val_loss: 3.0720 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 3.0780 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 3.0839 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0416 - acc: 1.0000 - val_loss: 3.0911 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 3.0943 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 3.1003 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 3.1066 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0390 - acc: 1.0000 - val_loss: 3.1168 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 3.1244 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 3.1327 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 3.1401 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0379 - acc: 1.0000 - val_loss: 3.1437 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 3.1517 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 3.1591 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 3.1628 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 3.1707 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 3.1742 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 3.1797 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 3.1902 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 3.1992 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 3.2028 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 3.2093 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 3.2160 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.0329 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0306 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 300us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 398us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 635us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 303us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "2017-07-18\n",
      "2017-07-19\n",
      "2017-07-20\n",
      "2017-07-21\n",
      "2017-07-24\n",
      "2017-07-25\n",
      "2017-07-26\n",
      "2017-07-27\n",
      "2017-07-28\n",
      "2017-07-31\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 1.0724 - acc: 0.7843 - val_loss: 5.2192e-04 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.0301 - acc: 0.7843 - val_loss: 5.5048e-04 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 383us/step - loss: 0.9973 - acc: 0.7647 - val_loss: 5.6822e-04 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9769 - acc: 0.7647 - val_loss: 5.9069e-04 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9535 - acc: 0.7647 - val_loss: 5.9952e-04 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9368 - acc: 0.7647 - val_loss: 6.1059e-04 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.9242 - acc: 0.7843 - val_loss: 6.3601e-04 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.9094 - acc: 0.8039 - val_loss: 6.5262e-04 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8991 - acc: 0.8039 - val_loss: 6.5925e-04 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8819 - acc: 0.8039 - val_loss: 6.7526e-04 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8692 - acc: 0.8039 - val_loss: 7.0659e-04 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8581 - acc: 0.8039 - val_loss: 7.3621e-04 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8467 - acc: 0.8039 - val_loss: 7.6328e-04 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8382 - acc: 0.8039 - val_loss: 7.8575e-04 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.8268 - acc: 0.8039 - val_loss: 8.0885e-04 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.8139 - acc: 0.8039 - val_loss: 8.1826e-04 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8056 - acc: 0.8039 - val_loss: 8.3658e-04 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7986 - acc: 0.8039 - val_loss: 8.4858e-04 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7932 - acc: 0.8039 - val_loss: 8.7381e-04 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7876 - acc: 0.8235 - val_loss: 9.1228e-04 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7792 - acc: 0.8235 - val_loss: 9.2297e-04 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7734 - acc: 0.8235 - val_loss: 9.6462e-04 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.7644 - acc: 0.8431 - val_loss: 9.9097e-04 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7583 - acc: 0.8431 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 177us/step - loss: 0.7532 - acc: 0.8431 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7412 - acc: 0.8431 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7311 - acc: 0.8431 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7217 - acc: 0.8431 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7094 - acc: 0.8627 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7018 - acc: 0.8627 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.6958 - acc: 0.8824 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6823 - acc: 0.8824 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6764 - acc: 0.8824 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6708 - acc: 0.8824 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6597 - acc: 0.8824 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6547 - acc: 0.8824 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6493 - acc: 0.8824 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6394 - acc: 0.8824 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.6325 - acc: 0.8824 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6291 - acc: 0.8824 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.6209 - acc: 0.8824 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6149 - acc: 0.8824 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6098 - acc: 0.8824 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6047 - acc: 0.8824 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5989 - acc: 0.8824 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5909 - acc: 0.8824 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5853 - acc: 0.8824 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 530us/step - loss: 0.5820 - acc: 0.8824 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5754 - acc: 0.8824 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5686 - acc: 0.8824 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5641 - acc: 0.8824 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5583 - acc: 0.8824 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5533 - acc: 0.9020 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5500 - acc: 0.9020 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5418 - acc: 0.9020 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5365 - acc: 0.9020 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5327 - acc: 0.9020 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5268 - acc: 0.9020 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5225 - acc: 0.9020 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5162 - acc: 0.9020 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5125 - acc: 0.9020 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5068 - acc: 0.9020 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5025 - acc: 0.9020 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4980 - acc: 0.9020 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4895 - acc: 0.9020 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4872 - acc: 0.9020 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4789 - acc: 0.9020 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4745 - acc: 0.9020 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4699 - acc: 0.9020 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4667 - acc: 0.9020 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4627 - acc: 0.9020 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4584 - acc: 0.9020 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4529 - acc: 0.9020 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4497 - acc: 0.9020 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4454 - acc: 0.9020 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4422 - acc: 0.9020 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4389 - acc: 0.9020 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.4351 - acc: 0.9020 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4310 - acc: 0.9020 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4251 - acc: 0.9020 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4213 - acc: 0.9020 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4208 - acc: 0.9020 - val_loss: 0.0279 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4137 - acc: 0.9020 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4104 - acc: 0.9020 - val_loss: 0.0292 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4085 - acc: 0.9020 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4047 - acc: 0.9020 - val_loss: 0.0300 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.4025 - acc: 0.9020 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3972 - acc: 0.9020 - val_loss: 0.0335 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3938 - acc: 0.9020 - val_loss: 0.0359 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3902 - acc: 0.9020 - val_loss: 0.0365 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3879 - acc: 0.9020 - val_loss: 0.0398 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3834 - acc: 0.9020 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3796 - acc: 0.9020 - val_loss: 0.0432 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.3755 - acc: 0.9020 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3732 - acc: 0.9020 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3702 - acc: 0.9020 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.3669 - acc: 0.9020 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 183us/step - loss: 0.3649 - acc: 0.9020 - val_loss: 0.0556 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3617 - acc: 0.9020 - val_loss: 0.0566 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3583 - acc: 0.9020 - val_loss: 0.0579 - val_acc: 1.0000\n",
      "2017-08-01\n",
      "2017-08-02\n",
      "2017-08-03\n",
      "2017-08-04\n",
      "2017-08-07\n",
      "2017-08-08\n",
      "2017-08-09\n",
      "2017-08-10\n",
      "2017-08-11\n",
      "2017-08-14\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.2682 - acc: 0.7843 - val_loss: 0.9493 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.1371 - acc: 0.8235 - val_loss: 0.9632 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0405 - acc: 0.8235 - val_loss: 0.9718 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.9778 - acc: 0.8431 - val_loss: 0.9790 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.9345 - acc: 0.8431 - val_loss: 0.9886 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.8831 - acc: 0.8824 - val_loss: 0.9932 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.8525 - acc: 0.8824 - val_loss: 0.9987 - val_acc: 0.6000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.8301 - acc: 0.8824 - val_loss: 1.0015 - val_acc: 0.6000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8122 - acc: 0.9020 - val_loss: 1.0038 - val_acc: 0.6000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7937 - acc: 0.9020 - val_loss: 1.0076 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7760 - acc: 0.9020 - val_loss: 1.0132 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7552 - acc: 0.9020 - val_loss: 1.0196 - val_acc: 0.6000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7341 - acc: 0.9020 - val_loss: 1.0254 - val_acc: 0.6000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7156 - acc: 0.9020 - val_loss: 1.0301 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.6977 - acc: 0.9020 - val_loss: 1.0344 - val_acc: 0.6000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6801 - acc: 0.9020 - val_loss: 1.0390 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6635 - acc: 0.9020 - val_loss: 1.0430 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6471 - acc: 0.9020 - val_loss: 1.0489 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6321 - acc: 0.9216 - val_loss: 1.0570 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6162 - acc: 0.9216 - val_loss: 1.0614 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6036 - acc: 0.9216 - val_loss: 1.0677 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5900 - acc: 0.9216 - val_loss: 1.0748 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5760 - acc: 0.9216 - val_loss: 1.0825 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 162us/step - loss: 0.5628 - acc: 0.9216 - val_loss: 1.0899 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5536 - acc: 0.9216 - val_loss: 1.0963 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5441 - acc: 0.9216 - val_loss: 1.1018 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.5355 - acc: 0.9216 - val_loss: 1.1064 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.5247 - acc: 0.9216 - val_loss: 1.1146 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5144 - acc: 0.9216 - val_loss: 1.1214 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5035 - acc: 0.9216 - val_loss: 1.1294 - val_acc: 0.4000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4960 - acc: 0.9216 - val_loss: 1.1359 - val_acc: 0.4000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.4889 - acc: 0.9216 - val_loss: 1.1475 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4783 - acc: 0.9412 - val_loss: 1.1548 - val_acc: 0.4000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4713 - acc: 0.9412 - val_loss: 1.1647 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4641 - acc: 0.9412 - val_loss: 1.1728 - val_acc: 0.4000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4569 - acc: 0.9412 - val_loss: 1.1847 - val_acc: 0.4000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4508 - acc: 0.9412 - val_loss: 1.1928 - val_acc: 0.4000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4420 - acc: 0.9412 - val_loss: 1.2050 - val_acc: 0.4000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4357 - acc: 0.9412 - val_loss: 1.2166 - val_acc: 0.4000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4297 - acc: 0.9412 - val_loss: 1.2289 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4238 - acc: 0.9412 - val_loss: 1.2417 - val_acc: 0.4000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4172 - acc: 0.9412 - val_loss: 1.2571 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4091 - acc: 0.9412 - val_loss: 1.2680 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4013 - acc: 0.9412 - val_loss: 1.2792 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3950 - acc: 0.9412 - val_loss: 1.2923 - val_acc: 0.3000\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 196us/step - loss: 0.3889 - acc: 0.9412 - val_loss: 1.3024 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3840 - acc: 0.9412 - val_loss: 1.3137 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3742 - acc: 0.9412 - val_loss: 1.3278 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.3696 - acc: 0.9412 - val_loss: 1.3448 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3637 - acc: 0.9412 - val_loss: 1.3589 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3571 - acc: 0.9412 - val_loss: 1.3751 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3513 - acc: 0.9412 - val_loss: 1.3919 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3439 - acc: 0.9412 - val_loss: 1.4086 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3374 - acc: 0.9412 - val_loss: 1.4226 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3321 - acc: 0.9412 - val_loss: 1.4283 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3251 - acc: 0.9412 - val_loss: 1.4361 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 351us/step - loss: 0.3198 - acc: 0.9412 - val_loss: 1.4488 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3141 - acc: 0.9412 - val_loss: 1.4608 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 220us/step - loss: 0.3109 - acc: 0.9412 - val_loss: 1.4725 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 189us/step - loss: 0.3069 - acc: 0.9412 - val_loss: 1.4837 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3019 - acc: 0.9412 - val_loss: 1.4966 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2969 - acc: 0.9412 - val_loss: 1.5075 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 210us/step - loss: 0.2927 - acc: 0.9412 - val_loss: 1.5212 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2892 - acc: 0.9412 - val_loss: 1.5353 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.2844 - acc: 0.9412 - val_loss: 1.5481 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2805 - acc: 0.9412 - val_loss: 1.5553 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2765 - acc: 0.9412 - val_loss: 1.5636 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2715 - acc: 0.9412 - val_loss: 1.5735 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2680 - acc: 0.9412 - val_loss: 1.5856 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2651 - acc: 0.9412 - val_loss: 1.6016 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2615 - acc: 0.9412 - val_loss: 1.6104 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2581 - acc: 0.9412 - val_loss: 1.6265 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2536 - acc: 0.9412 - val_loss: 1.6419 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2506 - acc: 0.9412 - val_loss: 1.6558 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2469 - acc: 0.9412 - val_loss: 1.6653 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2407 - acc: 0.9412 - val_loss: 1.6747 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2358 - acc: 0.9412 - val_loss: 1.6865 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2324 - acc: 0.9412 - val_loss: 1.7028 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2286 - acc: 0.9412 - val_loss: 1.7192 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 331us/step - loss: 0.2248 - acc: 0.9412 - val_loss: 1.7331 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2204 - acc: 0.9412 - val_loss: 1.7476 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2169 - acc: 0.9412 - val_loss: 1.7625 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2135 - acc: 0.9412 - val_loss: 1.7771 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2093 - acc: 0.9412 - val_loss: 1.7858 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2071 - acc: 0.9412 - val_loss: 1.7933 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2026 - acc: 0.9412 - val_loss: 1.8079 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.1993 - acc: 0.9412 - val_loss: 1.8241 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1953 - acc: 0.9412 - val_loss: 1.8323 - val_acc: 0.3000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1923 - acc: 0.9412 - val_loss: 1.8491 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.1894 - acc: 0.9412 - val_loss: 1.8650 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.1854 - acc: 0.9412 - val_loss: 1.8819 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1820 - acc: 0.9412 - val_loss: 1.8988 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1794 - acc: 0.9412 - val_loss: 1.9174 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1760 - acc: 0.9412 - val_loss: 1.9288 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1728 - acc: 0.9412 - val_loss: 1.9386 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.1697 - acc: 0.9412 - val_loss: 1.9511 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.1661 - acc: 0.9412 - val_loss: 1.9659 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.1638 - acc: 0.9412 - val_loss: 1.9763 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1612 - acc: 0.9412 - val_loss: 1.9917 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.1586 - acc: 0.9412 - val_loss: 2.0062 - val_acc: 0.3000\n",
      "2017-08-15\n",
      "2017-08-16\n",
      "2017-08-17\n",
      "2017-08-18\n",
      "2017-08-21\n",
      "2017-08-22\n",
      "2017-08-23\n",
      "2017-08-24\n",
      "2017-08-25\n",
      "2017-08-28\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.9487 - acc: 0.8039 - val_loss: 3.7954 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9096 - acc: 0.8039 - val_loss: 3.8401 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 220us/step - loss: 0.8851 - acc: 0.8039 - val_loss: 3.8650 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8673 - acc: 0.8039 - val_loss: 3.8879 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.8542 - acc: 0.8039 - val_loss: 3.9144 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8398 - acc: 0.8235 - val_loss: 3.9350 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.8278 - acc: 0.8235 - val_loss: 3.9429 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8154 - acc: 0.8235 - val_loss: 3.9564 - val_acc: 0.2000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8017 - acc: 0.8235 - val_loss: 3.9728 - val_acc: 0.2000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7945 - acc: 0.8235 - val_loss: 3.9792 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7819 - acc: 0.8431 - val_loss: 4.0061 - val_acc: 0.2000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7722 - acc: 0.8431 - val_loss: 4.0150 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7633 - acc: 0.8431 - val_loss: 4.0215 - val_acc: 0.2000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 191us/step - loss: 0.7551 - acc: 0.8431 - val_loss: 4.0389 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 158us/step - loss: 0.7467 - acc: 0.8431 - val_loss: 4.0507 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7377 - acc: 0.8431 - val_loss: 4.0718 - val_acc: 0.2000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7313 - acc: 0.8431 - val_loss: 4.0640 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7244 - acc: 0.8431 - val_loss: 4.0688 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7133 - acc: 0.8431 - val_loss: 4.0820 - val_acc: 0.2000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7026 - acc: 0.8431 - val_loss: 4.0833 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6962 - acc: 0.8431 - val_loss: 4.1161 - val_acc: 0.2000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6871 - acc: 0.8431 - val_loss: 4.1273 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6788 - acc: 0.8431 - val_loss: 4.1535 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.6709 - acc: 0.8431 - val_loss: 4.1504 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 220us/step - loss: 0.6642 - acc: 0.8431 - val_loss: 4.1615 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6594 - acc: 0.8431 - val_loss: 4.1583 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6515 - acc: 0.8431 - val_loss: 4.1859 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6467 - acc: 0.8431 - val_loss: 4.2034 - val_acc: 0.2000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6432 - acc: 0.8431 - val_loss: 4.2381 - val_acc: 0.2000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6384 - acc: 0.8431 - val_loss: 4.2532 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6362 - acc: 0.8431 - val_loss: 4.2871 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6301 - acc: 0.8627 - val_loss: 4.3141 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6261 - acc: 0.8627 - val_loss: 4.3260 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6206 - acc: 0.8627 - val_loss: 4.3342 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.6158 - acc: 0.8627 - val_loss: 4.3364 - val_acc: 0.2000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6120 - acc: 0.8627 - val_loss: 4.3330 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 205us/step - loss: 0.6083 - acc: 0.8627 - val_loss: 4.3311 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6061 - acc: 0.8824 - val_loss: 4.3303 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6012 - acc: 0.8824 - val_loss: 4.3321 - val_acc: 0.2000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5981 - acc: 0.8824 - val_loss: 4.3324 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5933 - acc: 0.8824 - val_loss: 4.3295 - val_acc: 0.2000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.5890 - acc: 0.8824 - val_loss: 4.3516 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5858 - acc: 0.8824 - val_loss: 4.3640 - val_acc: 0.2000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5837 - acc: 0.8824 - val_loss: 4.3603 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5806 - acc: 0.8824 - val_loss: 4.3768 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5792 - acc: 0.8824 - val_loss: 4.3868 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5764 - acc: 0.8824 - val_loss: 4.3891 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.5740 - acc: 0.8824 - val_loss: 4.4076 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 158us/step - loss: 0.5723 - acc: 0.8824 - val_loss: 4.4175 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.5698 - acc: 0.8824 - val_loss: 4.4219 - val_acc: 0.2000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5674 - acc: 0.8824 - val_loss: 4.4445 - val_acc: 0.2000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5663 - acc: 0.8824 - val_loss: 4.4607 - val_acc: 0.2000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5631 - acc: 0.9020 - val_loss: 4.4855 - val_acc: 0.2000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5606 - acc: 0.9020 - val_loss: 4.4886 - val_acc: 0.2000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5579 - acc: 0.9020 - val_loss: 4.4177 - val_acc: 0.2000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.5458 - acc: 0.9020 - val_loss: 4.3394 - val_acc: 0.2000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5348 - acc: 0.9020 - val_loss: 4.2959 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2723 - acc: 0.906 - 0s 176us/step - loss: 0.5276 - acc: 0.9020 - val_loss: 4.2331 - val_acc: 0.2000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.5164 - acc: 0.8824 - val_loss: 4.2208 - val_acc: 0.2000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5097 - acc: 0.9020 - val_loss: 4.1713 - val_acc: 0.2000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5026 - acc: 0.9020 - val_loss: 4.1641 - val_acc: 0.2000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4962 - acc: 0.9020 - val_loss: 4.1509 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4892 - acc: 0.9020 - val_loss: 4.1211 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.4833 - acc: 0.9020 - val_loss: 4.0868 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4775 - acc: 0.9020 - val_loss: 4.0469 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4715 - acc: 0.9020 - val_loss: 4.0423 - val_acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4661 - acc: 0.9020 - val_loss: 4.0274 - val_acc: 0.2000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4601 - acc: 0.9020 - val_loss: 3.9907 - val_acc: 0.2000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4491 - acc: 0.9020 - val_loss: 3.9770 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4434 - acc: 0.9020 - val_loss: 3.9425 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 78us/step - loss: 0.4348 - acc: 0.9020 - val_loss: 3.9333 - val_acc: 0.2000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4296 - acc: 0.9020 - val_loss: 3.9004 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.4221 - acc: 0.9020 - val_loss: 3.8748 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.4177 - acc: 0.9020 - val_loss: 3.8549 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.4113 - acc: 0.9020 - val_loss: 3.8434 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.4056 - acc: 0.9020 - val_loss: 3.8359 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3997 - acc: 0.9020 - val_loss: 3.8236 - val_acc: 0.2000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.3945 - acc: 0.9020 - val_loss: 3.8055 - val_acc: 0.2000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 109us/step - loss: 0.3892 - acc: 0.9020 - val_loss: 3.7856 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3842 - acc: 0.9216 - val_loss: 3.7724 - val_acc: 0.2000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 194us/step - loss: 0.3771 - acc: 0.9216 - val_loss: 3.7562 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 218us/step - loss: 0.3732 - acc: 0.9216 - val_loss: 3.7643 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3688 - acc: 0.9216 - val_loss: 3.7558 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.3649 - acc: 0.9216 - val_loss: 3.7276 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3586 - acc: 0.9216 - val_loss: 3.7180 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3531 - acc: 0.9216 - val_loss: 3.7263 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3493 - acc: 0.9216 - val_loss: 3.7073 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3439 - acc: 0.9216 - val_loss: 3.7137 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 67us/step - loss: 0.3391 - acc: 0.9216 - val_loss: 3.7007 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3342 - acc: 0.9216 - val_loss: 3.7161 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3310 - acc: 0.9216 - val_loss: 3.6964 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 250us/step - loss: 0.3277 - acc: 0.9216 - val_loss: 3.7086 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3217 - acc: 0.9216 - val_loss: 3.6934 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3180 - acc: 0.9216 - val_loss: 3.6809 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3128 - acc: 0.9216 - val_loss: 3.6683 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.3093 - acc: 0.9216 - val_loss: 3.6673 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3073 - acc: 0.9216 - val_loss: 3.6666 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 113us/step - loss: 0.3011 - acc: 0.9216 - val_loss: 3.6755 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2987 - acc: 0.9216 - val_loss: 3.6888 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2942 - acc: 0.9216 - val_loss: 3.6734 - val_acc: 0.2000\n",
      "2017-08-29\n",
      "2017-08-30\n",
      "2017-08-31\n",
      "2017-09-01\n",
      "2017-09-04\n",
      "2017-09-05\n",
      "2017-09-06\n",
      "2017-09-07\n",
      "2017-09-08\n",
      "2017-09-11\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 3.1208 - acc: 0.3137 - val_loss: 2.2312 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 2.8464 - acc: 0.3529 - val_loss: 2.2896 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 2.6468 - acc: 0.3529 - val_loss: 2.3442 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 2.4855 - acc: 0.3529 - val_loss: 2.3856 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 2.3534 - acc: 0.3529 - val_loss: 2.4388 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.2393 - acc: 0.3725 - val_loss: 2.4776 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.1454 - acc: 0.3922 - val_loss: 2.4978 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.0609 - acc: 0.3922 - val_loss: 2.5137 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.9780 - acc: 0.4118 - val_loss: 2.5427 - val_acc: 0.1000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.9112 - acc: 0.4118 - val_loss: 2.5473 - val_acc: 0.1000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 292us/step - loss: 1.8387 - acc: 0.4118 - val_loss: 2.5854 - val_acc: 0.1000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.7672 - acc: 0.3922 - val_loss: 2.6043 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.7005 - acc: 0.3922 - val_loss: 2.6461 - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.6354 - acc: 0.3922 - val_loss: 2.6483 - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.5748 - acc: 0.3922 - val_loss: 2.6596 - val_acc: 0.1000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.5136 - acc: 0.3922 - val_loss: 2.6757 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.4559 - acc: 0.4118 - val_loss: 2.7034 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.3984 - acc: 0.4314 - val_loss: 2.7144 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.3464 - acc: 0.4314 - val_loss: 2.7360 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.2943 - acc: 0.4314 - val_loss: 2.7453 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.2439 - acc: 0.4510 - val_loss: 2.7684 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1975 - acc: 0.4706 - val_loss: 2.7823 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1502 - acc: 0.4706 - val_loss: 2.8030 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.1084 - acc: 0.5098 - val_loss: 2.8116 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 1.0724 - acc: 0.5098 - val_loss: 2.8088 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.0345 - acc: 0.5098 - val_loss: 2.8299 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0039 - acc: 0.5490 - val_loss: 2.8447 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.9744 - acc: 0.5490 - val_loss: 2.8663 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.9428 - acc: 0.5490 - val_loss: 2.8914 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9145 - acc: 0.5490 - val_loss: 2.8941 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.8910 - acc: 0.5686 - val_loss: 2.8924 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.8663 - acc: 0.5686 - val_loss: 2.9098 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.8432 - acc: 0.5882 - val_loss: 2.9191 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 224us/step - loss: 0.8190 - acc: 0.5882 - val_loss: 2.9027 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7966 - acc: 0.5882 - val_loss: 2.9091 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7771 - acc: 0.5882 - val_loss: 2.8952 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.7590 - acc: 0.5882 - val_loss: 2.8881 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 262us/step - loss: 0.7406 - acc: 0.5882 - val_loss: 2.8909 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.7246 - acc: 0.5882 - val_loss: 2.8893 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.7086 - acc: 0.5882 - val_loss: 2.8860 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 181us/step - loss: 0.6923 - acc: 0.6078 - val_loss: 2.8834 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 163us/step - loss: 0.6774 - acc: 0.6275 - val_loss: 2.8770 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6653 - acc: 0.6275 - val_loss: 2.8623 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 123us/step - loss: 0.6502 - acc: 0.6275 - val_loss: 2.8428 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6375 - acc: 0.6275 - val_loss: 2.8402 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6261 - acc: 0.6275 - val_loss: 2.8308 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6143 - acc: 0.6667 - val_loss: 2.8086 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6027 - acc: 0.6667 - val_loss: 2.8267 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5916 - acc: 0.6667 - val_loss: 2.8145 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.5832 - acc: 0.6667 - val_loss: 2.8264 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5752 - acc: 0.6863 - val_loss: 2.7906 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5641 - acc: 0.7059 - val_loss: 2.7956 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5566 - acc: 0.7255 - val_loss: 2.8029 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 194us/step - loss: 0.5483 - acc: 0.7255 - val_loss: 2.8092 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5402 - acc: 0.7255 - val_loss: 2.7925 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5326 - acc: 0.7255 - val_loss: 2.7903 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5249 - acc: 0.7255 - val_loss: 2.7589 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5166 - acc: 0.7255 - val_loss: 2.7436 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5102 - acc: 0.7255 - val_loss: 2.7398 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 211us/step - loss: 0.5050 - acc: 0.7255 - val_loss: 2.7228 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4992 - acc: 0.7255 - val_loss: 2.7025 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 237us/step - loss: 0.4918 - acc: 0.7451 - val_loss: 2.7037 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 0.4847 - acc: 0.7647 - val_loss: 2.6919 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4798 - acc: 0.7647 - val_loss: 2.6910 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4754 - acc: 0.7843 - val_loss: 2.7025 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4705 - acc: 0.7843 - val_loss: 2.7244 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4651 - acc: 0.7843 - val_loss: 2.7103 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4611 - acc: 0.7843 - val_loss: 2.6640 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4583 - acc: 0.7843 - val_loss: 2.6782 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4539 - acc: 0.7843 - val_loss: 2.6730 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4489 - acc: 0.7843 - val_loss: 2.6839 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2851 - acc: 0.906 - 0s 274us/step - loss: 0.4457 - acc: 0.7843 - val_loss: 2.6372 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4402 - acc: 0.7843 - val_loss: 2.6512 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4364 - acc: 0.7843 - val_loss: 2.6534 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4337 - acc: 0.7843 - val_loss: 2.6480 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4304 - acc: 0.7843 - val_loss: 2.6526 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.4281 - acc: 0.7843 - val_loss: 2.6388 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4247 - acc: 0.7843 - val_loss: 2.6475 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4210 - acc: 0.7843 - val_loss: 2.6548 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4190 - acc: 0.7843 - val_loss: 2.6380 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4149 - acc: 0.7843 - val_loss: 2.6375 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4119 - acc: 0.7843 - val_loss: 2.6140 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4092 - acc: 0.7843 - val_loss: 2.6301 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3542 - acc: 0.843 - 0s 235us/step - loss: 0.4061 - acc: 0.7843 - val_loss: 2.6337 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4034 - acc: 0.7843 - val_loss: 2.6130 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3996 - acc: 0.7843 - val_loss: 2.6207 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3258 - acc: 0.843 - 0s 335us/step - loss: 0.3975 - acc: 0.7843 - val_loss: 2.5767 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 67us/step - loss: 0.3933 - acc: 0.8039 - val_loss: 2.5952 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3665 - acc: 0.812 - 0s 102us/step - loss: 0.3901 - acc: 0.8039 - val_loss: 2.6105 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 205us/step - loss: 0.3874 - acc: 0.8235 - val_loss: 2.5961 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 287us/step - loss: 0.3848 - acc: 0.8235 - val_loss: 2.5901 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3816 - acc: 0.8235 - val_loss: 2.5819 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 228us/step - loss: 0.3783 - acc: 0.8235 - val_loss: 2.5956 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3762 - acc: 0.8235 - val_loss: 2.5989 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 119us/step - loss: 0.3742 - acc: 0.8235 - val_loss: 2.6204 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.3722 - acc: 0.8235 - val_loss: 2.6171 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3696 - acc: 0.8235 - val_loss: 2.5661 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3671 - acc: 0.8235 - val_loss: 2.5682 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3648 - acc: 0.8235 - val_loss: 2.5821 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3641 - acc: 0.8235 - val_loss: 2.5567 - val_acc: 0.0000e+00\n",
      "2017-09-12\n",
      "2017-09-13\n",
      "2017-09-14\n",
      "2017-09-15\n",
      "2017-09-18\n",
      "2017-09-19\n",
      "2017-09-20\n",
      "2017-09-21\n",
      "2017-09-22\n",
      "2017-09-25\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 1.2887 - acc: 0.6275 - val_loss: 1.5060 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1893 - acc: 0.6275 - val_loss: 1.4893 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.1186 - acc: 0.6471 - val_loss: 1.4806 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 1.0595 - acc: 0.6667 - val_loss: 1.4717 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 1.0092 - acc: 0.6863 - val_loss: 1.4592 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 30us/step - loss: 0.9600 - acc: 0.6667 - val_loss: 1.4512 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 537us/step - loss: 0.9194 - acc: 0.6667 - val_loss: 1.4446 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8822 - acc: 0.6471 - val_loss: 1.4385 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.8417 - acc: 0.6471 - val_loss: 1.4349 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8095 - acc: 0.6471 - val_loss: 1.4301 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.7830 - acc: 0.6471 - val_loss: 1.4327 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7585 - acc: 0.6471 - val_loss: 1.4347 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.7345 - acc: 0.6471 - val_loss: 1.4377 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7111 - acc: 0.6471 - val_loss: 1.4294 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6868 - acc: 0.6667 - val_loss: 1.4237 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6650 - acc: 0.6667 - val_loss: 1.4195 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 383us/step - loss: 0.6476 - acc: 0.6667 - val_loss: 1.4145 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6248 - acc: 0.6471 - val_loss: 1.4071 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6088 - acc: 0.6471 - val_loss: 1.4080 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5978 - acc: 0.6471 - val_loss: 1.4036 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.5861 - acc: 0.6471 - val_loss: 1.4004 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5751 - acc: 0.6471 - val_loss: 1.4013 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5671 - acc: 0.6471 - val_loss: 1.4035 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5565 - acc: 0.6667 - val_loss: 1.4038 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.5482 - acc: 0.6471 - val_loss: 1.4033 - val_acc: 0.6000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5402 - acc: 0.6471 - val_loss: 1.4076 - val_acc: 0.6000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 61us/step - loss: 0.5320 - acc: 0.6667 - val_loss: 1.4080 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.5246 - acc: 0.6471 - val_loss: 1.4097 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5179 - acc: 0.6667 - val_loss: 1.4089 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5107 - acc: 0.7255 - val_loss: 1.4094 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5053 - acc: 0.7255 - val_loss: 1.4107 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4985 - acc: 0.7451 - val_loss: 1.4120 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4941 - acc: 0.7451 - val_loss: 1.4159 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4910 - acc: 0.7451 - val_loss: 1.4212 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4857 - acc: 0.7451 - val_loss: 1.4233 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.4855 - acc: 0.7451 - val_loss: 1.4188 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4775 - acc: 0.7647 - val_loss: 1.4223 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4733 - acc: 0.7647 - val_loss: 1.4231 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4713 - acc: 0.7843 - val_loss: 1.4253 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4689 - acc: 0.7843 - val_loss: 1.4244 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4653 - acc: 0.7647 - val_loss: 1.4223 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4609 - acc: 0.7843 - val_loss: 1.4215 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4584 - acc: 0.7843 - val_loss: 1.4237 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4547 - acc: 0.7843 - val_loss: 1.4224 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4513 - acc: 0.7843 - val_loss: 1.4208 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4489 - acc: 0.8039 - val_loss: 1.4176 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4452 - acc: 0.8235 - val_loss: 1.4195 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.4429 - acc: 0.8431 - val_loss: 1.4194 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 280us/step - loss: 0.4405 - acc: 0.8431 - val_loss: 1.4163 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 192us/step - loss: 0.4367 - acc: 0.8627 - val_loss: 1.4183 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 225us/step - loss: 0.4339 - acc: 0.8627 - val_loss: 1.4165 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.4317 - acc: 0.8627 - val_loss: 1.4094 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 229us/step - loss: 0.4281 - acc: 0.8627 - val_loss: 1.4079 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4266 - acc: 0.8431 - val_loss: 1.4081 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4263 - acc: 0.8431 - val_loss: 1.4115 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4225 - acc: 0.8431 - val_loss: 1.4099 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 222us/step - loss: 0.4201 - acc: 0.8039 - val_loss: 1.4111 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 239us/step - loss: 0.4170 - acc: 0.8235 - val_loss: 1.4055 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 344us/step - loss: 0.4158 - acc: 0.8627 - val_loss: 1.4020 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4137 - acc: 0.8431 - val_loss: 1.4029 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.4125 - acc: 0.8431 - val_loss: 1.4033 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4111 - acc: 0.8235 - val_loss: 1.4042 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.4080 - acc: 0.8431 - val_loss: 1.4033 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4075 - acc: 0.8431 - val_loss: 1.3960 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 220us/step - loss: 0.4042 - acc: 0.8431 - val_loss: 1.3931 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.4035 - acc: 0.8431 - val_loss: 1.3947 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4016 - acc: 0.8431 - val_loss: 1.3976 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4004 - acc: 0.8431 - val_loss: 1.3947 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3993 - acc: 0.8431 - val_loss: 1.3959 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3969 - acc: 0.8431 - val_loss: 1.3909 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3943 - acc: 0.8431 - val_loss: 1.3930 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.3930 - acc: 0.8431 - val_loss: 1.3904 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3918 - acc: 0.8431 - val_loss: 1.3908 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3896 - acc: 0.8431 - val_loss: 1.3915 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3882 - acc: 0.8431 - val_loss: 1.3900 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3888 - acc: 0.8431 - val_loss: 1.3871 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.3864 - acc: 0.8431 - val_loss: 1.3822 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3857 - acc: 0.8431 - val_loss: 1.3751 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3832 - acc: 0.8431 - val_loss: 1.3787 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3862 - acc: 0.8431 - val_loss: 1.3793 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3819 - acc: 0.8431 - val_loss: 1.3739 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3794 - acc: 0.8431 - val_loss: 1.3763 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3818 - acc: 0.8431 - val_loss: 1.3778 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3770 - acc: 0.8431 - val_loss: 1.3793 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.3757 - acc: 0.8431 - val_loss: 1.3799 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3743 - acc: 0.8431 - val_loss: 1.3808 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3723 - acc: 0.8431 - val_loss: 1.3807 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3715 - acc: 0.8431 - val_loss: 1.3810 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3718 - acc: 0.8431 - val_loss: 1.3778 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3710 - acc: 0.8431 - val_loss: 1.3834 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.3688 - acc: 0.8431 - val_loss: 1.3791 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3685 - acc: 0.8431 - val_loss: 1.3823 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3659 - acc: 0.8431 - val_loss: 1.3768 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3648 - acc: 0.8431 - val_loss: 1.3750 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 229us/step - loss: 0.3661 - acc: 0.8431 - val_loss: 1.3795 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3630 - acc: 0.8431 - val_loss: 1.3771 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3613 - acc: 0.8431 - val_loss: 1.3808 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3627 - acc: 0.8431 - val_loss: 1.3771 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3664 - acc: 0.8431 - val_loss: 1.3801 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3582 - acc: 0.8431 - val_loss: 1.3766 - val_acc: 0.7000\n",
      "2017-09-26\n",
      "2017-09-27\n",
      "2017-09-28\n",
      "2017-09-29\n",
      "2017-10-09\n",
      "2017-10-10\n",
      "2017-10-11\n",
      "2017-10-12\n",
      "2017-10-13\n",
      "2017-10-16\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 0.7333 - acc: 0.7255 - val_loss: 0.5619 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 219us/step - loss: 0.7005 - acc: 0.7451 - val_loss: 0.5409 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.6838 - acc: 0.7451 - val_loss: 0.5140 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6795 - acc: 0.7451 - val_loss: 0.5078 - val_acc: 0.7000\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 235us/step - loss: 0.6574 - acc: 0.7647 - val_loss: 0.4948 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 296us/step - loss: 0.6478 - acc: 0.7843 - val_loss: 0.4790 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 518us/step - loss: 0.6402 - acc: 0.7843 - val_loss: 0.4757 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.6304 - acc: 0.7843 - val_loss: 0.4632 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 293us/step - loss: 0.6230 - acc: 0.7843 - val_loss: 0.4564 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6163 - acc: 0.7843 - val_loss: 0.4510 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6162 - acc: 0.7843 - val_loss: 0.4476 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 553us/step - loss: 0.6050 - acc: 0.7843 - val_loss: 0.4320 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.5978 - acc: 0.7843 - val_loss: 0.4220 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5922 - acc: 0.7843 - val_loss: 0.4125 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 487us/step - loss: 0.5868 - acc: 0.7843 - val_loss: 0.4006 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 292us/step - loss: 0.5834 - acc: 0.7843 - val_loss: 0.3971 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 329us/step - loss: 0.5786 - acc: 0.7843 - val_loss: 0.3862 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5747 - acc: 0.7647 - val_loss: 0.3832 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5680 - acc: 0.7843 - val_loss: 0.3756 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 0.5668 - acc: 0.7843 - val_loss: 0.3629 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 228us/step - loss: 0.5593 - acc: 0.7451 - val_loss: 0.3566 - val_acc: 0.9000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 174us/step - loss: 0.5585 - acc: 0.7451 - val_loss: 0.3476 - val_acc: 0.9000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 212us/step - loss: 0.5519 - acc: 0.7647 - val_loss: 0.3432 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5484 - acc: 0.7647 - val_loss: 0.3374 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 302us/step - loss: 0.5453 - acc: 0.7647 - val_loss: 0.3274 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 59us/step - loss: 0.5424 - acc: 0.7647 - val_loss: 0.3262 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 423us/step - loss: 0.5373 - acc: 0.7451 - val_loss: 0.3230 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 210us/step - loss: 0.5404 - acc: 0.7451 - val_loss: 0.3195 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5302 - acc: 0.7451 - val_loss: 0.3115 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5248 - acc: 0.7451 - val_loss: 0.3052 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.5229 - acc: 0.7451 - val_loss: 0.2979 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.5175 - acc: 0.7451 - val_loss: 0.2938 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.5165 - acc: 0.7451 - val_loss: 0.2921 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5105 - acc: 0.7451 - val_loss: 0.2861 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.5075 - acc: 0.7451 - val_loss: 0.2821 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5048 - acc: 0.7451 - val_loss: 0.2737 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5000 - acc: 0.7451 - val_loss: 0.2694 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.5003 - acc: 0.7451 - val_loss: 0.2654 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4944 - acc: 0.7451 - val_loss: 0.2633 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4908 - acc: 0.7451 - val_loss: 0.2567 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4883 - acc: 0.7451 - val_loss: 0.2551 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4856 - acc: 0.7451 - val_loss: 0.2525 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4847 - acc: 0.7451 - val_loss: 0.2456 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4792 - acc: 0.7451 - val_loss: 0.2400 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 175us/step - loss: 0.4713 - acc: 0.7451 - val_loss: 0.2347 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4736 - acc: 0.7647 - val_loss: 0.2338 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4724 - acc: 0.7647 - val_loss: 0.2335 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4634 - acc: 0.7843 - val_loss: 0.2313 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 588us/step - loss: 0.4615 - acc: 0.7843 - val_loss: 0.2239 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4594 - acc: 0.7843 - val_loss: 0.2168 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 305us/step - loss: 0.4548 - acc: 0.7843 - val_loss: 0.2147 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4559 - acc: 0.7843 - val_loss: 0.2102 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.4484 - acc: 0.8039 - val_loss: 0.2082 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4455 - acc: 0.8039 - val_loss: 0.2055 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4428 - acc: 0.7843 - val_loss: 0.2035 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4397 - acc: 0.8039 - val_loss: 0.2001 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4362 - acc: 0.8039 - val_loss: 0.1964 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4347 - acc: 0.8039 - val_loss: 0.1945 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4309 - acc: 0.8235 - val_loss: 0.1911 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4288 - acc: 0.8235 - val_loss: 0.1864 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4256 - acc: 0.8235 - val_loss: 0.1839 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4252 - acc: 0.8235 - val_loss: 0.1788 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4204 - acc: 0.8235 - val_loss: 0.1745 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4180 - acc: 0.8039 - val_loss: 0.1739 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4147 - acc: 0.8235 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4140 - acc: 0.8235 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4102 - acc: 0.8235 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.4097 - acc: 0.8235 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4056 - acc: 0.8235 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 123us/step - loss: 0.4039 - acc: 0.8235 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4039 - acc: 0.8235 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3996 - acc: 0.8235 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3966 - acc: 0.8235 - val_loss: 0.1566 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3935 - acc: 0.8235 - val_loss: 0.1545 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3907 - acc: 0.8235 - val_loss: 0.1516 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3894 - acc: 0.8431 - val_loss: 0.1480 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3923 - acc: 0.8431 - val_loss: 0.1500 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3852 - acc: 0.8431 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3863 - acc: 0.8431 - val_loss: 0.1473 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3811 - acc: 0.8431 - val_loss: 0.1458 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3796 - acc: 0.8431 - val_loss: 0.1440 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3807 - acc: 0.8431 - val_loss: 0.1394 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3775 - acc: 0.8431 - val_loss: 0.1401 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3731 - acc: 0.8431 - val_loss: 0.1381 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 161us/step - loss: 0.3714 - acc: 0.8431 - val_loss: 0.1377 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3677 - acc: 0.8431 - val_loss: 0.1341 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3658 - acc: 0.8431 - val_loss: 0.1331 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 276us/step - loss: 0.3644 - acc: 0.8431 - val_loss: 0.1321 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3619 - acc: 0.8431 - val_loss: 0.1287 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3630 - acc: 0.8431 - val_loss: 0.1241 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.3562 - acc: 0.8431 - val_loss: 0.1231 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3594 - acc: 0.8431 - val_loss: 0.1253 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3528 - acc: 0.8431 - val_loss: 0.1247 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3482 - acc: 0.8627 - val_loss: 0.1228 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3470 - acc: 0.8627 - val_loss: 0.1218 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3453 - acc: 0.8627 - val_loss: 0.1191 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3450 - acc: 0.8627 - val_loss: 0.1205 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3421 - acc: 0.8627 - val_loss: 0.1178 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.3437 - acc: 0.8627 - val_loss: 0.1197 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3395 - acc: 0.8627 - val_loss: 0.1153 - val_acc: 1.0000\n",
      "2017-10-17\n",
      "2017-10-18\n",
      "2017-10-19\n",
      "2017-10-20\n",
      "2017-10-23\n",
      "2017-10-24\n",
      "2017-10-25\n",
      "2017-10-26\n",
      "2017-10-27\n",
      "2017-10-30\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 1.2434 - acc: 0.5294 - val_loss: 0.1625 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1699 - acc: 0.5490 - val_loss: 0.1620 - val_acc: 0.9000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1238 - acc: 0.5490 - val_loss: 0.1645 - val_acc: 0.9000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.0913 - acc: 0.5490 - val_loss: 0.1681 - val_acc: 0.9000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0671 - acc: 0.5490 - val_loss: 0.1721 - val_acc: 0.9000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.0397 - acc: 0.5490 - val_loss: 0.1735 - val_acc: 0.9000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0139 - acc: 0.5686 - val_loss: 0.1754 - val_acc: 0.9000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 0.9954 - acc: 0.5686 - val_loss: 0.1806 - val_acc: 0.9000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 162us/step - loss: 0.9753 - acc: 0.5686 - val_loss: 0.1816 - val_acc: 0.9000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9590 - acc: 0.5882 - val_loss: 0.1840 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 354us/step - loss: 0.9455 - acc: 0.5882 - val_loss: 0.1880 - val_acc: 0.9000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9314 - acc: 0.6078 - val_loss: 0.1917 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9157 - acc: 0.6275 - val_loss: 0.1897 - val_acc: 0.9000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9002 - acc: 0.6275 - val_loss: 0.1926 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8874 - acc: 0.6275 - val_loss: 0.1953 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8753 - acc: 0.6275 - val_loss: 0.1923 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 193us/step - loss: 0.8608 - acc: 0.6275 - val_loss: 0.1939 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8500 - acc: 0.6275 - val_loss: 0.1960 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 183us/step - loss: 0.8408 - acc: 0.6275 - val_loss: 0.1997 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8313 - acc: 0.6275 - val_loss: 0.2037 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8184 - acc: 0.6471 - val_loss: 0.2033 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8105 - acc: 0.6471 - val_loss: 0.2020 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 403us/step - loss: 0.8005 - acc: 0.6471 - val_loss: 0.1997 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7912 - acc: 0.6471 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.7842 - acc: 0.6471 - val_loss: 0.1999 - val_acc: 1.0000\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 313us/step - loss: 0.7758 - acc: 0.6471 - val_loss: 0.2055 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 38us/step - loss: 0.7660 - acc: 0.6471 - val_loss: 0.2079 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7590 - acc: 0.6471 - val_loss: 0.2111 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7513 - acc: 0.6471 - val_loss: 0.2115 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7434 - acc: 0.6471 - val_loss: 0.2102 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7372 - acc: 0.6471 - val_loss: 0.2116 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7292 - acc: 0.6471 - val_loss: 0.2124 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.7236 - acc: 0.6471 - val_loss: 0.2093 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7146 - acc: 0.6471 - val_loss: 0.2119 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7077 - acc: 0.6471 - val_loss: 0.2141 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7021 - acc: 0.6471 - val_loss: 0.2129 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 79us/step - loss: 0.6926 - acc: 0.6471 - val_loss: 0.2133 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6898 - acc: 0.6471 - val_loss: 0.2180 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.6802 - acc: 0.6471 - val_loss: 0.2194 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 491us/step - loss: 0.6735 - acc: 0.6275 - val_loss: 0.2175 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6692 - acc: 0.6275 - val_loss: 0.2143 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6617 - acc: 0.6471 - val_loss: 0.2122 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6552 - acc: 0.6471 - val_loss: 0.2120 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 199us/step - loss: 0.6511 - acc: 0.6275 - val_loss: 0.2078 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6445 - acc: 0.6471 - val_loss: 0.2098 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6380 - acc: 0.6471 - val_loss: 0.2109 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.6334 - acc: 0.6471 - val_loss: 0.2071 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.6284 - acc: 0.6471 - val_loss: 0.2100 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6225 - acc: 0.6667 - val_loss: 0.2106 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6168 - acc: 0.6667 - val_loss: 0.2109 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6122 - acc: 0.6667 - val_loss: 0.2110 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6073 - acc: 0.6667 - val_loss: 0.2085 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.6008 - acc: 0.6471 - val_loss: 0.2066 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 180us/step - loss: 0.5983 - acc: 0.6471 - val_loss: 0.2080 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5917 - acc: 0.6471 - val_loss: 0.2069 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 159us/step - loss: 0.5883 - acc: 0.6471 - val_loss: 0.2094 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5838 - acc: 0.6471 - val_loss: 0.2100 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 498us/step - loss: 0.5800 - acc: 0.6275 - val_loss: 0.2085 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5774 - acc: 0.6275 - val_loss: 0.2078 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5752 - acc: 0.6275 - val_loss: 0.2094 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 549us/step - loss: 0.5696 - acc: 0.6275 - val_loss: 0.2064 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5659 - acc: 0.6275 - val_loss: 0.2022 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5618 - acc: 0.6667 - val_loss: 0.2030 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.5586 - acc: 0.6863 - val_loss: 0.2017 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.5563 - acc: 0.6863 - val_loss: 0.2041 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.5529 - acc: 0.6667 - val_loss: 0.2014 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.5490 - acc: 0.6863 - val_loss: 0.1975 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5458 - acc: 0.7255 - val_loss: 0.1968 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 465us/step - loss: 0.5414 - acc: 0.7255 - val_loss: 0.1986 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5379 - acc: 0.7451 - val_loss: 0.1979 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5375 - acc: 0.7255 - val_loss: 0.2018 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5318 - acc: 0.7451 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5284 - acc: 0.7451 - val_loss: 0.2005 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5264 - acc: 0.7255 - val_loss: 0.1953 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5243 - acc: 0.7451 - val_loss: 0.1977 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5197 - acc: 0.7451 - val_loss: 0.2008 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.5171 - acc: 0.7451 - val_loss: 0.1999 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5139 - acc: 0.7451 - val_loss: 0.1990 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5122 - acc: 0.7451 - val_loss: 0.2027 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.5092 - acc: 0.7451 - val_loss: 0.2051 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5074 - acc: 0.7255 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5049 - acc: 0.7255 - val_loss: 0.2063 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5019 - acc: 0.7255 - val_loss: 0.2057 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5009 - acc: 0.7255 - val_loss: 0.2084 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4979 - acc: 0.7255 - val_loss: 0.2096 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4953 - acc: 0.7255 - val_loss: 0.2057 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4930 - acc: 0.7255 - val_loss: 0.2036 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4912 - acc: 0.7255 - val_loss: 0.2010 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 205us/step - loss: 0.4892 - acc: 0.7451 - val_loss: 0.2001 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4870 - acc: 0.7451 - val_loss: 0.1967 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4845 - acc: 0.7451 - val_loss: 0.1960 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4828 - acc: 0.7451 - val_loss: 0.1957 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 139us/step - loss: 0.4801 - acc: 0.7451 - val_loss: 0.1962 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4785 - acc: 0.7451 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4761 - acc: 0.7451 - val_loss: 0.2018 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4737 - acc: 0.7451 - val_loss: 0.2018 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.4724 - acc: 0.7647 - val_loss: 0.1977 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4706 - acc: 0.7451 - val_loss: 0.1976 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4673 - acc: 0.7451 - val_loss: 0.1970 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 363us/step - loss: 0.4657 - acc: 0.7647 - val_loss: 0.1979 - val_acc: 1.0000\n",
      "2017-10-31\n",
      "2017-11-01\n",
      "2017-11-02\n",
      "2017-11-03\n",
      "2017-11-06\n",
      "2017-11-07\n",
      "2017-11-08\n",
      "2017-11-09\n",
      "2017-11-10\n",
      "2017-11-13\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.4919 - acc: 0.7647 - val_loss: 0.8099 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4689 - acc: 0.7647 - val_loss: 0.8315 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4596 - acc: 0.7843 - val_loss: 0.8510 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4539 - acc: 0.7647 - val_loss: 0.8729 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.4476 - acc: 0.7647 - val_loss: 0.8892 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4440 - acc: 0.7843 - val_loss: 0.9049 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4412 - acc: 0.7647 - val_loss: 0.9143 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.4383 - acc: 0.7843 - val_loss: 0.9244 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.4364 - acc: 0.8039 - val_loss: 0.9381 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4352 - acc: 0.7843 - val_loss: 0.9557 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 443us/step - loss: 0.4317 - acc: 0.7843 - val_loss: 0.9677 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4304 - acc: 0.7843 - val_loss: 0.9769 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4294 - acc: 0.7843 - val_loss: 0.9881 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4271 - acc: 0.7843 - val_loss: 1.0021 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4245 - acc: 0.8039 - val_loss: 1.0103 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4224 - acc: 0.8039 - val_loss: 1.0205 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4211 - acc: 0.8039 - val_loss: 1.0294 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4204 - acc: 0.8235 - val_loss: 1.0465 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4168 - acc: 0.8431 - val_loss: 1.0529 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 538us/step - loss: 0.4165 - acc: 0.8431 - val_loss: 1.0666 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4147 - acc: 0.8431 - val_loss: 1.0783 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4130 - acc: 0.8431 - val_loss: 1.0841 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4123 - acc: 0.8431 - val_loss: 1.0925 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4094 - acc: 0.8431 - val_loss: 1.1045 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4085 - acc: 0.8431 - val_loss: 1.1141 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4065 - acc: 0.8431 - val_loss: 1.1242 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4051 - acc: 0.8431 - val_loss: 1.1331 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4044 - acc: 0.8431 - val_loss: 1.1506 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4025 - acc: 0.8431 - val_loss: 1.1608 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4012 - acc: 0.8431 - val_loss: 1.1689 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3995 - acc: 0.8431 - val_loss: 1.1810 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 319us/step - loss: 0.3980 - acc: 0.8431 - val_loss: 1.1919 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.3971 - acc: 0.8431 - val_loss: 1.1967 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3960 - acc: 0.8431 - val_loss: 1.2046 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3946 - acc: 0.8431 - val_loss: 1.2138 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3939 - acc: 0.8431 - val_loss: 1.2293 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 0.3922 - acc: 0.8431 - val_loss: 1.2430 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3913 - acc: 0.8431 - val_loss: 1.2507 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3901 - acc: 0.8431 - val_loss: 1.2627 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 191us/step - loss: 0.3899 - acc: 0.8431 - val_loss: 1.2758 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3873 - acc: 0.8431 - val_loss: 1.2848 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 213us/step - loss: 0.3857 - acc: 0.8431 - val_loss: 1.2872 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3853 - acc: 0.8431 - val_loss: 1.3016 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3842 - acc: 0.8431 - val_loss: 1.3020 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3829 - acc: 0.8431 - val_loss: 1.3085 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3808 - acc: 0.8431 - val_loss: 1.3144 - val_acc: 0.8000\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 21us/step - loss: 0.3803 - acc: 0.8431 - val_loss: 1.3278 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3792 - acc: 0.8431 - val_loss: 1.3345 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3792 - acc: 0.8431 - val_loss: 1.3408 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3770 - acc: 0.8431 - val_loss: 1.3535 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 329us/step - loss: 0.3763 - acc: 0.8431 - val_loss: 1.3647 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3754 - acc: 0.8431 - val_loss: 1.3742 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 180us/step - loss: 0.3748 - acc: 0.8431 - val_loss: 1.3778 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 178us/step - loss: 0.3733 - acc: 0.8431 - val_loss: 1.3838 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3721 - acc: 0.8431 - val_loss: 1.3872 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3707 - acc: 0.8431 - val_loss: 1.3974 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.3690 - acc: 0.8431 - val_loss: 1.4105 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3677 - acc: 0.8431 - val_loss: 1.4246 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3665 - acc: 0.8431 - val_loss: 1.4375 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3658 - acc: 0.8431 - val_loss: 1.4464 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.3640 - acc: 0.8431 - val_loss: 1.4479 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3632 - acc: 0.8431 - val_loss: 1.4582 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3619 - acc: 0.8431 - val_loss: 1.4601 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3617 - acc: 0.8431 - val_loss: 1.4626 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3592 - acc: 0.8431 - val_loss: 1.4770 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 483us/step - loss: 0.3583 - acc: 0.8431 - val_loss: 1.4925 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 305us/step - loss: 0.3571 - acc: 0.8431 - val_loss: 1.5050 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3555 - acc: 0.8431 - val_loss: 1.5127 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3546 - acc: 0.8431 - val_loss: 1.5196 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3553 - acc: 0.8431 - val_loss: 1.5298 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 222us/step - loss: 0.3530 - acc: 0.8431 - val_loss: 1.5350 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3530 - acc: 0.8431 - val_loss: 1.5384 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.3504 - acc: 0.8431 - val_loss: 1.5455 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 575us/step - loss: 0.3498 - acc: 0.8431 - val_loss: 1.5589 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3492 - acc: 0.8431 - val_loss: 1.5722 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3479 - acc: 0.8431 - val_loss: 1.5759 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3470 - acc: 0.8431 - val_loss: 1.5837 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3463 - acc: 0.8431 - val_loss: 1.5897 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3448 - acc: 0.8431 - val_loss: 1.5996 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 363us/step - loss: 0.3447 - acc: 0.8431 - val_loss: 1.6088 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3435 - acc: 0.8627 - val_loss: 1.6139 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 49us/step - loss: 0.3429 - acc: 0.8431 - val_loss: 1.6257 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3413 - acc: 0.8431 - val_loss: 1.6281 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3408 - acc: 0.8627 - val_loss: 1.6386 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.3395 - acc: 0.8627 - val_loss: 1.6426 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 302us/step - loss: 0.3382 - acc: 0.8627 - val_loss: 1.6513 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3392 - acc: 0.8627 - val_loss: 1.6532 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.3368 - acc: 0.8824 - val_loss: 1.6628 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3360 - acc: 0.8627 - val_loss: 1.6691 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3356 - acc: 0.8824 - val_loss: 1.6787 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3342 - acc: 0.8824 - val_loss: 1.6845 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3334 - acc: 0.8824 - val_loss: 1.6895 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3330 - acc: 0.8824 - val_loss: 1.7041 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.3339 - acc: 0.8627 - val_loss: 1.7089 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3313 - acc: 0.8824 - val_loss: 1.7174 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3313 - acc: 0.8824 - val_loss: 1.7222 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3306 - acc: 0.8824 - val_loss: 1.7351 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 159us/step - loss: 0.3283 - acc: 0.8824 - val_loss: 1.7453 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 345us/step - loss: 0.3277 - acc: 0.8824 - val_loss: 1.7514 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3277 - acc: 0.8824 - val_loss: 1.7619 - val_acc: 0.8000\n",
      "2017-11-14\n",
      "2017-11-15\n",
      "2017-11-16\n",
      "2017-11-17\n",
      "2017-11-20\n",
      "2017-11-21\n",
      "2017-11-22\n",
      "2017-11-23\n",
      "2017-11-24\n",
      "2017-11-27\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.7724 - acc: 0.8431 - val_loss: 1.6291 - val_acc: 0.4000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7274 - acc: 0.8431 - val_loss: 1.6115 - val_acc: 0.4000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 0.6985 - acc: 0.8431 - val_loss: 1.6018 - val_acc: 0.4000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.6759 - acc: 0.8431 - val_loss: 1.5881 - val_acc: 0.4000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 351us/step - loss: 0.6580 - acc: 0.8235 - val_loss: 1.5740 - val_acc: 0.4000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6416 - acc: 0.8235 - val_loss: 1.5603 - val_acc: 0.4000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.6279 - acc: 0.8235 - val_loss: 1.5453 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 164us/step - loss: 0.6142 - acc: 0.8431 - val_loss: 1.5370 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 173us/step - loss: 0.6054 - acc: 0.8431 - val_loss: 1.5258 - val_acc: 0.3000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 184us/step - loss: 0.5939 - acc: 0.8431 - val_loss: 1.5208 - val_acc: 0.3000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 497us/step - loss: 0.5841 - acc: 0.8431 - val_loss: 1.5088 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 383us/step - loss: 0.5732 - acc: 0.8431 - val_loss: 1.5005 - val_acc: 0.3000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5639 - acc: 0.8627 - val_loss: 1.4894 - val_acc: 0.3000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 328us/step - loss: 0.5552 - acc: 0.8627 - val_loss: 1.4796 - val_acc: 0.3000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 300us/step - loss: 0.5459 - acc: 0.8627 - val_loss: 1.4704 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.5371 - acc: 0.8824 - val_loss: 1.4601 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 522us/step - loss: 0.5301 - acc: 0.8824 - val_loss: 1.4541 - val_acc: 0.3000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.5240 - acc: 0.8824 - val_loss: 1.4498 - val_acc: 0.3000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5188 - acc: 0.8824 - val_loss: 1.4454 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.5107 - acc: 0.8824 - val_loss: 1.4369 - val_acc: 0.3000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 318us/step - loss: 0.5038 - acc: 0.8824 - val_loss: 1.4294 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.4990 - acc: 0.8824 - val_loss: 1.4230 - val_acc: 0.3000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 479us/step - loss: 0.4912 - acc: 0.8824 - val_loss: 1.4128 - val_acc: 0.3000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 263us/step - loss: 0.4835 - acc: 0.9020 - val_loss: 1.4029 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 0.4762 - acc: 0.9020 - val_loss: 1.3935 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4714 - acc: 0.9020 - val_loss: 1.3822 - val_acc: 0.3000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 588us/step - loss: 0.4624 - acc: 0.9020 - val_loss: 1.3708 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4549 - acc: 0.9020 - val_loss: 1.3593 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4469 - acc: 0.9020 - val_loss: 1.3543 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4422 - acc: 0.9020 - val_loss: 1.3446 - val_acc: 0.3000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.4367 - acc: 0.9020 - val_loss: 1.3337 - val_acc: 0.3000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 263us/step - loss: 0.4293 - acc: 0.9020 - val_loss: 1.3266 - val_acc: 0.3000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 615us/step - loss: 0.4229 - acc: 0.9020 - val_loss: 1.3177 - val_acc: 0.3000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4134 - acc: 0.9020 - val_loss: 1.3094 - val_acc: 0.3000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4068 - acc: 0.9020 - val_loss: 1.3023 - val_acc: 0.3000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4003 - acc: 0.9020 - val_loss: 1.2937 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3939 - acc: 0.9020 - val_loss: 1.2817 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3869 - acc: 0.9020 - val_loss: 1.2789 - val_acc: 0.3000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 259us/step - loss: 0.3782 - acc: 0.9020 - val_loss: 1.2672 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 173us/step - loss: 0.3689 - acc: 0.9020 - val_loss: 1.2588 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 500us/step - loss: 0.3626 - acc: 0.9020 - val_loss: 1.2539 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 249us/step - loss: 0.3565 - acc: 0.9020 - val_loss: 1.2473 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 245us/step - loss: 0.3486 - acc: 0.9020 - val_loss: 1.2409 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3431 - acc: 0.9020 - val_loss: 1.2369 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.3368 - acc: 0.9020 - val_loss: 1.2264 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 435us/step - loss: 0.3279 - acc: 0.9020 - val_loss: 1.2195 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3197 - acc: 0.9020 - val_loss: 1.2134 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 49us/step - loss: 0.3091 - acc: 0.9020 - val_loss: 1.2052 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 326us/step - loss: 0.3005 - acc: 0.9020 - val_loss: 1.1959 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 476us/step - loss: 0.2887 - acc: 0.9020 - val_loss: 1.1887 - val_acc: 0.4000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 398us/step - loss: 0.2804 - acc: 0.9020 - val_loss: 1.1817 - val_acc: 0.4000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2729 - acc: 0.9020 - val_loss: 1.1787 - val_acc: 0.4000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 463us/step - loss: 0.2649 - acc: 0.9020 - val_loss: 1.1756 - val_acc: 0.4000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 305us/step - loss: 0.2584 - acc: 0.9020 - val_loss: 1.1700 - val_acc: 0.4000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 263us/step - loss: 0.2512 - acc: 0.9020 - val_loss: 1.1696 - val_acc: 0.4000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2450 - acc: 0.9020 - val_loss: 1.1667 - val_acc: 0.4000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 522us/step - loss: 0.2403 - acc: 0.9020 - val_loss: 1.1645 - val_acc: 0.4000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.2336 - acc: 0.9020 - val_loss: 1.1633 - val_acc: 0.4000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2300 - acc: 0.9020 - val_loss: 1.1580 - val_acc: 0.4000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2248 - acc: 0.9020 - val_loss: 1.1566 - val_acc: 0.4000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2225 - acc: 0.9216 - val_loss: 1.1582 - val_acc: 0.4000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.2182 - acc: 0.9216 - val_loss: 1.1564 - val_acc: 0.4000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 185us/step - loss: 0.2166 - acc: 0.9216 - val_loss: 1.1571 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.2116 - acc: 0.9216 - val_loss: 1.1529 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2083 - acc: 0.9412 - val_loss: 1.1505 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 162us/step - loss: 0.2052 - acc: 0.9412 - val_loss: 1.1489 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 487us/step - loss: 0.2033 - acc: 0.9412 - val_loss: 1.1473 - val_acc: 0.3000\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 176us/step - loss: 0.2018 - acc: 0.9412 - val_loss: 1.1461 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 489us/step - loss: 0.2012 - acc: 0.9412 - val_loss: 1.1474 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 446us/step - loss: 0.1986 - acc: 0.9412 - val_loss: 1.1472 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.1972 - acc: 0.9412 - val_loss: 1.1455 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.1949 - acc: 0.9412 - val_loss: 1.1460 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 397us/step - loss: 0.1933 - acc: 0.9412 - val_loss: 1.1455 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.1921 - acc: 0.9412 - val_loss: 1.1425 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.1911 - acc: 0.9412 - val_loss: 1.1460 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 290us/step - loss: 0.1895 - acc: 0.9412 - val_loss: 1.1453 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.1892 - acc: 0.9412 - val_loss: 1.1475 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.1868 - acc: 0.9412 - val_loss: 1.1474 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 612us/step - loss: 0.1860 - acc: 0.9412 - val_loss: 1.1461 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 498us/step - loss: 0.1858 - acc: 0.9412 - val_loss: 1.1496 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.1855 - acc: 0.9412 - val_loss: 1.1490 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.1834 - acc: 0.9412 - val_loss: 1.1496 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.1830 - acc: 0.9412 - val_loss: 1.1492 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.1834 - acc: 0.9412 - val_loss: 1.1502 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 341us/step - loss: 0.1814 - acc: 0.9412 - val_loss: 1.1474 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.1815 - acc: 0.9412 - val_loss: 1.1471 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 341us/step - loss: 0.1803 - acc: 0.9412 - val_loss: 1.1491 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 723us/step - loss: 0.1790 - acc: 0.9412 - val_loss: 1.1481 - val_acc: 0.3000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 434us/step - loss: 0.1792 - acc: 0.9412 - val_loss: 1.1467 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 562us/step - loss: 0.1787 - acc: 0.9412 - val_loss: 1.1437 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 522us/step - loss: 0.1774 - acc: 0.9412 - val_loss: 1.1424 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.1766 - acc: 0.9412 - val_loss: 1.1421 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 464us/step - loss: 0.1758 - acc: 0.9412 - val_loss: 1.1441 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 465us/step - loss: 0.1763 - acc: 0.9412 - val_loss: 1.1462 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.1746 - acc: 0.9412 - val_loss: 1.1460 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.1750 - acc: 0.9412 - val_loss: 1.1461 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 365us/step - loss: 0.1747 - acc: 0.9412 - val_loss: 1.1460 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 736us/step - loss: 0.1741 - acc: 0.9216 - val_loss: 1.1456 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 579us/step - loss: 0.1733 - acc: 0.9216 - val_loss: 1.1493 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 722us/step - loss: 0.1724 - acc: 0.9412 - val_loss: 1.1493 - val_acc: 0.3000\n",
      "2017-11-28\n",
      "2017-11-29\n",
      "2017-11-30\n",
      "2017-12-01\n",
      "2017-12-04\n",
      "2017-12-05\n",
      "2017-12-06\n",
      "2017-12-07\n",
      "2017-12-08\n",
      "2017-12-11\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.5267 - acc: 0.7843 - val_loss: 1.1508 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 429us/step - loss: 0.4986 - acc: 0.8039 - val_loss: 1.1476 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 415us/step - loss: 0.4829 - acc: 0.8039 - val_loss: 1.1488 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 326us/step - loss: 0.4695 - acc: 0.8039 - val_loss: 1.1493 - val_acc: 0.3000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4611 - acc: 0.8039 - val_loss: 1.1509 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4545 - acc: 0.8039 - val_loss: 1.1492 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 596us/step - loss: 0.4468 - acc: 0.8039 - val_loss: 1.1510 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4402 - acc: 0.8039 - val_loss: 1.1513 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.4330 - acc: 0.8039 - val_loss: 1.1515 - val_acc: 0.3000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 282us/step - loss: 0.4289 - acc: 0.8039 - val_loss: 1.1522 - val_acc: 0.3000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4210 - acc: 0.8039 - val_loss: 1.1546 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4165 - acc: 0.8039 - val_loss: 1.1525 - val_acc: 0.3000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4125 - acc: 0.8039 - val_loss: 1.1549 - val_acc: 0.3000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 460us/step - loss: 0.4081 - acc: 0.8039 - val_loss: 1.1572 - val_acc: 0.3000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 159us/step - loss: 0.4044 - acc: 0.8235 - val_loss: 1.1558 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 178us/step - loss: 0.4001 - acc: 0.8235 - val_loss: 1.1554 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3966 - acc: 0.8235 - val_loss: 1.1518 - val_acc: 0.3000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3926 - acc: 0.8235 - val_loss: 1.1511 - val_acc: 0.3000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3880 - acc: 0.8235 - val_loss: 1.1514 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.3866 - acc: 0.8431 - val_loss: 1.1499 - val_acc: 0.3000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 288us/step - loss: 0.3835 - acc: 0.8431 - val_loss: 1.1500 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 305us/step - loss: 0.3797 - acc: 0.8431 - val_loss: 1.1503 - val_acc: 0.3000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 228us/step - loss: 0.3774 - acc: 0.8431 - val_loss: 1.1497 - val_acc: 0.3000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3743 - acc: 0.8431 - val_loss: 1.1483 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 312us/step - loss: 0.3716 - acc: 0.8431 - val_loss: 1.1492 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.3696 - acc: 0.8431 - val_loss: 1.1463 - val_acc: 0.3000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 200us/step - loss: 0.3671 - acc: 0.8431 - val_loss: 1.1482 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 715us/step - loss: 0.3647 - acc: 0.8431 - val_loss: 1.1501 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.3632 - acc: 0.8431 - val_loss: 1.1470 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 437us/step - loss: 0.3606 - acc: 0.8431 - val_loss: 1.1456 - val_acc: 0.3000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 19us/step - loss: 0.3584 - acc: 0.8431 - val_loss: 1.1458 - val_acc: 0.3000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 328us/step - loss: 0.3564 - acc: 0.8431 - val_loss: 1.1431 - val_acc: 0.3000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 0.3543 - acc: 0.8431 - val_loss: 1.1454 - val_acc: 0.3000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 956us/step - loss: 0.3534 - acc: 0.8431 - val_loss: 1.1447 - val_acc: 0.3000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3514 - acc: 0.8431 - val_loss: 1.1459 - val_acc: 0.3000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 378us/step - loss: 0.3489 - acc: 0.8431 - val_loss: 1.1482 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 501us/step - loss: 0.3461 - acc: 0.8431 - val_loss: 1.1488 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3448 - acc: 0.8627 - val_loss: 1.1468 - val_acc: 0.3000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 488us/step - loss: 0.3409 - acc: 0.8627 - val_loss: 1.1492 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 0.3396 - acc: 0.8627 - val_loss: 1.1485 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 0.3375 - acc: 0.8627 - val_loss: 1.1508 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 558us/step - loss: 0.3354 - acc: 0.8627 - val_loss: 1.1519 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3341 - acc: 0.8627 - val_loss: 1.1524 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 357us/step - loss: 0.3306 - acc: 0.8627 - val_loss: 1.1539 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 477us/step - loss: 0.3292 - acc: 0.8627 - val_loss: 1.1547 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 538us/step - loss: 0.3268 - acc: 0.8627 - val_loss: 1.1557 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 623us/step - loss: 0.3243 - acc: 0.8627 - val_loss: 1.1584 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 499us/step - loss: 0.3223 - acc: 0.8627 - val_loss: 1.1599 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.3202 - acc: 0.8627 - val_loss: 1.1620 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.3190 - acc: 0.8627 - val_loss: 1.1635 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 494us/step - loss: 0.3171 - acc: 0.8824 - val_loss: 1.1651 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3148 - acc: 0.8824 - val_loss: 1.1682 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 161us/step - loss: 0.3145 - acc: 0.8824 - val_loss: 1.1707 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.3122 - acc: 0.8824 - val_loss: 1.1692 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.3106 - acc: 0.8824 - val_loss: 1.1716 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 647us/step - loss: 0.3091 - acc: 0.8824 - val_loss: 1.1737 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 396us/step - loss: 0.3078 - acc: 0.8824 - val_loss: 1.1768 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.3062 - acc: 0.8824 - val_loss: 1.1803 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 0.3043 - acc: 0.8824 - val_loss: 1.1794 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 429us/step - loss: 0.3021 - acc: 0.8824 - val_loss: 1.1799 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.3007 - acc: 0.8824 - val_loss: 1.1801 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 210us/step - loss: 0.2996 - acc: 0.8824 - val_loss: 1.1813 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2977 - acc: 0.8824 - val_loss: 1.1830 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 556us/step - loss: 0.2960 - acc: 0.8824 - val_loss: 1.1852 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.2939 - acc: 0.8824 - val_loss: 1.1834 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 404us/step - loss: 0.2925 - acc: 0.8824 - val_loss: 1.1868 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 429us/step - loss: 0.2910 - acc: 0.8824 - val_loss: 1.1877 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2903 - acc: 0.8824 - val_loss: 1.1875 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2897 - acc: 0.8824 - val_loss: 1.1909 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2864 - acc: 0.8824 - val_loss: 1.1929 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2865 - acc: 0.8824 - val_loss: 1.1937 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 184us/step - loss: 0.2842 - acc: 0.8824 - val_loss: 1.1957 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 273us/step - loss: 0.2828 - acc: 0.8824 - val_loss: 1.1949 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 454us/step - loss: 0.2819 - acc: 0.9020 - val_loss: 1.1969 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 626us/step - loss: 0.2792 - acc: 0.9020 - val_loss: 1.1996 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2787 - acc: 0.9020 - val_loss: 1.2046 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.2770 - acc: 0.9020 - val_loss: 1.2050 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2759 - acc: 0.9020 - val_loss: 1.2018 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.2743 - acc: 0.9020 - val_loss: 1.2069 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2723 - acc: 0.9020 - val_loss: 1.2097 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 148us/step - loss: 0.2708 - acc: 0.9020 - val_loss: 1.2109 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 631us/step - loss: 0.2704 - acc: 0.9020 - val_loss: 1.2074 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2689 - acc: 0.9020 - val_loss: 1.2118 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2669 - acc: 0.9020 - val_loss: 1.2143 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2664 - acc: 0.9020 - val_loss: 1.2152 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 482us/step - loss: 0.2643 - acc: 0.9020 - val_loss: 1.2184 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.2633 - acc: 0.9020 - val_loss: 1.2159 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2625 - acc: 0.9020 - val_loss: 1.2128 - val_acc: 0.3000\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 207us/step - loss: 0.2599 - acc: 0.9020 - val_loss: 1.2145 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 97us/step - loss: 0.2588 - acc: 0.9020 - val_loss: 1.2136 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.2581 - acc: 0.9020 - val_loss: 1.2165 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.2561 - acc: 0.9020 - val_loss: 1.2210 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 0.2557 - acc: 0.9020 - val_loss: 1.2249 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.2540 - acc: 0.9020 - val_loss: 1.2218 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 375us/step - loss: 0.2527 - acc: 0.9020 - val_loss: 1.2219 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 193us/step - loss: 0.2529 - acc: 0.9020 - val_loss: 1.2286 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.2506 - acc: 0.9020 - val_loss: 1.2352 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2497 - acc: 0.9020 - val_loss: 1.2327 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 643us/step - loss: 0.2489 - acc: 0.9020 - val_loss: 1.2322 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2477 - acc: 0.9020 - val_loss: 1.2382 - val_acc: 0.3000\n",
      "2017-12-12\n",
      "2017-12-13\n",
      "2017-12-14\n",
      "2017-12-15\n",
      "2017-12-18\n",
      "2017-12-19\n",
      "2017-12-20\n",
      "2017-12-21\n",
      "2017-12-22\n",
      "2017-12-25\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.7085 - acc: 0.7255 - val_loss: 1.5780 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 715us/step - loss: 0.6622 - acc: 0.7255 - val_loss: 1.5607 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 79us/step - loss: 0.6361 - acc: 0.7255 - val_loss: 1.5416 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 478us/step - loss: 0.6108 - acc: 0.7255 - val_loss: 1.5331 - val_acc: 0.3000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 439us/step - loss: 0.5928 - acc: 0.7451 - val_loss: 1.5152 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 0.5750 - acc: 0.7647 - val_loss: 1.5093 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 179us/step - loss: 0.5634 - acc: 0.7647 - val_loss: 1.5003 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 467us/step - loss: 0.5501 - acc: 0.7647 - val_loss: 1.4886 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 184us/step - loss: 0.5328 - acc: 0.7647 - val_loss: 1.4760 - val_acc: 0.3000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.5229 - acc: 0.7647 - val_loss: 1.4618 - val_acc: 0.3000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 49us/step - loss: 0.5078 - acc: 0.7647 - val_loss: 1.4513 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 415us/step - loss: 0.4945 - acc: 0.7647 - val_loss: 1.4470 - val_acc: 0.3000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 578us/step - loss: 0.4864 - acc: 0.7647 - val_loss: 1.4353 - val_acc: 0.3000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.4767 - acc: 0.7647 - val_loss: 1.4359 - val_acc: 0.3000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 303us/step - loss: 0.4619 - acc: 0.7647 - val_loss: 1.4306 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 493us/step - loss: 0.4542 - acc: 0.7843 - val_loss: 1.4234 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 0.4441 - acc: 0.7843 - val_loss: 1.4151 - val_acc: 0.3000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 429us/step - loss: 0.4334 - acc: 0.7843 - val_loss: 1.4075 - val_acc: 0.3000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4242 - acc: 0.7843 - val_loss: 1.3971 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.4177 - acc: 0.7843 - val_loss: 1.3925 - val_acc: 0.3000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 728us/step - loss: 0.4122 - acc: 0.7843 - val_loss: 1.3823 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 584us/step - loss: 0.4071 - acc: 0.7843 - val_loss: 1.3700 - val_acc: 0.3000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4005 - acc: 0.7843 - val_loss: 1.3622 - val_acc: 0.3000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 428us/step - loss: 0.3941 - acc: 0.7843 - val_loss: 1.3552 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3894 - acc: 0.7843 - val_loss: 1.3521 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.3812 - acc: 0.8039 - val_loss: 1.3429 - val_acc: 0.3000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 593us/step - loss: 0.3744 - acc: 0.8039 - val_loss: 1.3337 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 358us/step - loss: 0.3679 - acc: 0.8039 - val_loss: 1.3314 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3646 - acc: 0.8039 - val_loss: 1.3219 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 778us/step - loss: 0.3591 - acc: 0.8235 - val_loss: 1.3171 - val_acc: 0.3000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 544us/step - loss: 0.3563 - acc: 0.8235 - val_loss: 1.3118 - val_acc: 0.3000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 532us/step - loss: 0.3493 - acc: 0.8235 - val_loss: 1.3004 - val_acc: 0.3000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 341us/step - loss: 0.3461 - acc: 0.8235 - val_loss: 1.2911 - val_acc: 0.3000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3415 - acc: 0.8431 - val_loss: 1.2847 - val_acc: 0.3000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 146us/step - loss: 0.3374 - acc: 0.8235 - val_loss: 1.2845 - val_acc: 0.3000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3339 - acc: 0.8431 - val_loss: 1.2783 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 267us/step - loss: 0.3303 - acc: 0.8431 - val_loss: 1.2730 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.3267 - acc: 0.8431 - val_loss: 1.2657 - val_acc: 0.3000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 368us/step - loss: 0.3236 - acc: 0.8431 - val_loss: 1.2605 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3194 - acc: 0.8431 - val_loss: 1.2554 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 252us/step - loss: 0.3157 - acc: 0.8431 - val_loss: 1.2543 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3128 - acc: 0.8431 - val_loss: 1.2531 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3093 - acc: 0.8431 - val_loss: 1.2445 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 175us/step - loss: 0.3072 - acc: 0.8431 - val_loss: 1.2358 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.3016 - acc: 0.8431 - val_loss: 1.2350 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2977 - acc: 0.8431 - val_loss: 1.2319 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.2962 - acc: 0.8431 - val_loss: 1.2316 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2934 - acc: 0.8431 - val_loss: 1.2238 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 264us/step - loss: 0.2887 - acc: 0.8431 - val_loss: 1.2166 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.2849 - acc: 0.8431 - val_loss: 1.2087 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.2833 - acc: 0.8431 - val_loss: 1.2045 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.2790 - acc: 0.8431 - val_loss: 1.1993 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.2779 - acc: 0.8431 - val_loss: 1.1906 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 531us/step - loss: 0.2749 - acc: 0.8431 - val_loss: 1.1916 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 199us/step - loss: 0.2705 - acc: 0.8431 - val_loss: 1.1875 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.2681 - acc: 0.8431 - val_loss: 1.1822 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 459us/step - loss: 0.2646 - acc: 0.8431 - val_loss: 1.1734 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 329us/step - loss: 0.2620 - acc: 0.8431 - val_loss: 1.1758 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.2563 - acc: 0.8431 - val_loss: 1.1683 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2522 - acc: 0.8431 - val_loss: 1.1659 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2504 - acc: 0.8235 - val_loss: 1.1564 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.2441 - acc: 0.8431 - val_loss: 1.1509 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2420 - acc: 0.8431 - val_loss: 1.1526 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 509us/step - loss: 0.2391 - acc: 0.8431 - val_loss: 1.1428 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 814us/step - loss: 0.2348 - acc: 0.8431 - val_loss: 1.1412 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.2336 - acc: 0.8627 - val_loss: 1.1332 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2283 - acc: 0.8431 - val_loss: 1.1250 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 675us/step - loss: 0.2250 - acc: 0.8627 - val_loss: 1.1237 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2224 - acc: 0.8627 - val_loss: 1.1145 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 139us/step - loss: 0.2205 - acc: 0.8627 - val_loss: 1.1084 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 401us/step - loss: 0.2183 - acc: 0.8627 - val_loss: 1.0986 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 433us/step - loss: 0.2156 - acc: 0.8627 - val_loss: 1.0928 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 345us/step - loss: 0.2126 - acc: 0.8627 - val_loss: 1.0854 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 581us/step - loss: 0.2108 - acc: 0.8824 - val_loss: 1.0876 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.2068 - acc: 0.8824 - val_loss: 1.0839 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 396us/step - loss: 0.2043 - acc: 0.8824 - val_loss: 1.0767 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 205us/step - loss: 0.2035 - acc: 0.8824 - val_loss: 1.0687 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.1995 - acc: 0.8824 - val_loss: 1.0688 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 426us/step - loss: 0.1974 - acc: 0.8824 - val_loss: 1.0652 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.1955 - acc: 0.8824 - val_loss: 1.0653 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.1925 - acc: 0.8824 - val_loss: 1.0619 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 369us/step - loss: 0.1912 - acc: 0.9020 - val_loss: 1.0624 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.1879 - acc: 0.9020 - val_loss: 1.0549 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.1874 - acc: 0.9020 - val_loss: 1.0454 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.1835 - acc: 0.9020 - val_loss: 1.0472 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 262us/step - loss: 0.1818 - acc: 0.9020 - val_loss: 1.0402 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.1805 - acc: 0.9020 - val_loss: 1.0322 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.1768 - acc: 0.9216 - val_loss: 1.0260 - val_acc: 0.3000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 430us/step - loss: 0.1752 - acc: 0.9216 - val_loss: 1.0200 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 691us/step - loss: 0.1733 - acc: 0.9216 - val_loss: 1.0198 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 401us/step - loss: 0.1716 - acc: 0.9216 - val_loss: 1.0119 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.1688 - acc: 0.9216 - val_loss: 1.0114 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 446us/step - loss: 0.1669 - acc: 0.9216 - val_loss: 1.0105 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 0.1649 - acc: 0.9216 - val_loss: 1.0077 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.1627 - acc: 0.9216 - val_loss: 1.0050 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 700us/step - loss: 0.1608 - acc: 0.9216 - val_loss: 1.0008 - val_acc: 0.4000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 603us/step - loss: 0.1589 - acc: 0.9216 - val_loss: 0.9976 - val_acc: 0.4000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.1571 - acc: 0.9216 - val_loss: 0.9958 - val_acc: 0.4000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1561 - acc: 0.9216 - val_loss: 0.9900 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 467us/step - loss: 0.1549 - acc: 0.9216 - val_loss: 0.9909 - val_acc: 0.4000\n",
      "2017-12-26\n",
      "2017-12-27\n",
      "2017-12-28\n",
      "2017-12-29\n",
      "2018-01-02\n",
      "2018-01-03\n",
      "2018-01-04\n",
      "2018-01-05\n",
      "2018-01-08\n",
      "2018-01-09\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 1.8402 - acc: 0.5294 - val_loss: 0.7637 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 1.7798 - acc: 0.5294 - val_loss: 0.7553 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 1.7381 - acc: 0.5294 - val_loss: 0.7458 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 311us/step - loss: 1.7054 - acc: 0.5294 - val_loss: 0.7299 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 452us/step - loss: 1.6772 - acc: 0.5294 - val_loss: 0.7191 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 531us/step - loss: 1.6509 - acc: 0.5294 - val_loss: 0.7160 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 644us/step - loss: 1.6261 - acc: 0.5294 - val_loss: 0.7064 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 486us/step - loss: 1.6025 - acc: 0.5294 - val_loss: 0.6972 - val_acc: 0.7000\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 177us/step - loss: 1.5862 - acc: 0.5294 - val_loss: 0.6936 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.5583 - acc: 0.5294 - val_loss: 0.6874 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 1.5367 - acc: 0.5294 - val_loss: 0.6830 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 282us/step - loss: 1.5198 - acc: 0.5294 - val_loss: 0.6827 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 566us/step - loss: 1.4993 - acc: 0.5294 - val_loss: 0.6721 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 576us/step - loss: 1.4815 - acc: 0.5294 - val_loss: 0.6633 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.4635 - acc: 0.5294 - val_loss: 0.6575 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 387us/step - loss: 1.4438 - acc: 0.5294 - val_loss: 0.6496 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 574us/step - loss: 1.4285 - acc: 0.5294 - val_loss: 0.6473 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 354us/step - loss: 1.4132 - acc: 0.5294 - val_loss: 0.6431 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 1.3969 - acc: 0.5294 - val_loss: 0.6371 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 1.3810 - acc: 0.5294 - val_loss: 0.6292 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 349us/step - loss: 1.3649 - acc: 0.5294 - val_loss: 0.6232 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.3462 - acc: 0.5294 - val_loss: 0.6182 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 269us/step - loss: 1.3358 - acc: 0.5294 - val_loss: 0.6152 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 249us/step - loss: 1.3170 - acc: 0.5294 - val_loss: 0.6173 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 338us/step - loss: 1.3088 - acc: 0.5686 - val_loss: 0.6166 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 420us/step - loss: 1.2891 - acc: 0.5686 - val_loss: 0.6102 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 347us/step - loss: 1.2783 - acc: 0.5686 - val_loss: 0.6128 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 424us/step - loss: 1.2617 - acc: 0.5686 - val_loss: 0.6106 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 802us/step - loss: 1.2469 - acc: 0.5686 - val_loss: 0.6074 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 1.2343 - acc: 0.5686 - val_loss: 0.6059 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.2234 - acc: 0.5686 - val_loss: 0.5980 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 1.2084 - acc: 0.5686 - val_loss: 0.6000 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 296us/step - loss: 1.2003 - acc: 0.5686 - val_loss: 0.5980 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 1.1835 - acc: 0.5686 - val_loss: 0.5978 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 381us/step - loss: 1.1738 - acc: 0.5686 - val_loss: 0.5942 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1620 - acc: 0.5882 - val_loss: 0.5875 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 607us/step - loss: 1.1507 - acc: 0.5882 - val_loss: 0.5874 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1364 - acc: 0.5882 - val_loss: 0.5829 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1234 - acc: 0.5882 - val_loss: 0.5819 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1113 - acc: 0.6078 - val_loss: 0.5858 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 1.0989 - acc: 0.5882 - val_loss: 0.5893 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 450us/step - loss: 1.0907 - acc: 0.5882 - val_loss: 0.5906 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 321us/step - loss: 1.0782 - acc: 0.5882 - val_loss: 0.5848 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 613us/step - loss: 1.0665 - acc: 0.5882 - val_loss: 0.5844 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 1.0562 - acc: 0.5882 - val_loss: 0.5863 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 1.0444 - acc: 0.5882 - val_loss: 0.5841 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 422us/step - loss: 1.0366 - acc: 0.6078 - val_loss: 0.5850 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 1.0222 - acc: 0.6078 - val_loss: 0.5857 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 450us/step - loss: 1.0128 - acc: 0.6078 - val_loss: 0.5875 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7439 - acc: 0.718 - 0s 0us/step - loss: 1.0031 - acc: 0.6078 - val_loss: 0.5871 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 401us/step - loss: 0.9916 - acc: 0.6275 - val_loss: 0.5830 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.9808 - acc: 0.6471 - val_loss: 0.5799 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.9726 - acc: 0.6471 - val_loss: 0.5792 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.9618 - acc: 0.6667 - val_loss: 0.5761 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 423us/step - loss: 0.9524 - acc: 0.6667 - val_loss: 0.5794 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.9412 - acc: 0.6667 - val_loss: 0.5780 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.9374 - acc: 0.6667 - val_loss: 0.5801 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.9235 - acc: 0.6667 - val_loss: 0.5786 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9144 - acc: 0.6667 - val_loss: 0.5772 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 309us/step - loss: 0.9062 - acc: 0.6471 - val_loss: 0.5763 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 402us/step - loss: 0.8970 - acc: 0.6275 - val_loss: 0.5773 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 194us/step - loss: 0.8919 - acc: 0.6078 - val_loss: 0.5777 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8829 - acc: 0.6078 - val_loss: 0.5732 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8740 - acc: 0.6275 - val_loss: 0.5748 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 0.8633 - acc: 0.6275 - val_loss: 0.5740 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8545 - acc: 0.6275 - val_loss: 0.5747 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.8483 - acc: 0.6078 - val_loss: 0.5710 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8395 - acc: 0.6275 - val_loss: 0.5676 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.8349 - acc: 0.6275 - val_loss: 0.5639 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8945 - acc: 0.593 - 0s 294us/step - loss: 0.8252 - acc: 0.6275 - val_loss: 0.5627 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8203 - acc: 0.6078 - val_loss: 0.5633 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 457us/step - loss: 0.8122 - acc: 0.6275 - val_loss: 0.5588 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 569us/step - loss: 0.8076 - acc: 0.6078 - val_loss: 0.5578 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7974 - acc: 0.6078 - val_loss: 0.5575 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.7896 - acc: 0.6275 - val_loss: 0.5575 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7833 - acc: 0.6078 - val_loss: 0.5554 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.7749 - acc: 0.5882 - val_loss: 0.5566 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 362us/step - loss: 0.7704 - acc: 0.5882 - val_loss: 0.5588 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.7629 - acc: 0.5882 - val_loss: 0.5620 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 509us/step - loss: 0.7570 - acc: 0.5882 - val_loss: 0.5640 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7477 - acc: 0.6078 - val_loss: 0.5612 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7450 - acc: 0.5882 - val_loss: 0.5579 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 266us/step - loss: 0.7365 - acc: 0.5882 - val_loss: 0.5616 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7355 - acc: 0.5882 - val_loss: 0.5613 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7290 - acc: 0.5882 - val_loss: 0.5619 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.7205 - acc: 0.6275 - val_loss: 0.5649 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 491us/step - loss: 0.7145 - acc: 0.6275 - val_loss: 0.5622 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 249us/step - loss: 0.7146 - acc: 0.5882 - val_loss: 0.5642 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7044 - acc: 0.6275 - val_loss: 0.5674 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 628us/step - loss: 0.7007 - acc: 0.5882 - val_loss: 0.5658 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.6951 - acc: 0.6275 - val_loss: 0.5640 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.6880 - acc: 0.6078 - val_loss: 0.5622 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.6839 - acc: 0.6078 - val_loss: 0.5616 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6796 - acc: 0.6078 - val_loss: 0.5624 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.6754 - acc: 0.5882 - val_loss: 0.5600 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6700 - acc: 0.6078 - val_loss: 0.5553 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6699 - acc: 0.6078 - val_loss: 0.5537 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 159us/step - loss: 0.6610 - acc: 0.6078 - val_loss: 0.5544 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 174us/step - loss: 0.6585 - acc: 0.6471 - val_loss: 0.5548 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 232us/step - loss: 0.6525 - acc: 0.6471 - val_loss: 0.5556 - val_acc: 0.7000\n",
      "2018-01-10\n",
      "2018-01-11\n",
      "2018-01-12\n",
      "2018-01-15\n",
      "2018-01-16\n",
      "2018-01-17\n",
      "2018-01-18\n",
      "2018-01-19\n",
      "2018-01-22\n",
      "2018-01-23\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.7658 - acc: 0.5686 - val_loss: 2.1911 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 479us/step - loss: 0.7304 - acc: 0.5882 - val_loss: 2.2054 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 151us/step - loss: 0.7072 - acc: 0.6078 - val_loss: 2.2154 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6910 - acc: 0.6275 - val_loss: 2.2200 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 635us/step - loss: 0.6760 - acc: 0.6275 - val_loss: 2.2237 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6624 - acc: 0.6275 - val_loss: 2.2204 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 264us/step - loss: 0.6521 - acc: 0.6275 - val_loss: 2.2222 - val_acc: 0.6000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 665us/step - loss: 0.6415 - acc: 0.6471 - val_loss: 2.2263 - val_acc: 0.6000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.6315 - acc: 0.6667 - val_loss: 2.2176 - val_acc: 0.6000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 370us/step - loss: 0.6207 - acc: 0.6667 - val_loss: 2.2210 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5785 - acc: 0.718 - 0s 0us/step - loss: 0.6134 - acc: 0.6667 - val_loss: 2.2138 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6042 - acc: 0.6863 - val_loss: 2.2200 - val_acc: 0.6000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 108us/step - loss: 0.5951 - acc: 0.7059 - val_loss: 2.2128 - val_acc: 0.6000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5887 - acc: 0.7059 - val_loss: 2.2086 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 276us/step - loss: 0.5824 - acc: 0.7059 - val_loss: 2.2021 - val_acc: 0.6000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5741 - acc: 0.7059 - val_loss: 2.2047 - val_acc: 0.6000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 519us/step - loss: 0.5669 - acc: 0.7059 - val_loss: 2.1981 - val_acc: 0.6000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 573us/step - loss: 0.5611 - acc: 0.7059 - val_loss: 2.1908 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 495us/step - loss: 0.5533 - acc: 0.7059 - val_loss: 2.1894 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5477 - acc: 0.7255 - val_loss: 2.1918 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.5443 - acc: 0.7255 - val_loss: 2.2000 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 267us/step - loss: 0.5358 - acc: 0.7255 - val_loss: 2.1975 - val_acc: 0.6000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5302 - acc: 0.7255 - val_loss: 2.2048 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.5244 - acc: 0.7255 - val_loss: 2.2074 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 475us/step - loss: 0.5221 - acc: 0.7255 - val_loss: 2.1982 - val_acc: 0.6000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 530us/step - loss: 0.5166 - acc: 0.7255 - val_loss: 2.2052 - val_acc: 0.6000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 109us/step - loss: 0.5097 - acc: 0.7255 - val_loss: 2.2082 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5045 - acc: 0.7451 - val_loss: 2.2028 - val_acc: 0.6000\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 517us/step - loss: 0.5029 - acc: 0.7255 - val_loss: 2.2071 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4956 - acc: 0.7451 - val_loss: 2.2060 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4920 - acc: 0.7647 - val_loss: 2.2013 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 592us/step - loss: 0.4867 - acc: 0.7843 - val_loss: 2.1966 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 497us/step - loss: 0.4830 - acc: 0.8039 - val_loss: 2.1891 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 199us/step - loss: 0.4779 - acc: 0.8235 - val_loss: 2.1864 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4732 - acc: 0.8235 - val_loss: 2.1795 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 562us/step - loss: 0.4690 - acc: 0.8039 - val_loss: 2.1812 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 238us/step - loss: 0.4671 - acc: 0.8039 - val_loss: 2.1866 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.4626 - acc: 0.8235 - val_loss: 2.1909 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.4586 - acc: 0.8235 - val_loss: 2.1841 - val_acc: 0.6000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 462us/step - loss: 0.4551 - acc: 0.8235 - val_loss: 2.1841 - val_acc: 0.6000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 504us/step - loss: 0.4530 - acc: 0.8235 - val_loss: 2.1749 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4602 - acc: 0.843 - 0s 0us/step - loss: 0.4494 - acc: 0.8235 - val_loss: 2.1670 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 520us/step - loss: 0.4453 - acc: 0.8431 - val_loss: 2.1690 - val_acc: 0.6000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 415us/step - loss: 0.4432 - acc: 0.8431 - val_loss: 2.1735 - val_acc: 0.6000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 193us/step - loss: 0.4401 - acc: 0.8431 - val_loss: 2.1763 - val_acc: 0.6000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 497us/step - loss: 0.4394 - acc: 0.8235 - val_loss: 2.1677 - val_acc: 0.6000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4343 - acc: 0.8431 - val_loss: 2.1707 - val_acc: 0.6000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 441us/step - loss: 0.4315 - acc: 0.8235 - val_loss: 2.1683 - val_acc: 0.6000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 278us/step - loss: 0.4295 - acc: 0.8235 - val_loss: 2.1616 - val_acc: 0.6000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 62us/step - loss: 0.4262 - acc: 0.8235 - val_loss: 2.1602 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.4234 - acc: 0.8235 - val_loss: 2.1563 - val_acc: 0.6000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4226 - acc: 0.8235 - val_loss: 2.1621 - val_acc: 0.6000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 367us/step - loss: 0.4169 - acc: 0.8431 - val_loss: 2.1610 - val_acc: 0.6000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4161 - acc: 0.8431 - val_loss: 2.1526 - val_acc: 0.6000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 342us/step - loss: 0.4126 - acc: 0.8431 - val_loss: 2.1482 - val_acc: 0.6000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 427us/step - loss: 0.4115 - acc: 0.8431 - val_loss: 2.1395 - val_acc: 0.6000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 527us/step - loss: 0.4077 - acc: 0.8431 - val_loss: 2.1323 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 397us/step - loss: 0.4038 - acc: 0.8627 - val_loss: 2.1312 - val_acc: 0.6000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 301us/step - loss: 0.4013 - acc: 0.8627 - val_loss: 2.1285 - val_acc: 0.6000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.3986 - acc: 0.8627 - val_loss: 2.1267 - val_acc: 0.6000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3953 - acc: 0.8627 - val_loss: 2.1275 - val_acc: 0.6000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3938 - acc: 0.8431 - val_loss: 2.1212 - val_acc: 0.6000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 200us/step - loss: 0.3908 - acc: 0.8627 - val_loss: 2.1254 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 420us/step - loss: 0.3879 - acc: 0.8627 - val_loss: 2.1297 - val_acc: 0.6000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 248us/step - loss: 0.3871 - acc: 0.8431 - val_loss: 2.1335 - val_acc: 0.6000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 264us/step - loss: 0.3834 - acc: 0.8431 - val_loss: 2.1275 - val_acc: 0.6000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3810 - acc: 0.8431 - val_loss: 2.1260 - val_acc: 0.6000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 421us/step - loss: 0.3797 - acc: 0.8431 - val_loss: 2.1192 - val_acc: 0.6000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3780 - acc: 0.8431 - val_loss: 2.1134 - val_acc: 0.6000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 406us/step - loss: 0.3738 - acc: 0.8627 - val_loss: 2.1198 - val_acc: 0.6000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.4333 - acc: 0.843 - 0s 0us/step - loss: 0.3728 - acc: 0.8627 - val_loss: 2.1264 - val_acc: 0.6000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 610us/step - loss: 0.3706 - acc: 0.8431 - val_loss: 2.1271 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 324us/step - loss: 0.3679 - acc: 0.8431 - val_loss: 2.1235 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3666 - acc: 0.8627 - val_loss: 2.1264 - val_acc: 0.6000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 0.3648 - acc: 0.8431 - val_loss: 2.1182 - val_acc: 0.6000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.3628 - acc: 0.8627 - val_loss: 2.1241 - val_acc: 0.6000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 279us/step - loss: 0.3595 - acc: 0.8431 - val_loss: 2.1173 - val_acc: 0.6000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 659us/step - loss: 0.3562 - acc: 0.8431 - val_loss: 2.1103 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3856 - acc: 0.843 - 0s 340us/step - loss: 0.3541 - acc: 0.8627 - val_loss: 2.1056 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 423us/step - loss: 0.3516 - acc: 0.8627 - val_loss: 2.1003 - val_acc: 0.6000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3498 - acc: 0.8627 - val_loss: 2.1025 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 328us/step - loss: 0.3496 - acc: 0.8431 - val_loss: 2.0953 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 425us/step - loss: 0.3465 - acc: 0.8627 - val_loss: 2.0992 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3441 - acc: 0.8431 - val_loss: 2.0912 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3410 - acc: 0.8431 - val_loss: 2.0798 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3373 - acc: 0.8824 - val_loss: 2.0750 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3363 - acc: 0.8824 - val_loss: 2.0801 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 421us/step - loss: 0.3339 - acc: 0.8824 - val_loss: 2.0738 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3312 - acc: 0.8627 - val_loss: 2.0664 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3285 - acc: 0.8824 - val_loss: 2.0678 - val_acc: 0.6000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 381us/step - loss: 0.3259 - acc: 0.8627 - val_loss: 2.0678 - val_acc: 0.6000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3237 - acc: 0.8824 - val_loss: 2.0685 - val_acc: 0.6000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3221 - acc: 0.8824 - val_loss: 2.0715 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3209 - acc: 0.8431 - val_loss: 2.0645 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3195 - acc: 0.8824 - val_loss: 2.0708 - val_acc: 0.6000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3182 - acc: 0.8431 - val_loss: 2.0750 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3145 - acc: 0.8431 - val_loss: 2.0719 - val_acc: 0.6000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3123 - acc: 0.8431 - val_loss: 2.0711 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3116 - acc: 0.8431 - val_loss: 2.0687 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3110 - acc: 0.8431 - val_loss: 2.0743 - val_acc: 0.6000\n",
      "2018-01-24\n",
      "2018-01-25\n",
      "2018-01-26\n",
      "2018-01-29\n",
      "2018-01-30\n",
      "2018-01-31\n",
      "2018-02-01\n",
      "2018-02-02\n",
      "2018-02-05\n",
      "2018-02-06\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 1.0879 - acc: 0.6078 - val_loss: 0.7729 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0332 - acc: 0.6275 - val_loss: 0.7686 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 1.0000 - acc: 0.6275 - val_loss: 0.7600 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 435us/step - loss: 0.9725 - acc: 0.6275 - val_loss: 0.7511 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.9473 - acc: 0.6275 - val_loss: 0.7447 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 632us/step - loss: 0.9247 - acc: 0.6275 - val_loss: 0.7412 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.9051 - acc: 0.6078 - val_loss: 0.7372 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8873 - acc: 0.6471 - val_loss: 0.7312 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8679 - acc: 0.6471 - val_loss: 0.7270 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 577us/step - loss: 0.8511 - acc: 0.6275 - val_loss: 0.7243 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.8356 - acc: 0.6667 - val_loss: 0.7226 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 601us/step - loss: 0.8223 - acc: 0.6667 - val_loss: 0.7151 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 278us/step - loss: 0.7991 - acc: 0.6667 - val_loss: 0.7121 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7822 - acc: 0.6667 - val_loss: 0.7062 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7655 - acc: 0.6863 - val_loss: 0.7026 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 208us/step - loss: 0.7528 - acc: 0.6667 - val_loss: 0.6949 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7349 - acc: 0.6863 - val_loss: 0.6904 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.7185 - acc: 0.6863 - val_loss: 0.6846 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 135us/step - loss: 0.7048 - acc: 0.6863 - val_loss: 0.6809 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6926 - acc: 0.6863 - val_loss: 0.6746 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 40us/step - loss: 0.6794 - acc: 0.6863 - val_loss: 0.6695 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.6638 - acc: 0.6863 - val_loss: 0.6640 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 450us/step - loss: 0.6499 - acc: 0.6863 - val_loss: 0.6575 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6367 - acc: 0.6863 - val_loss: 0.6540 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 303us/step - loss: 0.6244 - acc: 0.6863 - val_loss: 0.6492 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 321us/step - loss: 0.6143 - acc: 0.7255 - val_loss: 0.6477 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6008 - acc: 0.7255 - val_loss: 0.6438 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 628us/step - loss: 0.5883 - acc: 0.7255 - val_loss: 0.6387 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.5765 - acc: 0.7451 - val_loss: 0.6335 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 509us/step - loss: 0.5656 - acc: 0.7451 - val_loss: 0.6288 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5551 - acc: 0.7647 - val_loss: 0.6252 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5444 - acc: 0.7647 - val_loss: 0.6204 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.5350 - acc: 0.7647 - val_loss: 0.6180 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.5260 - acc: 0.7647 - val_loss: 0.6132 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5155 - acc: 0.7647 - val_loss: 0.6085 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.5068 - acc: 0.7647 - val_loss: 0.6023 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 435us/step - loss: 0.4966 - acc: 0.7647 - val_loss: 0.5967 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 248us/step - loss: 0.4874 - acc: 0.7647 - val_loss: 0.5926 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5062 - acc: 0.750 - 0s 307us/step - loss: 0.4792 - acc: 0.7647 - val_loss: 0.5875 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 699us/step - loss: 0.4695 - acc: 0.7647 - val_loss: 0.5819 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4601 - acc: 0.7647 - val_loss: 0.5778 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4532 - acc: 0.7647 - val_loss: 0.5728 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4445 - acc: 0.7647 - val_loss: 0.5681 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 354us/step - loss: 0.4387 - acc: 0.7647 - val_loss: 0.5617 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.4301 - acc: 0.7647 - val_loss: 0.5580 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4247 - acc: 0.7647 - val_loss: 0.5526 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4172 - acc: 0.7647 - val_loss: 0.5487 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.4111 - acc: 0.7843 - val_loss: 0.5454 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4040 - acc: 0.7843 - val_loss: 0.5407 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 460us/step - loss: 0.3974 - acc: 0.8039 - val_loss: 0.5387 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 447us/step - loss: 0.3906 - acc: 0.7843 - val_loss: 0.5360 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 326us/step - loss: 0.3852 - acc: 0.7843 - val_loss: 0.5308 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 0.3791 - acc: 0.7843 - val_loss: 0.5245 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 424us/step - loss: 0.3739 - acc: 0.8039 - val_loss: 0.5211 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 251us/step - loss: 0.3685 - acc: 0.8039 - val_loss: 0.5183 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 391us/step - loss: 0.3654 - acc: 0.8039 - val_loss: 0.5154 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3586 - acc: 0.8235 - val_loss: 0.5137 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 609us/step - loss: 0.3520 - acc: 0.8235 - val_loss: 0.5104 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3473 - acc: 0.8235 - val_loss: 0.5040 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.3409 - acc: 0.8235 - val_loss: 0.5016 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3368 - acc: 0.8235 - val_loss: 0.4987 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 339us/step - loss: 0.3329 - acc: 0.8235 - val_loss: 0.4950 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 449us/step - loss: 0.3277 - acc: 0.8235 - val_loss: 0.4922 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3233 - acc: 0.8235 - val_loss: 0.4904 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 168us/step - loss: 0.3200 - acc: 0.8235 - val_loss: 0.4894 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3163 - acc: 0.8235 - val_loss: 0.4853 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3116 - acc: 0.8235 - val_loss: 0.4817 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3086 - acc: 0.8039 - val_loss: 0.4795 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3044 - acc: 0.8039 - val_loss: 0.4753 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.3005 - acc: 0.8039 - val_loss: 0.4725 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 594us/step - loss: 0.2976 - acc: 0.8039 - val_loss: 0.4704 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2935 - acc: 0.8039 - val_loss: 0.4665 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2891 - acc: 0.8235 - val_loss: 0.4645 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.2855 - acc: 0.8235 - val_loss: 0.4646 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 231us/step - loss: 0.2824 - acc: 0.8235 - val_loss: 0.4631 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 360us/step - loss: 0.2780 - acc: 0.8431 - val_loss: 0.4622 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 0.2760 - acc: 0.8627 - val_loss: 0.4619 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.2734 - acc: 0.9020 - val_loss: 0.4600 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.2700 - acc: 0.9020 - val_loss: 0.4577 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2660 - acc: 0.9020 - val_loss: 0.4546 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.2622 - acc: 0.9020 - val_loss: 0.4544 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 158us/step - loss: 0.2599 - acc: 0.9020 - val_loss: 0.4534 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 231us/step - loss: 0.2568 - acc: 0.9020 - val_loss: 0.4516 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.2548 - acc: 0.9020 - val_loss: 0.4486 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2521 - acc: 0.9020 - val_loss: 0.4467 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2495 - acc: 0.9020 - val_loss: 0.4458 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2482 - acc: 0.9020 - val_loss: 0.4448 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.2458 - acc: 0.9020 - val_loss: 0.4447 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2440 - acc: 0.9020 - val_loss: 0.4442 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.2422 - acc: 0.9020 - val_loss: 0.4453 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 634us/step - loss: 0.2421 - acc: 0.9020 - val_loss: 0.4427 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 611us/step - loss: 0.2396 - acc: 0.9020 - val_loss: 0.4438 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2379 - acc: 0.9216 - val_loss: 0.4422 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2358 - acc: 0.9216 - val_loss: 0.4440 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2345 - acc: 0.9216 - val_loss: 0.4439 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2338 - acc: 0.9216 - val_loss: 0.4454 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 447us/step - loss: 0.2314 - acc: 0.9020 - val_loss: 0.4444 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2314 - acc: 0.9020 - val_loss: 0.4454 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.2287 - acc: 0.9020 - val_loss: 0.4482 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 494us/step - loss: 0.2280 - acc: 0.9020 - val_loss: 0.4490 - val_acc: 0.7000\n",
      "2018-02-07\n",
      "2018-02-08\n",
      "2018-02-09\n",
      "2018-02-12\n",
      "2018-02-13\n",
      "2018-02-14\n",
      "2018-02-22\n",
      "2018-02-23\n",
      "2018-02-26\n",
      "2018-02-27\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 1.3120 - acc: 0.5686 - val_loss: 0.6577 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 205us/step - loss: 1.2413 - acc: 0.5686 - val_loss: 0.6529 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.1932 - acc: 0.5686 - val_loss: 0.6439 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.1503 - acc: 0.5686 - val_loss: 0.6386 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.1114 - acc: 0.5882 - val_loss: 0.6311 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 299us/step - loss: 1.0820 - acc: 0.5882 - val_loss: 0.6197 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 1.0526 - acc: 0.5882 - val_loss: 0.6092 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.0243 - acc: 0.5882 - val_loss: 0.6112 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 613us/step - loss: 0.9935 - acc: 0.6275 - val_loss: 0.6025 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 342us/step - loss: 0.9685 - acc: 0.6275 - val_loss: 0.5934 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 424us/step - loss: 0.9443 - acc: 0.6275 - val_loss: 0.5923 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.9190 - acc: 0.6275 - val_loss: 0.5833 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 648us/step - loss: 0.8941 - acc: 0.6275 - val_loss: 0.5799 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.8712 - acc: 0.6275 - val_loss: 0.5700 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.8489 - acc: 0.6275 - val_loss: 0.5635 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 149us/step - loss: 0.8277 - acc: 0.6275 - val_loss: 0.5586 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 324us/step - loss: 0.8067 - acc: 0.6471 - val_loss: 0.5554 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 754us/step - loss: 0.7816 - acc: 0.6471 - val_loss: 0.5460 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7579 - acc: 0.6471 - val_loss: 0.5389 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 381us/step - loss: 0.7411 - acc: 0.6471 - val_loss: 0.5351 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 675us/step - loss: 0.7212 - acc: 0.6471 - val_loss: 0.5286 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7020 - acc: 0.6471 - val_loss: 0.5180 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 463us/step - loss: 0.6823 - acc: 0.6667 - val_loss: 0.5103 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 669us/step - loss: 0.6682 - acc: 0.6667 - val_loss: 0.5052 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.6494 - acc: 0.7059 - val_loss: 0.4968 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 192us/step - loss: 0.6343 - acc: 0.7059 - val_loss: 0.4881 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.6202 - acc: 0.7059 - val_loss: 0.4819 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 418us/step - loss: 0.6048 - acc: 0.7255 - val_loss: 0.4758 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 305us/step - loss: 0.5877 - acc: 0.7451 - val_loss: 0.4671 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.5715 - acc: 0.7451 - val_loss: 0.4611 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.5557 - acc: 0.7451 - val_loss: 0.4515 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.5370 - acc: 0.7647 - val_loss: 0.4439 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.5228 - acc: 0.7647 - val_loss: 0.4378 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5089 - acc: 0.7647 - val_loss: 0.4345 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4953 - acc: 0.7647 - val_loss: 0.4300 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4816 - acc: 0.7647 - val_loss: 0.4222 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4639 - acc: 0.7647 - val_loss: 0.4177 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4476 - acc: 0.7647 - val_loss: 0.4128 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 478us/step - loss: 0.4334 - acc: 0.7843 - val_loss: 0.4072 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 453us/step - loss: 0.4203 - acc: 0.8039 - val_loss: 0.4001 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4076 - acc: 0.7843 - val_loss: 0.3999 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 468us/step - loss: 0.3981 - acc: 0.8039 - val_loss: 0.3988 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.3885 - acc: 0.8235 - val_loss: 0.3964 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3791 - acc: 0.8431 - val_loss: 0.3899 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 354us/step - loss: 0.3701 - acc: 0.8431 - val_loss: 0.3831 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 154us/step - loss: 0.3643 - acc: 0.8431 - val_loss: 0.3820 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 494us/step - loss: 0.3561 - acc: 0.8431 - val_loss: 0.3791 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 834us/step - loss: 0.3483 - acc: 0.8627 - val_loss: 0.3722 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 0.3420 - acc: 0.8627 - val_loss: 0.3697 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 486us/step - loss: 0.3357 - acc: 0.8627 - val_loss: 0.3646 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.3295 - acc: 0.8627 - val_loss: 0.3571 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3253 - acc: 0.8824 - val_loss: 0.3524 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3189 - acc: 0.9020 - val_loss: 0.3452 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3132 - acc: 0.9020 - val_loss: 0.3404 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3100 - acc: 0.9020 - val_loss: 0.3328 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.3064 - acc: 0.9020 - val_loss: 0.3257 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3003 - acc: 0.9020 - val_loss: 0.3218 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2961 - acc: 0.9216 - val_loss: 0.3183 - val_acc: 0.9000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2915 - acc: 0.9216 - val_loss: 0.3159 - val_acc: 0.9000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 752us/step - loss: 0.2890 - acc: 0.9216 - val_loss: 0.3128 - val_acc: 0.9000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2865 - acc: 0.9216 - val_loss: 0.3079 - val_acc: 0.9000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2834 - acc: 0.9216 - val_loss: 0.3090 - val_acc: 0.9000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2811 - acc: 0.9216 - val_loss: 0.3112 - val_acc: 0.9000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 304us/step - loss: 0.2769 - acc: 0.9216 - val_loss: 0.3102 - val_acc: 0.9000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2740 - acc: 0.9216 - val_loss: 0.3078 - val_acc: 0.9000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 404us/step - loss: 0.2711 - acc: 0.9216 - val_loss: 0.3058 - val_acc: 0.9000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2685 - acc: 0.9216 - val_loss: 0.3048 - val_acc: 0.9000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 508us/step - loss: 0.2663 - acc: 0.9216 - val_loss: 0.3081 - val_acc: 0.9000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2620 - acc: 0.9216 - val_loss: 0.3066 - val_acc: 0.9000\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 275us/step - loss: 0.2595 - acc: 0.9216 - val_loss: 0.3076 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2571 - acc: 0.9216 - val_loss: 0.3028 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 662us/step - loss: 0.2542 - acc: 0.9216 - val_loss: 0.3025 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 218us/step - loss: 0.2520 - acc: 0.9216 - val_loss: 0.3045 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 149us/step - loss: 0.2498 - acc: 0.9216 - val_loss: 0.2997 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 269us/step - loss: 0.2475 - acc: 0.9216 - val_loss: 0.3019 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 347us/step - loss: 0.2459 - acc: 0.9216 - val_loss: 0.3041 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 231us/step - loss: 0.2417 - acc: 0.9216 - val_loss: 0.3034 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.2395 - acc: 0.9216 - val_loss: 0.2993 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2367 - acc: 0.9216 - val_loss: 0.3000 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2354 - acc: 0.9216 - val_loss: 0.3030 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2321 - acc: 0.9216 - val_loss: 0.3020 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 620us/step - loss: 0.2310 - acc: 0.9216 - val_loss: 0.3030 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2290 - acc: 0.9216 - val_loss: 0.3037 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 203us/step - loss: 0.2258 - acc: 0.9216 - val_loss: 0.3046 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 491us/step - loss: 0.2227 - acc: 0.9216 - val_loss: 0.3031 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 456us/step - loss: 0.2204 - acc: 0.9216 - val_loss: 0.3022 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2188 - acc: 0.9216 - val_loss: 0.3037 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.2162 - acc: 0.9216 - val_loss: 0.3057 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 264us/step - loss: 0.2134 - acc: 0.9216 - val_loss: 0.3042 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2121 - acc: 0.9216 - val_loss: 0.3044 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.2082 - acc: 0.9216 - val_loss: 0.3022 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 746us/step - loss: 0.2060 - acc: 0.9216 - val_loss: 0.3015 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.2033 - acc: 0.9216 - val_loss: 0.2964 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 371us/step - loss: 0.2011 - acc: 0.9216 - val_loss: 0.2965 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.1994 - acc: 0.9216 - val_loss: 0.2936 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.1963 - acc: 0.9216 - val_loss: 0.2911 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 319us/step - loss: 0.1949 - acc: 0.9216 - val_loss: 0.2915 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.1915 - acc: 0.9216 - val_loss: 0.2922 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.1899 - acc: 0.9216 - val_loss: 0.2905 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.1874 - acc: 0.9216 - val_loss: 0.2925 - val_acc: 0.8000\n",
      "2018-02-28\n",
      "2018-03-01\n",
      "2018-03-02\n",
      "2018-03-05\n",
      "2018-03-06\n",
      "2018-03-07\n",
      "2018-03-08\n",
      "2018-03-09\n",
      "2018-03-12\n",
      "2018-03-13\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 2.0566 - acc: 0.5686 - val_loss: 2.6103 - val_acc: 0.4000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.9572 - acc: 0.5686 - val_loss: 2.5784 - val_acc: 0.4000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 409us/step - loss: 1.8734 - acc: 0.5686 - val_loss: 2.5354 - val_acc: 0.4000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 374us/step - loss: 1.7986 - acc: 0.5686 - val_loss: 2.5074 - val_acc: 0.4000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.7384 - acc: 0.5686 - val_loss: 2.5034 - val_acc: 0.4000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.6852 - acc: 0.5686 - val_loss: 2.4774 - val_acc: 0.4000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 465us/step - loss: 1.6297 - acc: 0.5882 - val_loss: 2.4584 - val_acc: 0.4000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 1.5816 - acc: 0.6078 - val_loss: 2.4364 - val_acc: 0.4000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 1.5331 - acc: 0.6078 - val_loss: 2.4265 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.4913 - acc: 0.6078 - val_loss: 2.4060 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 340us/step - loss: 1.4487 - acc: 0.6078 - val_loss: 2.3866 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 1.4169 - acc: 0.6078 - val_loss: 2.3853 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.3806 - acc: 0.6078 - val_loss: 2.3793 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 1.3477 - acc: 0.6078 - val_loss: 2.3691 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3162 - acc: 0.6078 - val_loss: 2.3484 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.2879 - acc: 0.6078 - val_loss: 2.3234 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.2502 - acc: 0.6275 - val_loss: 2.3078 - val_acc: 0.4000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.2224 - acc: 0.6275 - val_loss: 2.2894 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1875 - acc: 0.6275 - val_loss: 2.2614 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 1.1588 - acc: 0.6471 - val_loss: 2.2509 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.1318 - acc: 0.6471 - val_loss: 2.2331 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 1.1065 - acc: 0.6471 - val_loss: 2.2083 - val_acc: 0.4000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 1.0760 - acc: 0.6471 - val_loss: 2.1993 - val_acc: 0.4000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0528 - acc: 0.6471 - val_loss: 2.1930 - val_acc: 0.4000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.0317 - acc: 0.6667 - val_loss: 2.1755 - val_acc: 0.4000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.0097 - acc: 0.6667 - val_loss: 2.1595 - val_acc: 0.4000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.9900 - acc: 0.6667 - val_loss: 2.1503 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.9663 - acc: 0.6667 - val_loss: 2.1433 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.9464 - acc: 0.6863 - val_loss: 2.1308 - val_acc: 0.4000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 261us/step - loss: 0.9287 - acc: 0.6863 - val_loss: 2.1205 - val_acc: 0.4000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9083 - acc: 0.7059 - val_loss: 2.1043 - val_acc: 0.4000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8857 - acc: 0.7059 - val_loss: 2.0831 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8649 - acc: 0.7059 - val_loss: 2.0741 - val_acc: 0.4000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8469 - acc: 0.7059 - val_loss: 2.0589 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.8317 - acc: 0.7059 - val_loss: 2.0488 - val_acc: 0.4000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 342us/step - loss: 0.8110 - acc: 0.7059 - val_loss: 2.0289 - val_acc: 0.4000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 481us/step - loss: 0.7917 - acc: 0.7059 - val_loss: 2.0057 - val_acc: 0.4000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7761 - acc: 0.7059 - val_loss: 1.9919 - val_acc: 0.4000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.7602 - acc: 0.7059 - val_loss: 1.9740 - val_acc: 0.4000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 347us/step - loss: 0.7457 - acc: 0.7059 - val_loss: 1.9553 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 229us/step - loss: 0.7309 - acc: 0.7059 - val_loss: 1.9399 - val_acc: 0.4000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 403us/step - loss: 0.7157 - acc: 0.7059 - val_loss: 1.9258 - val_acc: 0.4000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 0.7027 - acc: 0.7059 - val_loss: 1.9107 - val_acc: 0.4000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.6921 - acc: 0.7255 - val_loss: 1.8936 - val_acc: 0.4000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 475us/step - loss: 0.6788 - acc: 0.7451 - val_loss: 1.8733 - val_acc: 0.4000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 199us/step - loss: 0.6678 - acc: 0.7451 - val_loss: 1.8470 - val_acc: 0.4000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.6094 - acc: 0.750 - 0s 317us/step - loss: 0.6525 - acc: 0.7451 - val_loss: 1.8364 - val_acc: 0.4000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5837 - acc: 0.750 - 0s 0us/step - loss: 0.6396 - acc: 0.7451 - val_loss: 1.8156 - val_acc: 0.4000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6269 - acc: 0.7451 - val_loss: 1.7952 - val_acc: 0.4000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 407us/step - loss: 0.6163 - acc: 0.7451 - val_loss: 1.7963 - val_acc: 0.4000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 635us/step - loss: 0.6043 - acc: 0.7451 - val_loss: 1.7908 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 463us/step - loss: 0.5935 - acc: 0.7647 - val_loss: 1.7759 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 697us/step - loss: 0.5806 - acc: 0.7451 - val_loss: 1.7705 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 361us/step - loss: 0.5704 - acc: 0.7647 - val_loss: 1.7692 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5600 - acc: 0.7647 - val_loss: 1.7385 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.5519 - acc: 0.7647 - val_loss: 1.7336 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.5414 - acc: 0.7647 - val_loss: 1.7266 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.5337 - acc: 0.7451 - val_loss: 1.7005 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.5246 - acc: 0.7647 - val_loss: 1.6943 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.5143 - acc: 0.7647 - val_loss: 1.6860 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5070 - acc: 0.718 - 0s 235us/step - loss: 0.5059 - acc: 0.7647 - val_loss: 1.6660 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.4982 - acc: 0.7451 - val_loss: 1.6617 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 630us/step - loss: 0.4889 - acc: 0.7647 - val_loss: 1.6656 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.4828 - acc: 0.7647 - val_loss: 1.6435 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4745 - acc: 0.7647 - val_loss: 1.6408 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4670 - acc: 0.7647 - val_loss: 1.6334 - val_acc: 0.4000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4588 - acc: 0.8039 - val_loss: 1.6181 - val_acc: 0.4000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 338us/step - loss: 0.4523 - acc: 0.8039 - val_loss: 1.6167 - val_acc: 0.4000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 534us/step - loss: 0.4451 - acc: 0.8039 - val_loss: 1.5968 - val_acc: 0.4000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4406 - acc: 0.8039 - val_loss: 1.5919 - val_acc: 0.4000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 491us/step - loss: 0.4313 - acc: 0.8039 - val_loss: 1.5966 - val_acc: 0.4000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 664us/step - loss: 0.4263 - acc: 0.8235 - val_loss: 1.5837 - val_acc: 0.4000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 359us/step - loss: 0.4201 - acc: 0.8039 - val_loss: 1.5854 - val_acc: 0.4000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4145 - acc: 0.8039 - val_loss: 1.5868 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 560us/step - loss: 0.4072 - acc: 0.7843 - val_loss: 1.5774 - val_acc: 0.4000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4009 - acc: 0.7843 - val_loss: 1.5732 - val_acc: 0.4000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 472us/step - loss: 0.3964 - acc: 0.7843 - val_loss: 1.5514 - val_acc: 0.4000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 390us/step - loss: 0.3909 - acc: 0.8039 - val_loss: 1.5532 - val_acc: 0.4000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3857 - acc: 0.8039 - val_loss: 1.5538 - val_acc: 0.4000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 212us/step - loss: 0.3799 - acc: 0.8039 - val_loss: 1.5372 - val_acc: 0.4000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 426us/step - loss: 0.3728 - acc: 0.8039 - val_loss: 1.5384 - val_acc: 0.4000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 0.3680 - acc: 0.8039 - val_loss: 1.5349 - val_acc: 0.4000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3629 - acc: 0.8039 - val_loss: 1.5447 - val_acc: 0.4000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 413us/step - loss: 0.3576 - acc: 0.8039 - val_loss: 1.5318 - val_acc: 0.4000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 223us/step - loss: 0.3522 - acc: 0.8039 - val_loss: 1.5270 - val_acc: 0.4000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.3483 - acc: 0.8039 - val_loss: 1.5157 - val_acc: 0.4000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3427 - acc: 0.8039 - val_loss: 1.5227 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 239us/step - loss: 0.3393 - acc: 0.8039 - val_loss: 1.5034 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 591us/step - loss: 0.3341 - acc: 0.8235 - val_loss: 1.5055 - val_acc: 0.4000\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 368us/step - loss: 0.3316 - acc: 0.8039 - val_loss: 1.4947 - val_acc: 0.4000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.3266 - acc: 0.8039 - val_loss: 1.4977 - val_acc: 0.4000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3225 - acc: 0.8235 - val_loss: 1.4776 - val_acc: 0.4000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3178 - acc: 0.8235 - val_loss: 1.4837 - val_acc: 0.4000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 424us/step - loss: 0.3147 - acc: 0.8431 - val_loss: 1.4738 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 250us/step - loss: 0.3089 - acc: 0.8627 - val_loss: 1.4691 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 391us/step - loss: 0.3061 - acc: 0.8627 - val_loss: 1.4757 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3016 - acc: 0.8627 - val_loss: 1.4621 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 185us/step - loss: 0.2971 - acc: 0.8627 - val_loss: 1.4554 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2939 - acc: 0.8627 - val_loss: 1.4342 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 326us/step - loss: 0.2899 - acc: 0.8824 - val_loss: 1.4326 - val_acc: 0.5000\n",
      "2018-03-14\n",
      "2018-03-15\n",
      "2018-03-16\n",
      "2018-03-19\n",
      "2018-03-20\n",
      "2018-03-21\n",
      "2018-03-22\n",
      "2018-03-23\n",
      "2018-03-26\n",
      "2018-03-27\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 1.7450 - acc: 0.4706 - val_loss: 0.4843 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 1.6571 - acc: 0.4902 - val_loss: 0.4855 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.5926 - acc: 0.5098 - val_loss: 0.4878 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5420 - acc: 0.5098 - val_loss: 0.4899 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.4954 - acc: 0.5098 - val_loss: 0.4921 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.4519 - acc: 0.5294 - val_loss: 0.4940 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.4116 - acc: 0.5294 - val_loss: 0.4954 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3798 - acc: 0.5294 - val_loss: 0.4977 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.3449 - acc: 0.5294 - val_loss: 0.4996 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.3143 - acc: 0.5294 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 1.2845 - acc: 0.5294 - val_loss: 0.5035 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.2548 - acc: 0.5294 - val_loss: 0.5066 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 1.2223 - acc: 0.5490 - val_loss: 0.5080 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.1974 - acc: 0.5686 - val_loss: 0.5106 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 811us/step - loss: 1.1713 - acc: 0.5686 - val_loss: 0.5128 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1451 - acc: 0.5686 - val_loss: 0.5161 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1157 - acc: 0.5686 - val_loss: 0.5204 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 1.0873 - acc: 0.5686 - val_loss: 0.5236 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 1.0603 - acc: 0.5686 - val_loss: 0.5271 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 417us/step - loss: 1.0342 - acc: 0.5686 - val_loss: 0.5319 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 794us/step - loss: 1.0055 - acc: 0.5686 - val_loss: 0.5372 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9782 - acc: 0.5686 - val_loss: 0.5422 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9529 - acc: 0.5686 - val_loss: 0.5468 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.9306 - acc: 0.5686 - val_loss: 0.5511 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.9123 - acc: 0.5882 - val_loss: 0.5552 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.8920 - acc: 0.6078 - val_loss: 0.5615 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8715 - acc: 0.6078 - val_loss: 0.5674 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.8507 - acc: 0.6275 - val_loss: 0.5773 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 672us/step - loss: 0.8267 - acc: 0.6471 - val_loss: 0.5851 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.5459 - acc: 0.718 - 0s 265us/step - loss: 0.8062 - acc: 0.6667 - val_loss: 0.5946 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.7833 - acc: 0.6667 - val_loss: 0.6007 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 525us/step - loss: 0.7657 - acc: 0.6667 - val_loss: 0.6093 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7522 - acc: 0.6667 - val_loss: 0.6163 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 459us/step - loss: 0.7344 - acc: 0.6667 - val_loss: 0.6267 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 647us/step - loss: 0.7168 - acc: 0.6667 - val_loss: 0.6358 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 229us/step - loss: 0.7027 - acc: 0.6667 - val_loss: 0.6427 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6865 - acc: 0.6863 - val_loss: 0.6549 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 690us/step - loss: 0.6706 - acc: 0.6863 - val_loss: 0.6674 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.6557 - acc: 0.6863 - val_loss: 0.6817 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.6413 - acc: 0.6863 - val_loss: 0.6931 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 609us/step - loss: 0.6274 - acc: 0.6863 - val_loss: 0.6976 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.6149 - acc: 0.6863 - val_loss: 0.6998 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6043 - acc: 0.7059 - val_loss: 0.7026 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 261us/step - loss: 0.5942 - acc: 0.7059 - val_loss: 0.7052 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 290us/step - loss: 0.5824 - acc: 0.7059 - val_loss: 0.7087 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.5727 - acc: 0.7255 - val_loss: 0.7114 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 587us/step - loss: 0.5637 - acc: 0.7255 - val_loss: 0.7143 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5556 - acc: 0.7255 - val_loss: 0.7199 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.5437 - acc: 0.7255 - val_loss: 0.7233 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5354 - acc: 0.7451 - val_loss: 0.7259 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 394us/step - loss: 0.5279 - acc: 0.7451 - val_loss: 0.7273 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.5191 - acc: 0.7451 - val_loss: 0.7326 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.5094 - acc: 0.7451 - val_loss: 0.7360 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 720us/step - loss: 0.5024 - acc: 0.7647 - val_loss: 0.7370 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 533us/step - loss: 0.4949 - acc: 0.7647 - val_loss: 0.7389 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 331us/step - loss: 0.4878 - acc: 0.7647 - val_loss: 0.7428 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4827 - acc: 0.7647 - val_loss: 0.7474 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.4743 - acc: 0.7843 - val_loss: 0.7492 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 213us/step - loss: 0.4677 - acc: 0.7843 - val_loss: 0.7531 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.4603 - acc: 0.7843 - val_loss: 0.7560 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4536 - acc: 0.7843 - val_loss: 0.7574 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 539us/step - loss: 0.4496 - acc: 0.7843 - val_loss: 0.7597 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 427us/step - loss: 0.4420 - acc: 0.7843 - val_loss: 0.7616 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4357 - acc: 0.7843 - val_loss: 0.7666 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.4306 - acc: 0.7843 - val_loss: 0.7705 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 230us/step - loss: 0.4250 - acc: 0.7843 - val_loss: 0.7736 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 0.4173 - acc: 0.7843 - val_loss: 0.7779 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 462us/step - loss: 0.4137 - acc: 0.7843 - val_loss: 0.7823 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 341us/step - loss: 0.4087 - acc: 0.7647 - val_loss: 0.7867 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.4011 - acc: 0.7451 - val_loss: 0.7871 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 514us/step - loss: 0.3962 - acc: 0.7647 - val_loss: 0.7871 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3919 - acc: 0.7647 - val_loss: 0.7873 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3857 - acc: 0.7647 - val_loss: 0.7905 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3806 - acc: 0.8039 - val_loss: 0.7943 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 30us/step - loss: 0.3753 - acc: 0.8039 - val_loss: 0.7990 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 311us/step - loss: 0.3713 - acc: 0.7843 - val_loss: 0.7995 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 238us/step - loss: 0.3700 - acc: 0.8039 - val_loss: 0.8053 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 396us/step - loss: 0.3638 - acc: 0.7843 - val_loss: 0.8099 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 403us/step - loss: 0.3580 - acc: 0.7843 - val_loss: 0.8112 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 689us/step - loss: 0.3550 - acc: 0.7843 - val_loss: 0.8135 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3506 - acc: 0.7843 - val_loss: 0.8152 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3456 - acc: 0.7843 - val_loss: 0.8158 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 364us/step - loss: 0.3419 - acc: 0.7843 - val_loss: 0.8198 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3376 - acc: 0.7843 - val_loss: 0.8225 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 520us/step - loss: 0.3338 - acc: 0.7843 - val_loss: 0.8272 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 815us/step - loss: 0.3298 - acc: 0.7843 - val_loss: 0.8304 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 517us/step - loss: 0.3263 - acc: 0.7843 - val_loss: 0.8308 - val_acc: 0.5000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.3228 - acc: 0.7843 - val_loss: 0.8332 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3189 - acc: 0.8039 - val_loss: 0.8352 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 534us/step - loss: 0.3166 - acc: 0.8039 - val_loss: 0.8409 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3130 - acc: 0.8039 - val_loss: 0.8413 - val_acc: 0.5000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3087 - acc: 0.8431 - val_loss: 0.8446 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 718us/step - loss: 0.3056 - acc: 0.8431 - val_loss: 0.8486 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 626us/step - loss: 0.3019 - acc: 0.8431 - val_loss: 0.8503 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 237us/step - loss: 0.2981 - acc: 0.8431 - val_loss: 0.8540 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.2947 - acc: 0.8431 - val_loss: 0.8580 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 302us/step - loss: 0.2916 - acc: 0.8431 - val_loss: 0.8628 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 0.2877 - acc: 0.8431 - val_loss: 0.8657 - val_acc: 0.4000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 468us/step - loss: 0.2840 - acc: 0.8627 - val_loss: 0.8705 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2808 - acc: 0.8824 - val_loss: 0.8731 - val_acc: 0.5000\n",
      "2018-03-28\n",
      "2018-03-29\n",
      "2018-03-30\n",
      "2018-04-02\n",
      "2018-04-03\n",
      "2018-04-04\n",
      "2018-04-09\n",
      "2018-04-10\n",
      "2018-04-11\n",
      "2018-04-12\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.6641 - acc: 0.4118 - val_loss: 0.2769 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5680 - acc: 0.4902 - val_loss: 0.2740 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 548us/step - loss: 1.5029 - acc: 0.4902 - val_loss: 0.2703 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 1.4564 - acc: 0.4902 - val_loss: 0.2674 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 381us/step - loss: 1.4137 - acc: 0.4902 - val_loss: 0.2650 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.3778 - acc: 0.4902 - val_loss: 0.2631 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3414 - acc: 0.5098 - val_loss: 0.2611 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.3089 - acc: 0.5098 - val_loss: 0.2586 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 746us/step - loss: 1.2781 - acc: 0.5098 - val_loss: 0.2565 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.2494 - acc: 0.5098 - val_loss: 0.2546 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 413us/step - loss: 1.2224 - acc: 0.5098 - val_loss: 0.2534 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1960 - acc: 0.5098 - val_loss: 0.2524 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1691 - acc: 0.5098 - val_loss: 0.2506 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 802us/step - loss: 1.1446 - acc: 0.5294 - val_loss: 0.2489 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 509us/step - loss: 1.1159 - acc: 0.5294 - val_loss: 0.2476 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 1.0921 - acc: 0.5294 - val_loss: 0.2468 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.0731 - acc: 0.5294 - val_loss: 0.2470 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 320us/step - loss: 1.0525 - acc: 0.5294 - val_loss: 0.2459 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 1.0304 - acc: 0.5294 - val_loss: 0.2455 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 281us/step - loss: 1.0110 - acc: 0.5490 - val_loss: 0.2452 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9904 - acc: 0.5686 - val_loss: 0.2439 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9707 - acc: 0.5686 - val_loss: 0.2426 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.9484 - acc: 0.5686 - val_loss: 0.2422 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9284 - acc: 0.5882 - val_loss: 0.2417 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 0.9100 - acc: 0.6078 - val_loss: 0.2415 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 441us/step - loss: 0.8932 - acc: 0.6078 - val_loss: 0.2411 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8757 - acc: 0.6275 - val_loss: 0.2409 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 876us/step - loss: 0.8599 - acc: 0.6667 - val_loss: 0.2406 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.8446 - acc: 0.6667 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 420us/step - loss: 0.8296 - acc: 0.6667 - val_loss: 0.2398 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 371us/step - loss: 0.8133 - acc: 0.6863 - val_loss: 0.2395 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 725us/step - loss: 0.7986 - acc: 0.6863 - val_loss: 0.2393 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.7852 - acc: 0.6863 - val_loss: 0.2394 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.7703 - acc: 0.6863 - val_loss: 0.2401 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7561 - acc: 0.6863 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7436 - acc: 0.6863 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7316 - acc: 0.6863 - val_loss: 0.2407 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7201 - acc: 0.6863 - val_loss: 0.2415 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7104 - acc: 0.6863 - val_loss: 0.2418 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 452us/step - loss: 0.6979 - acc: 0.6863 - val_loss: 0.2426 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 438us/step - loss: 0.6867 - acc: 0.6863 - val_loss: 0.2431 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.6763 - acc: 0.6863 - val_loss: 0.2433 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 378us/step - loss: 0.6661 - acc: 0.6863 - val_loss: 0.2438 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 497us/step - loss: 0.6547 - acc: 0.7059 - val_loss: 0.2442 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 435us/step - loss: 0.6463 - acc: 0.7059 - val_loss: 0.2450 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.6367 - acc: 0.7059 - val_loss: 0.2458 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 310us/step - loss: 0.6270 - acc: 0.7059 - val_loss: 0.2464 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 59us/step - loss: 0.6164 - acc: 0.7255 - val_loss: 0.2473 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.6064 - acc: 0.7255 - val_loss: 0.2479 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5984 - acc: 0.7451 - val_loss: 0.2491 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5903 - acc: 0.7451 - val_loss: 0.2500 - val_acc: 0.9000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5818 - acc: 0.7647 - val_loss: 0.2504 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 239us/step - loss: 0.5739 - acc: 0.7647 - val_loss: 0.2502 - val_acc: 0.9000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5658 - acc: 0.7647 - val_loss: 0.2506 - val_acc: 0.9000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5596 - acc: 0.7647 - val_loss: 0.2511 - val_acc: 0.9000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 611us/step - loss: 0.5519 - acc: 0.7647 - val_loss: 0.2518 - val_acc: 0.9000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5452 - acc: 0.7647 - val_loss: 0.2520 - val_acc: 0.9000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5367 - acc: 0.7843 - val_loss: 0.2525 - val_acc: 0.9000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 250us/step - loss: 0.5302 - acc: 0.8039 - val_loss: 0.2532 - val_acc: 0.9000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5236 - acc: 0.8039 - val_loss: 0.2540 - val_acc: 0.9000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5173 - acc: 0.8039 - val_loss: 0.2541 - val_acc: 0.9000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5109 - acc: 0.8235 - val_loss: 0.2551 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5037 - acc: 0.8235 - val_loss: 0.2555 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4972 - acc: 0.8235 - val_loss: 0.2558 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4911 - acc: 0.8235 - val_loss: 0.2559 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 517us/step - loss: 0.4848 - acc: 0.8235 - val_loss: 0.2563 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4791 - acc: 0.8235 - val_loss: 0.2570 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4725 - acc: 0.8235 - val_loss: 0.2566 - val_acc: 0.9000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4659 - acc: 0.8235 - val_loss: 0.2569 - val_acc: 0.9000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 266us/step - loss: 0.4603 - acc: 0.8235 - val_loss: 0.2567 - val_acc: 0.9000\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 623us/step - loss: 0.4557 - acc: 0.8235 - val_loss: 0.2573 - val_acc: 0.9000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 637us/step - loss: 0.4492 - acc: 0.8235 - val_loss: 0.2573 - val_acc: 0.9000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4453 - acc: 0.8235 - val_loss: 0.2576 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.4404 - acc: 0.8235 - val_loss: 0.2577 - val_acc: 0.9000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 552us/step - loss: 0.4356 - acc: 0.8235 - val_loss: 0.2580 - val_acc: 0.9000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.4303 - acc: 0.8235 - val_loss: 0.2586 - val_acc: 0.9000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4252 - acc: 0.8235 - val_loss: 0.2596 - val_acc: 0.9000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.4202 - acc: 0.8235 - val_loss: 0.2602 - val_acc: 0.9000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4149 - acc: 0.8235 - val_loss: 0.2607 - val_acc: 0.9000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 458us/step - loss: 0.4106 - acc: 0.8235 - val_loss: 0.2612 - val_acc: 0.9000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 415us/step - loss: 0.4052 - acc: 0.8039 - val_loss: 0.2619 - val_acc: 0.9000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3995 - acc: 0.8039 - val_loss: 0.2631 - val_acc: 0.9000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3964 - acc: 0.8039 - val_loss: 0.2633 - val_acc: 0.9000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.3925 - acc: 0.8039 - val_loss: 0.2634 - val_acc: 0.9000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 713us/step - loss: 0.3893 - acc: 0.8039 - val_loss: 0.2642 - val_acc: 0.9000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3851 - acc: 0.8039 - val_loss: 0.2645 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 445us/step - loss: 0.3817 - acc: 0.8039 - val_loss: 0.2650 - val_acc: 0.9000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.3793 - acc: 0.8039 - val_loss: 0.2651 - val_acc: 0.9000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 414us/step - loss: 0.3746 - acc: 0.8039 - val_loss: 0.2653 - val_acc: 0.9000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 218us/step - loss: 0.3719 - acc: 0.8039 - val_loss: 0.2650 - val_acc: 0.9000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 426us/step - loss: 0.3687 - acc: 0.8039 - val_loss: 0.2656 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3663 - acc: 0.8039 - val_loss: 0.2669 - val_acc: 0.9000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 287us/step - loss: 0.3633 - acc: 0.8039 - val_loss: 0.2678 - val_acc: 0.9000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3607 - acc: 0.8039 - val_loss: 0.2679 - val_acc: 0.9000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.3568 - acc: 0.8039 - val_loss: 0.2687 - val_acc: 0.9000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 404us/step - loss: 0.3522 - acc: 0.8039 - val_loss: 0.2691 - val_acc: 0.9000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 748us/step - loss: 0.3484 - acc: 0.8039 - val_loss: 0.2692 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3444 - acc: 0.8039 - val_loss: 0.2694 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.3412 - acc: 0.8039 - val_loss: 0.2697 - val_acc: 0.9000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 493us/step - loss: 0.3390 - acc: 0.8235 - val_loss: 0.2704 - val_acc: 0.9000\n",
      "2018-04-13\n",
      "2018-04-16\n",
      "2018-04-17\n",
      "2018-04-18\n",
      "2018-04-19\n",
      "2018-04-20\n",
      "2018-04-23\n",
      "2018-04-24\n",
      "2018-04-25\n",
      "2018-04-26\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.8820 - acc: 0.6863 - val_loss: 1.2433 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.8485 - acc: 0.7059 - val_loss: 1.2004 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 321us/step - loss: 0.8223 - acc: 0.7059 - val_loss: 1.1570 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 324us/step - loss: 0.8018 - acc: 0.7451 - val_loss: 1.1099 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 527us/step - loss: 0.7847 - acc: 0.7843 - val_loss: 1.0657 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7715 - acc: 0.8235 - val_loss: 1.0405 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7586 - acc: 0.8431 - val_loss: 1.0042 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 330us/step - loss: 0.7472 - acc: 0.8431 - val_loss: 0.9795 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7377 - acc: 0.8431 - val_loss: 0.9450 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 223us/step - loss: 0.7260 - acc: 0.8431 - val_loss: 0.9154 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 422us/step - loss: 0.7174 - acc: 0.8431 - val_loss: 0.8940 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.7074 - acc: 0.8431 - val_loss: 0.8655 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 399us/step - loss: 0.6965 - acc: 0.8431 - val_loss: 0.8355 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 342us/step - loss: 0.6879 - acc: 0.8431 - val_loss: 0.8071 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6779 - acc: 0.8431 - val_loss: 0.7790 - val_acc: 0.6000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6650 - acc: 0.8431 - val_loss: 0.7609 - val_acc: 0.6000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.6590 - acc: 0.8431 - val_loss: 0.7402 - val_acc: 0.6000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6470 - acc: 0.8431 - val_loss: 0.7253 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6389 - acc: 0.8431 - val_loss: 0.7081 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6306 - acc: 0.8431 - val_loss: 0.6977 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.6218 - acc: 0.8431 - val_loss: 0.6862 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6138 - acc: 0.8431 - val_loss: 0.6732 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.6043 - acc: 0.8627 - val_loss: 0.6618 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 374us/step - loss: 0.5953 - acc: 0.8627 - val_loss: 0.6518 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 218us/step - loss: 0.5864 - acc: 0.8627 - val_loss: 0.6441 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5781 - acc: 0.8627 - val_loss: 0.6361 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.5692 - acc: 0.8627 - val_loss: 0.6311 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5617 - acc: 0.8627 - val_loss: 0.6261 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 402us/step - loss: 0.5532 - acc: 0.8627 - val_loss: 0.6218 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5467 - acc: 0.8627 - val_loss: 0.6181 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 367us/step - loss: 0.5369 - acc: 0.8627 - val_loss: 0.6163 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5294 - acc: 0.8627 - val_loss: 0.6156 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.5235 - acc: 0.8627 - val_loss: 0.6148 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 523us/step - loss: 0.5165 - acc: 0.8627 - val_loss: 0.6149 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.5090 - acc: 0.8627 - val_loss: 0.6147 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.5025 - acc: 0.8627 - val_loss: 0.6154 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4942 - acc: 0.8627 - val_loss: 0.6154 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 575us/step - loss: 0.4861 - acc: 0.8627 - val_loss: 0.6165 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4789 - acc: 0.8627 - val_loss: 0.6178 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4726 - acc: 0.8627 - val_loss: 0.6198 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 586us/step - loss: 0.4663 - acc: 0.8627 - val_loss: 0.6206 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.4600 - acc: 0.8627 - val_loss: 0.6231 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 599us/step - loss: 0.4538 - acc: 0.8627 - val_loss: 0.6248 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 139us/step - loss: 0.4478 - acc: 0.8627 - val_loss: 0.6267 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 606us/step - loss: 0.4407 - acc: 0.8627 - val_loss: 0.6283 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.4342 - acc: 0.8824 - val_loss: 0.6306 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 581us/step - loss: 0.4287 - acc: 0.8824 - val_loss: 0.6312 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 213us/step - loss: 0.4229 - acc: 0.8824 - val_loss: 0.6341 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4185 - acc: 0.8824 - val_loss: 0.6352 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 481us/step - loss: 0.4160 - acc: 0.8824 - val_loss: 0.6385 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4088 - acc: 0.8824 - val_loss: 0.6412 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 797us/step - loss: 0.4060 - acc: 0.8824 - val_loss: 0.6446 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.4037 - acc: 0.8824 - val_loss: 0.6479 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 163us/step - loss: 0.4002 - acc: 0.8824 - val_loss: 0.6510 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 810us/step - loss: 0.3979 - acc: 0.8824 - val_loss: 0.6541 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.3952 - acc: 0.8824 - val_loss: 0.6581 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 902us/step - loss: 0.3916 - acc: 0.8824 - val_loss: 0.6606 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.3877 - acc: 0.8824 - val_loss: 0.6643 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3844 - acc: 0.8824 - val_loss: 0.6676 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3806 - acc: 0.8824 - val_loss: 0.6714 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3776 - acc: 0.8824 - val_loss: 0.6757 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3735 - acc: 0.8824 - val_loss: 0.6829 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3704 - acc: 0.8824 - val_loss: 0.6871 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3681 - acc: 0.9020 - val_loss: 0.6920 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3647 - acc: 0.9020 - val_loss: 0.6997 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3609 - acc: 0.8824 - val_loss: 0.7013 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.3579 - acc: 0.8824 - val_loss: 0.7066 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3552 - acc: 0.8824 - val_loss: 0.7118 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3525 - acc: 0.8824 - val_loss: 0.7179 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3491 - acc: 0.8824 - val_loss: 0.7213 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3458 - acc: 0.8824 - val_loss: 0.7275 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3433 - acc: 0.8824 - val_loss: 0.7312 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3405 - acc: 0.8824 - val_loss: 0.7368 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 450us/step - loss: 0.3384 - acc: 0.8824 - val_loss: 0.7383 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 494us/step - loss: 0.3356 - acc: 0.8824 - val_loss: 0.7429 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 256us/step - loss: 0.3330 - acc: 0.8824 - val_loss: 0.7491 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3301 - acc: 0.8824 - val_loss: 0.7537 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3277 - acc: 0.8824 - val_loss: 0.7565 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3261 - acc: 0.8824 - val_loss: 0.7647 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3230 - acc: 0.8824 - val_loss: 0.7682 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3213 - acc: 0.8824 - val_loss: 0.7724 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.3186 - acc: 0.8824 - val_loss: 0.7772 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3167 - acc: 0.8824 - val_loss: 0.7826 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3148 - acc: 0.8824 - val_loss: 0.7863 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 324us/step - loss: 0.3128 - acc: 0.8824 - val_loss: 0.7948 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3105 - acc: 0.8824 - val_loss: 0.7995 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3081 - acc: 0.8824 - val_loss: 0.8045 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 547us/step - loss: 0.3066 - acc: 0.8824 - val_loss: 0.8124 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 506us/step - loss: 0.3042 - acc: 0.8824 - val_loss: 0.8188 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3023 - acc: 0.8824 - val_loss: 0.8225 - val_acc: 0.6000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.3001 - acc: 0.8824 - val_loss: 0.8279 - val_acc: 0.6000\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 275us/step - loss: 0.2990 - acc: 0.8824 - val_loss: 0.8322 - val_acc: 0.6000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.2974 - acc: 0.8824 - val_loss: 0.8407 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 485us/step - loss: 0.2945 - acc: 0.8824 - val_loss: 0.8448 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.2933 - acc: 0.8824 - val_loss: 0.8555 - val_acc: 0.6000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.2908 - acc: 0.8824 - val_loss: 0.8635 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.2898 - acc: 0.8824 - val_loss: 0.8719 - val_acc: 0.6000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2866 - acc: 0.8824 - val_loss: 0.8778 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 108us/step - loss: 0.2844 - acc: 0.8824 - val_loss: 0.8857 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.2834 - acc: 0.8824 - val_loss: 0.8883 - val_acc: 0.6000\n",
      "2018-04-27\n",
      "2018-05-02\n",
      "2018-05-03\n",
      "2018-05-04\n",
      "2018-05-07\n",
      "2018-05-08\n",
      "2018-05-09\n",
      "2018-05-10\n",
      "2018-05-11\n",
      "2018-05-14\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.6976 - acc: 0.8431 - val_loss: 2.0165 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6608 - acc: 0.8431 - val_loss: 2.0941 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.6351 - acc: 0.8431 - val_loss: 2.1674 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.6185 - acc: 0.8431 - val_loss: 2.2164 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6032 - acc: 0.8431 - val_loss: 2.2701 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5886 - acc: 0.8431 - val_loss: 2.3336 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5734 - acc: 0.8431 - val_loss: 2.3757 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 457us/step - loss: 0.5607 - acc: 0.8431 - val_loss: 2.4122 - val_acc: 0.2000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.5449 - acc: 0.8431 - val_loss: 2.4621 - val_acc: 0.2000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.5339 - acc: 0.8431 - val_loss: 2.5003 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5222 - acc: 0.8431 - val_loss: 2.5418 - val_acc: 0.2000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.5110 - acc: 0.8431 - val_loss: 2.5902 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 175us/step - loss: 0.4993 - acc: 0.8431 - val_loss: 2.6333 - val_acc: 0.2000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 245us/step - loss: 0.4883 - acc: 0.8431 - val_loss: 2.6770 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 79us/step - loss: 0.4800 - acc: 0.8431 - val_loss: 2.7176 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.4689 - acc: 0.8431 - val_loss: 2.7506 - val_acc: 0.2000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 239us/step - loss: 0.4606 - acc: 0.8235 - val_loss: 2.7941 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.4533 - acc: 0.8235 - val_loss: 2.8329 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 181us/step - loss: 0.4462 - acc: 0.8235 - val_loss: 2.8729 - val_acc: 0.2000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4405 - acc: 0.8235 - val_loss: 2.9084 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4354 - acc: 0.8235 - val_loss: 2.9356 - val_acc: 0.2000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 363us/step - loss: 0.4284 - acc: 0.8235 - val_loss: 2.9770 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4227 - acc: 0.8235 - val_loss: 3.0105 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4145 - acc: 0.8431 - val_loss: 3.0433 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4083 - acc: 0.8431 - val_loss: 3.0800 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 279us/step - loss: 0.4018 - acc: 0.8431 - val_loss: 3.1177 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3965 - acc: 0.8431 - val_loss: 3.1620 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 325us/step - loss: 0.3930 - acc: 0.8431 - val_loss: 3.2059 - val_acc: 0.2000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3872 - acc: 0.8431 - val_loss: 3.2333 - val_acc: 0.2000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3825 - acc: 0.8431 - val_loss: 3.2605 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 559us/step - loss: 0.3782 - acc: 0.8431 - val_loss: 3.2920 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3731 - acc: 0.8431 - val_loss: 3.3124 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 486us/step - loss: 0.3687 - acc: 0.8431 - val_loss: 3.3401 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.3638 - acc: 0.8431 - val_loss: 3.3611 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.3607 - acc: 0.8431 - val_loss: 3.3959 - val_acc: 0.2000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 449us/step - loss: 0.3550 - acc: 0.8431 - val_loss: 3.4193 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3508 - acc: 0.8431 - val_loss: 3.4417 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3466 - acc: 0.8431 - val_loss: 3.4737 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 415us/step - loss: 0.3431 - acc: 0.8431 - val_loss: 3.4906 - val_acc: 0.2000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.3386 - acc: 0.8431 - val_loss: 3.5258 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 402us/step - loss: 0.3388 - acc: 0.8431 - val_loss: 3.5618 - val_acc: 0.2000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3338 - acc: 0.8431 - val_loss: 3.6004 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 455us/step - loss: 0.3287 - acc: 0.8431 - val_loss: 3.6234 - val_acc: 0.2000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 414us/step - loss: 0.3257 - acc: 0.8431 - val_loss: 3.6458 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 349us/step - loss: 0.3227 - acc: 0.8431 - val_loss: 3.6688 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.3190 - acc: 0.8431 - val_loss: 3.6993 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 459us/step - loss: 0.3185 - acc: 0.8431 - val_loss: 3.7299 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3144 - acc: 0.8431 - val_loss: 3.7322 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3075 - acc: 0.8431 - val_loss: 3.7388 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3045 - acc: 0.8431 - val_loss: 3.7587 - val_acc: 0.2000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3036 - acc: 0.8431 - val_loss: 3.7851 - val_acc: 0.2000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 616us/step - loss: 0.3003 - acc: 0.8431 - val_loss: 3.7856 - val_acc: 0.2000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.2982 - acc: 0.8431 - val_loss: 3.8089 - val_acc: 0.2000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.2947 - acc: 0.8431 - val_loss: 3.8177 - val_acc: 0.2000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.2929 - acc: 0.8431 - val_loss: 3.8410 - val_acc: 0.2000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 791us/step - loss: 0.2899 - acc: 0.8431 - val_loss: 3.8690 - val_acc: 0.2000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 543us/step - loss: 0.2872 - acc: 0.8431 - val_loss: 3.8840 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 476us/step - loss: 0.2852 - acc: 0.8431 - val_loss: 3.9015 - val_acc: 0.2000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 445us/step - loss: 0.2831 - acc: 0.8431 - val_loss: 3.9100 - val_acc: 0.2000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2802 - acc: 0.8431 - val_loss: 3.9161 - val_acc: 0.2000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 147us/step - loss: 0.2784 - acc: 0.8431 - val_loss: 3.9424 - val_acc: 0.2000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.2773 - acc: 0.8431 - val_loss: 3.9698 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 472us/step - loss: 0.2741 - acc: 0.8431 - val_loss: 3.9962 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.2719 - acc: 0.8431 - val_loss: 3.9966 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 783us/step - loss: 0.2695 - acc: 0.8431 - val_loss: 3.9992 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2677 - acc: 0.8431 - val_loss: 4.0230 - val_acc: 0.2000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 466us/step - loss: 0.2650 - acc: 0.8431 - val_loss: 4.0373 - val_acc: 0.2000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 344us/step - loss: 0.2636 - acc: 0.8431 - val_loss: 4.0496 - val_acc: 0.2000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2620 - acc: 0.8431 - val_loss: 4.0520 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 430us/step - loss: 0.2594 - acc: 0.8431 - val_loss: 4.0668 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 573us/step - loss: 0.2602 - acc: 0.8431 - val_loss: 4.0980 - val_acc: 0.2000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 403us/step - loss: 0.2560 - acc: 0.8431 - val_loss: 4.1087 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.2560 - acc: 0.8431 - val_loss: 4.1174 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 261us/step - loss: 0.2529 - acc: 0.8627 - val_loss: 4.1478 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 520us/step - loss: 0.2516 - acc: 0.8431 - val_loss: 4.1745 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 541us/step - loss: 0.2494 - acc: 0.8431 - val_loss: 4.1902 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2478 - acc: 0.8431 - val_loss: 4.2047 - val_acc: 0.2000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2468 - acc: 0.8431 - val_loss: 4.2121 - val_acc: 0.2000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2438 - acc: 0.8627 - val_loss: 4.2227 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2413 - acc: 0.8627 - val_loss: 4.2552 - val_acc: 0.2000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 49us/step - loss: 0.2398 - acc: 0.8627 - val_loss: 4.2779 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2374 - acc: 0.8431 - val_loss: 4.3073 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 495us/step - loss: 0.2360 - acc: 0.8627 - val_loss: 4.3384 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 501us/step - loss: 0.2348 - acc: 0.8627 - val_loss: 4.3554 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 269us/step - loss: 0.2338 - acc: 0.8431 - val_loss: 4.3922 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 475us/step - loss: 0.2329 - acc: 0.8431 - val_loss: 4.4327 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.2312 - acc: 0.8431 - val_loss: 4.4701 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.2307 - acc: 0.8431 - val_loss: 4.5033 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.2291 - acc: 0.8431 - val_loss: 4.5308 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.2284 - acc: 0.8431 - val_loss: 4.5358 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 519us/step - loss: 0.2284 - acc: 0.8431 - val_loss: 4.5825 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.2266 - acc: 0.8431 - val_loss: 4.6044 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2249 - acc: 0.8431 - val_loss: 4.6368 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 841us/step - loss: 0.2247 - acc: 0.8431 - val_loss: 4.6272 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 565us/step - loss: 0.2232 - acc: 0.8627 - val_loss: 4.6648 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 309us/step - loss: 0.2223 - acc: 0.8431 - val_loss: 4.6906 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 184us/step - loss: 0.2220 - acc: 0.8431 - val_loss: 4.7034 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2228 - acc: 0.8431 - val_loss: 4.7352 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 389us/step - loss: 0.2215 - acc: 0.8824 - val_loss: 4.7558 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 454us/step - loss: 0.2200 - acc: 0.8627 - val_loss: 4.7763 - val_acc: 0.2000\n",
      "2018-05-15\n",
      "2018-05-16\n",
      "2018-05-17\n",
      "2018-05-18\n",
      "2018-05-21\n",
      "2018-05-22\n",
      "2018-05-23\n",
      "2018-05-24\n",
      "2018-05-25\n",
      "2018-05-28\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 1.7697 - acc: 0.5490 - val_loss: 1.0011 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 1.6662 - acc: 0.5882 - val_loss: 0.9815 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.6119 - acc: 0.6078 - val_loss: 0.9710 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.5429 - acc: 0.6078 - val_loss: 0.9561 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.4730 - acc: 0.6078 - val_loss: 0.9451 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 252us/step - loss: 1.4237 - acc: 0.6078 - val_loss: 0.9341 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.3931 - acc: 0.6275 - val_loss: 0.9226 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 1.3559 - acc: 0.6275 - val_loss: 0.9121 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.3224 - acc: 0.6275 - val_loss: 0.9065 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.2967 - acc: 0.6275 - val_loss: 0.8996 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.2680 - acc: 0.6471 - val_loss: 0.8946 - val_acc: 0.7000\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 0us/step - loss: 1.2472 - acc: 0.6471 - val_loss: 0.8901 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.2286 - acc: 0.6471 - val_loss: 0.8837 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.2080 - acc: 0.6667 - val_loss: 0.8784 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1877 - acc: 0.6667 - val_loss: 0.8693 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 1.1692 - acc: 0.6667 - val_loss: 0.8614 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 220us/step - loss: 1.1509 - acc: 0.6863 - val_loss: 0.8586 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.1361 - acc: 0.6863 - val_loss: 0.8563 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 1.1205 - acc: 0.7059 - val_loss: 0.8490 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1023 - acc: 0.7059 - val_loss: 0.8423 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.0863 - acc: 0.7059 - val_loss: 0.8361 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 1.0686 - acc: 0.7059 - val_loss: 0.8307 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 1.0510 - acc: 0.7059 - val_loss: 0.8242 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.0371 - acc: 0.7059 - val_loss: 0.8199 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 1.0232 - acc: 0.7059 - val_loss: 0.8116 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 1.0072 - acc: 0.7059 - val_loss: 0.8069 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9968 - acc: 0.7059 - val_loss: 0.8002 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.9842 - acc: 0.7255 - val_loss: 0.7956 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.9697 - acc: 0.7255 - val_loss: 0.7903 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9617 - acc: 0.7255 - val_loss: 0.7866 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 347us/step - loss: 0.9506 - acc: 0.7255 - val_loss: 0.7803 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9403 - acc: 0.7059 - val_loss: 0.7738 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 961us/step - loss: 0.9305 - acc: 0.7059 - val_loss: 0.7704 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.9212 - acc: 0.7255 - val_loss: 0.7678 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.9122 - acc: 0.7255 - val_loss: 0.7616 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9043 - acc: 0.7255 - val_loss: 0.7601 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8947 - acc: 0.7451 - val_loss: 0.7589 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8876 - acc: 0.7451 - val_loss: 0.7550 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 239us/step - loss: 0.8791 - acc: 0.7647 - val_loss: 0.7530 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8732 - acc: 0.7451 - val_loss: 0.7477 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.8662 - acc: 0.7451 - val_loss: 0.7427 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8589 - acc: 0.7451 - val_loss: 0.7407 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8485 - acc: 0.7647 - val_loss: 0.7323 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8367 - acc: 0.7843 - val_loss: 0.7283 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8289 - acc: 0.7843 - val_loss: 0.7207 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.8158 - acc: 0.8039 - val_loss: 0.7137 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8048 - acc: 0.8039 - val_loss: 0.7091 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7987 - acc: 0.8039 - val_loss: 0.7064 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7931 - acc: 0.8039 - val_loss: 0.6996 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7835 - acc: 0.8235 - val_loss: 0.6947 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7756 - acc: 0.8235 - val_loss: 0.6932 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 137us/step - loss: 0.7689 - acc: 0.8431 - val_loss: 0.6902 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.7623 - acc: 0.8235 - val_loss: 0.6869 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.7552 - acc: 0.8431 - val_loss: 0.6865 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 361us/step - loss: 0.7487 - acc: 0.8235 - val_loss: 0.6857 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.7423 - acc: 0.8431 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 242us/step - loss: 0.7365 - acc: 0.8431 - val_loss: 0.6792 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7273 - acc: 0.8431 - val_loss: 0.6777 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.7213 - acc: 0.8431 - val_loss: 0.6754 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.7130 - acc: 0.8235 - val_loss: 0.6753 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.7073 - acc: 0.8431 - val_loss: 0.6736 - val_acc: 0.7000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7055 - acc: 0.8627 - val_loss: 0.6756 - val_acc: 0.7000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.6971 - acc: 0.8431 - val_loss: 0.6779 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6911 - acc: 0.8431 - val_loss: 0.6776 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6862 - acc: 0.8431 - val_loss: 0.6792 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.6811 - acc: 0.8431 - val_loss: 0.6784 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6758 - acc: 0.8431 - val_loss: 0.6777 - val_acc: 0.7000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 170us/step - loss: 0.6698 - acc: 0.8431 - val_loss: 0.6751 - val_acc: 0.7000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 194us/step - loss: 0.6612 - acc: 0.8431 - val_loss: 0.6736 - val_acc: 0.7000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6543 - acc: 0.8627 - val_loss: 0.6739 - val_acc: 0.7000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.6498 - acc: 0.8431 - val_loss: 0.6743 - val_acc: 0.7000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.6417 - acc: 0.8431 - val_loss: 0.6743 - val_acc: 0.7000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.6367 - acc: 0.8431 - val_loss: 0.6748 - val_acc: 0.7000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6335 - acc: 0.8431 - val_loss: 0.6742 - val_acc: 0.7000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6299 - acc: 0.8431 - val_loss: 0.6737 - val_acc: 0.7000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.6230 - acc: 0.8431 - val_loss: 0.6731 - val_acc: 0.7000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6160 - acc: 0.8627 - val_loss: 0.6754 - val_acc: 0.7000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6106 - acc: 0.8431 - val_loss: 0.6767 - val_acc: 0.7000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6061 - acc: 0.8431 - val_loss: 0.6772 - val_acc: 0.7000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6019 - acc: 0.8431 - val_loss: 0.6770 - val_acc: 0.7000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6009 - acc: 0.8431 - val_loss: 0.6762 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5947 - acc: 0.8627 - val_loss: 0.6770 - val_acc: 0.7000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.5907 - acc: 0.8627 - val_loss: 0.6779 - val_acc: 0.7000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5875 - acc: 0.8431 - val_loss: 0.6784 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5833 - acc: 0.8627 - val_loss: 0.6790 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5802 - acc: 0.8627 - val_loss: 0.6795 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 172us/step - loss: 0.5759 - acc: 0.8627 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5721 - acc: 0.8627 - val_loss: 0.6795 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5679 - acc: 0.8627 - val_loss: 0.6795 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 128us/step - loss: 0.5658 - acc: 0.8431 - val_loss: 0.6806 - val_acc: 0.7000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5592 - acc: 0.8627 - val_loss: 0.6801 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.5533 - acc: 0.8627 - val_loss: 0.6807 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.5478 - acc: 0.8627 - val_loss: 0.6824 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.5437 - acc: 0.8627 - val_loss: 0.6830 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5394 - acc: 0.8627 - val_loss: 0.6834 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 305us/step - loss: 0.5352 - acc: 0.8627 - val_loss: 0.6833 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5302 - acc: 0.8627 - val_loss: 0.6830 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5264 - acc: 0.8627 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.5222 - acc: 0.8627 - val_loss: 0.6825 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5183 - acc: 0.8627 - val_loss: 0.6818 - val_acc: 0.7000\n",
      "2018-05-29\n",
      "2018-05-30\n",
      "2018-05-31\n",
      "2018-06-01\n",
      "2018-06-04\n",
      "2018-06-05\n",
      "2018-06-06\n",
      "2018-06-07\n",
      "2018-06-08\n",
      "2018-06-11\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.8584 - acc: 0.7647 - val_loss: 0.6487 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 379us/step - loss: 0.8298 - acc: 0.7647 - val_loss: 0.6401 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8089 - acc: 0.7647 - val_loss: 0.6365 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7967 - acc: 0.7647 - val_loss: 0.6310 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 560us/step - loss: 0.7868 - acc: 0.7647 - val_loss: 0.6253 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 267us/step - loss: 0.7733 - acc: 0.7647 - val_loss: 0.6210 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7651 - acc: 0.7647 - val_loss: 0.6154 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7564 - acc: 0.7647 - val_loss: 0.6115 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 371us/step - loss: 0.7477 - acc: 0.7647 - val_loss: 0.6090 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.7378 - acc: 0.7647 - val_loss: 0.6069 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 298us/step - loss: 0.7299 - acc: 0.7647 - val_loss: 0.6050 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.7220 - acc: 0.7647 - val_loss: 0.6022 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 639us/step - loss: 0.7155 - acc: 0.7647 - val_loss: 0.6014 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 321us/step - loss: 0.7052 - acc: 0.7843 - val_loss: 0.5990 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.6967 - acc: 0.7843 - val_loss: 0.5970 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.6908 - acc: 0.7843 - val_loss: 0.5951 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 358us/step - loss: 0.6783 - acc: 0.7843 - val_loss: 0.5922 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.6680 - acc: 0.7843 - val_loss: 0.5889 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6609 - acc: 0.7843 - val_loss: 0.5832 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.6528 - acc: 0.8039 - val_loss: 0.5809 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 517us/step - loss: 0.6450 - acc: 0.7843 - val_loss: 0.5769 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.6369 - acc: 0.8039 - val_loss: 0.5748 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.6289 - acc: 0.8039 - val_loss: 0.5745 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.6232 - acc: 0.8039 - val_loss: 0.5728 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 0.6122 - acc: 0.8039 - val_loss: 0.5698 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 0.6057 - acc: 0.8235 - val_loss: 0.5666 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 231us/step - loss: 0.5983 - acc: 0.8235 - val_loss: 0.5613 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.5913 - acc: 0.8235 - val_loss: 0.5568 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 464us/step - loss: 0.5842 - acc: 0.8235 - val_loss: 0.5540 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 492us/step - loss: 0.5770 - acc: 0.8235 - val_loss: 0.5510 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 473us/step - loss: 0.5700 - acc: 0.8235 - val_loss: 0.5484 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 202us/step - loss: 0.5630 - acc: 0.8235 - val_loss: 0.5451 - val_acc: 0.7000\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 166us/step - loss: 0.5560 - acc: 0.8431 - val_loss: 0.5446 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.5493 - acc: 0.8235 - val_loss: 0.5408 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.5420 - acc: 0.8431 - val_loss: 0.5378 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5334 - acc: 0.8627 - val_loss: 0.5365 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5289 - acc: 0.8627 - val_loss: 0.5329 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5221 - acc: 0.8627 - val_loss: 0.5318 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5141 - acc: 0.8627 - val_loss: 0.5285 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 364us/step - loss: 0.5081 - acc: 0.8627 - val_loss: 0.5279 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5023 - acc: 0.8627 - val_loss: 0.5266 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.4955 - acc: 0.8627 - val_loss: 0.5254 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 296us/step - loss: 0.4903 - acc: 0.8627 - val_loss: 0.5236 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4871 - acc: 0.8627 - val_loss: 0.5222 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4783 - acc: 0.8627 - val_loss: 0.5208 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4731 - acc: 0.8627 - val_loss: 0.5188 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4685 - acc: 0.8627 - val_loss: 0.5201 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4642 - acc: 0.8627 - val_loss: 0.5180 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 440us/step - loss: 0.4599 - acc: 0.8627 - val_loss: 0.5171 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.4540 - acc: 0.8627 - val_loss: 0.5151 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4497 - acc: 0.8627 - val_loss: 0.5134 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4452 - acc: 0.8627 - val_loss: 0.5125 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 726us/step - loss: 0.4420 - acc: 0.8824 - val_loss: 0.5133 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 450us/step - loss: 0.4383 - acc: 0.8824 - val_loss: 0.5124 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.4331 - acc: 0.8824 - val_loss: 0.5109 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4295 - acc: 0.8824 - val_loss: 0.5099 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4255 - acc: 0.8824 - val_loss: 0.5085 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4215 - acc: 0.8824 - val_loss: 0.5073 - val_acc: 0.7000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.4176 - acc: 0.8824 - val_loss: 0.5063 - val_acc: 0.6000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.4168 - acc: 0.8824 - val_loss: 0.5074 - val_acc: 0.6000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4108 - acc: 0.8824 - val_loss: 0.5061 - val_acc: 0.6000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.4071 - acc: 0.8824 - val_loss: 0.5051 - val_acc: 0.6000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 554us/step - loss: 0.4046 - acc: 0.8824 - val_loss: 0.5043 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 539us/step - loss: 0.4010 - acc: 0.8824 - val_loss: 0.5032 - val_acc: 0.6000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.3985 - acc: 0.8824 - val_loss: 0.5031 - val_acc: 0.6000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3940 - acc: 0.8824 - val_loss: 0.5043 - val_acc: 0.6000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3913 - acc: 0.8824 - val_loss: 0.5034 - val_acc: 0.6000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 278us/step - loss: 0.3883 - acc: 0.8824 - val_loss: 0.5024 - val_acc: 0.6000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.3857 - acc: 0.8824 - val_loss: 0.5015 - val_acc: 0.6000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3833 - acc: 0.8824 - val_loss: 0.5014 - val_acc: 0.6000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 528us/step - loss: 0.3800 - acc: 0.8824 - val_loss: 0.5016 - val_acc: 0.6000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 248us/step - loss: 0.3779 - acc: 0.8824 - val_loss: 0.5018 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3763 - acc: 0.8824 - val_loss: 0.5009 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 516us/step - loss: 0.3721 - acc: 0.8824 - val_loss: 0.5012 - val_acc: 0.6000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 405us/step - loss: 0.3697 - acc: 0.8824 - val_loss: 0.5006 - val_acc: 0.6000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 55us/step - loss: 0.3670 - acc: 0.8824 - val_loss: 0.5024 - val_acc: 0.6000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3657 - acc: 0.8824 - val_loss: 0.5029 - val_acc: 0.6000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3630 - acc: 0.8824 - val_loss: 0.5025 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.3597 - acc: 0.8824 - val_loss: 0.5020 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3570 - acc: 0.8824 - val_loss: 0.5008 - val_acc: 0.6000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.3545 - acc: 0.8824 - val_loss: 0.5017 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3535 - acc: 0.8824 - val_loss: 0.5016 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 238us/step - loss: 0.3491 - acc: 0.8824 - val_loss: 0.5017 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.3467 - acc: 0.8824 - val_loss: 0.5012 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.3444 - acc: 0.8824 - val_loss: 0.5023 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3419 - acc: 0.8824 - val_loss: 0.5030 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 393us/step - loss: 0.3397 - acc: 0.8824 - val_loss: 0.5041 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3372 - acc: 0.8824 - val_loss: 0.5051 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 231us/step - loss: 0.3351 - acc: 0.8824 - val_loss: 0.5038 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 446us/step - loss: 0.3349 - acc: 0.8824 - val_loss: 0.5045 - val_acc: 0.6000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3315 - acc: 0.8824 - val_loss: 0.5059 - val_acc: 0.7000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 308us/step - loss: 0.3283 - acc: 0.8824 - val_loss: 0.5067 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.3257 - acc: 0.8824 - val_loss: 0.5061 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 375us/step - loss: 0.3233 - acc: 0.8824 - val_loss: 0.5058 - val_acc: 0.7000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 397us/step - loss: 0.3214 - acc: 0.8824 - val_loss: 0.5041 - val_acc: 0.7000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3194 - acc: 0.8824 - val_loss: 0.5036 - val_acc: 0.7000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.3189 - acc: 0.8824 - val_loss: 0.5071 - val_acc: 0.7000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3167 - acc: 0.8824 - val_loss: 0.5065 - val_acc: 0.7000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 342us/step - loss: 0.3140 - acc: 0.8824 - val_loss: 0.5057 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3127 - acc: 0.8627 - val_loss: 0.5028 - val_acc: 0.7000\n",
      "2018-06-12\n",
      "2018-06-13\n",
      "2018-06-14\n",
      "2018-06-15\n",
      "2018-06-19\n",
      "2018-06-20\n",
      "2018-06-21\n",
      "2018-06-22\n",
      "2018-06-25\n",
      "2018-06-26\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.4299 - acc: 0.8235 - val_loss: 0.1545 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 554us/step - loss: 0.4148 - acc: 0.8431 - val_loss: 0.1590 - val_acc: 0.9000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 347us/step - loss: 0.4070 - acc: 0.8627 - val_loss: 0.1617 - val_acc: 0.9000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 225us/step - loss: 0.3995 - acc: 0.8627 - val_loss: 0.1632 - val_acc: 0.9000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.3942 - acc: 0.8431 - val_loss: 0.1662 - val_acc: 0.9000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.3905 - acc: 0.8627 - val_loss: 0.1678 - val_acc: 0.9000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.3853 - acc: 0.8431 - val_loss: 0.1709 - val_acc: 0.9000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 368us/step - loss: 0.3826 - acc: 0.8431 - val_loss: 0.1722 - val_acc: 0.9000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 300us/step - loss: 0.3778 - acc: 0.8627 - val_loss: 0.1760 - val_acc: 0.9000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3774 - acc: 0.8235 - val_loss: 0.1741 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3712 - acc: 0.8627 - val_loss: 0.1736 - val_acc: 0.9000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.3676 - acc: 0.8627 - val_loss: 0.1765 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.3653 - acc: 0.8627 - val_loss: 0.1791 - val_acc: 0.9000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 118us/step - loss: 0.3609 - acc: 0.8627 - val_loss: 0.1809 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 282us/step - loss: 0.3593 - acc: 0.8627 - val_loss: 0.1842 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 205us/step - loss: 0.3547 - acc: 0.8627 - val_loss: 0.1851 - val_acc: 0.9000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 322us/step - loss: 0.3514 - acc: 0.8824 - val_loss: 0.1834 - val_acc: 0.9000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3486 - acc: 0.9020 - val_loss: 0.1827 - val_acc: 0.9000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 300us/step - loss: 0.3472 - acc: 0.8824 - val_loss: 0.1813 - val_acc: 0.9000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3439 - acc: 0.9020 - val_loss: 0.1817 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 458us/step - loss: 0.3405 - acc: 0.9020 - val_loss: 0.1810 - val_acc: 0.9000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3387 - acc: 0.9020 - val_loss: 0.1796 - val_acc: 0.9000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 460us/step - loss: 0.3366 - acc: 0.9020 - val_loss: 0.1817 - val_acc: 0.9000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.3337 - acc: 0.9020 - val_loss: 0.1847 - val_acc: 0.9000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 230us/step - loss: 0.3298 - acc: 0.9020 - val_loss: 0.1861 - val_acc: 0.9000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.3290 - acc: 0.9020 - val_loss: 0.1885 - val_acc: 0.9000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.3258 - acc: 0.9020 - val_loss: 0.1886 - val_acc: 0.9000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 245us/step - loss: 0.3261 - acc: 0.8824 - val_loss: 0.1912 - val_acc: 0.9000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 203us/step - loss: 0.3204 - acc: 0.8627 - val_loss: 0.1912 - val_acc: 0.9000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.3179 - acc: 0.8824 - val_loss: 0.1923 - val_acc: 0.9000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3158 - acc: 0.8627 - val_loss: 0.1931 - val_acc: 0.9000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3130 - acc: 0.8627 - val_loss: 0.1909 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.3100 - acc: 0.9020 - val_loss: 0.1901 - val_acc: 0.9000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.3092 - acc: 0.9020 - val_loss: 0.1923 - val_acc: 0.9000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3058 - acc: 0.9020 - val_loss: 0.1910 - val_acc: 0.9000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 389us/step - loss: 0.3032 - acc: 0.9020 - val_loss: 0.1911 - val_acc: 0.9000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.3003 - acc: 0.9020 - val_loss: 0.1906 - val_acc: 0.9000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2984 - acc: 0.9020 - val_loss: 0.1913 - val_acc: 0.9000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2954 - acc: 0.9020 - val_loss: 0.1908 - val_acc: 0.9000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 242us/step - loss: 0.2955 - acc: 0.8824 - val_loss: 0.1871 - val_acc: 0.9000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.2927 - acc: 0.9020 - val_loss: 0.1847 - val_acc: 0.9000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.2902 - acc: 0.9020 - val_loss: 0.1869 - val_acc: 0.9000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 422us/step - loss: 0.2878 - acc: 0.9020 - val_loss: 0.1878 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 438us/step - loss: 0.2867 - acc: 0.9020 - val_loss: 0.1862 - val_acc: 0.9000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 487us/step - loss: 0.2834 - acc: 0.9020 - val_loss: 0.1861 - val_acc: 0.9000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 301us/step - loss: 0.2823 - acc: 0.9020 - val_loss: 0.1877 - val_acc: 0.9000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 526us/step - loss: 0.2800 - acc: 0.9020 - val_loss: 0.1878 - val_acc: 0.9000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 484us/step - loss: 0.2788 - acc: 0.9020 - val_loss: 0.1904 - val_acc: 0.9000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.2765 - acc: 0.9020 - val_loss: 0.1929 - val_acc: 0.9000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.2746 - acc: 0.9020 - val_loss: 0.1935 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.2726 - acc: 0.9020 - val_loss: 0.1943 - val_acc: 0.9000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 479us/step - loss: 0.2708 - acc: 0.9020 - val_loss: 0.1945 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 592us/step - loss: 0.2692 - acc: 0.9020 - val_loss: 0.1954 - val_acc: 0.9000\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 741us/step - loss: 0.2674 - acc: 0.9216 - val_loss: 0.1943 - val_acc: 0.9000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 279us/step - loss: 0.2665 - acc: 0.9216 - val_loss: 0.1951 - val_acc: 0.9000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 340us/step - loss: 0.2648 - acc: 0.9216 - val_loss: 0.1925 - val_acc: 0.9000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2625 - acc: 0.9216 - val_loss: 0.1930 - val_acc: 0.9000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 731us/step - loss: 0.2608 - acc: 0.9216 - val_loss: 0.1927 - val_acc: 0.9000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2603 - acc: 0.9216 - val_loss: 0.1946 - val_acc: 0.9000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2571 - acc: 0.9216 - val_loss: 0.1961 - val_acc: 0.9000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2570 - acc: 0.9216 - val_loss: 0.1941 - val_acc: 0.9000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 0.2541 - acc: 0.9216 - val_loss: 0.1934 - val_acc: 0.9000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 284us/step - loss: 0.2524 - acc: 0.9216 - val_loss: 0.1943 - val_acc: 0.9000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2507 - acc: 0.9216 - val_loss: 0.1946 - val_acc: 0.9000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2495 - acc: 0.9216 - val_loss: 0.1982 - val_acc: 0.9000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.2486 - acc: 0.9216 - val_loss: 0.1964 - val_acc: 0.9000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.2467 - acc: 0.9216 - val_loss: 0.1955 - val_acc: 0.9000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2447 - acc: 0.9216 - val_loss: 0.1985 - val_acc: 0.9000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2433 - acc: 0.9216 - val_loss: 0.1978 - val_acc: 0.9000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2423 - acc: 0.9216 - val_loss: 0.2011 - val_acc: 0.9000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 192us/step - loss: 0.2410 - acc: 0.9216 - val_loss: 0.2023 - val_acc: 0.9000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 441us/step - loss: 0.2395 - acc: 0.9412 - val_loss: 0.2018 - val_acc: 0.9000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 544us/step - loss: 0.2388 - acc: 0.9412 - val_loss: 0.1994 - val_acc: 0.9000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 352us/step - loss: 0.2361 - acc: 0.9412 - val_loss: 0.1989 - val_acc: 0.9000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2351 - acc: 0.9412 - val_loss: 0.1968 - val_acc: 0.9000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.2361 - acc: 0.9216 - val_loss: 0.1945 - val_acc: 0.9000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2319 - acc: 0.9412 - val_loss: 0.1953 - val_acc: 0.9000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2308 - acc: 0.9412 - val_loss: 0.1965 - val_acc: 0.9000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2293 - acc: 0.9412 - val_loss: 0.1962 - val_acc: 0.9000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 204us/step - loss: 0.2293 - acc: 0.9412 - val_loss: 0.1955 - val_acc: 0.9000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 302us/step - loss: 0.2265 - acc: 0.9412 - val_loss: 0.1974 - val_acc: 0.9000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.2268 - acc: 0.9412 - val_loss: 0.1981 - val_acc: 0.9000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.2249 - acc: 0.9412 - val_loss: 0.2001 - val_acc: 0.9000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2257 - acc: 0.9412 - val_loss: 0.1988 - val_acc: 0.9000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.2223 - acc: 0.9412 - val_loss: 0.2000 - val_acc: 0.9000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2225 - acc: 0.9412 - val_loss: 0.2028 - val_acc: 0.9000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2212 - acc: 0.9412 - val_loss: 0.2015 - val_acc: 0.9000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2196 - acc: 0.9412 - val_loss: 0.2001 - val_acc: 0.9000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2184 - acc: 0.9412 - val_loss: 0.2007 - val_acc: 0.9000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.2178 - acc: 0.9412 - val_loss: 0.2012 - val_acc: 0.9000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2168 - acc: 0.9412 - val_loss: 0.2027 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.2169 - acc: 0.9412 - val_loss: 0.2022 - val_acc: 0.9000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.2150 - acc: 0.9412 - val_loss: 0.2017 - val_acc: 0.9000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2153 - acc: 0.9412 - val_loss: 0.2062 - val_acc: 0.9000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.2127 - acc: 0.9412 - val_loss: 0.2090 - val_acc: 0.9000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2151 - acc: 0.9412 - val_loss: 0.2065 - val_acc: 0.9000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.2106 - acc: 0.9412 - val_loss: 0.2066 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2107 - acc: 0.9412 - val_loss: 0.2051 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2102 - acc: 0.9412 - val_loss: 0.2080 - val_acc: 0.9000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 282us/step - loss: 0.2100 - acc: 0.9412 - val_loss: 0.2067 - val_acc: 0.9000\n",
      "2018-06-27\n",
      "2018-06-28\n",
      "2018-06-29\n",
      "2018-07-02\n",
      "2018-07-03\n",
      "2018-07-04\n",
      "2018-07-05\n",
      "2018-07-06\n",
      "2018-07-09\n",
      "2018-07-10\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.4718 - acc: 0.8039 - val_loss: 1.7197 - val_acc: 0.7000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 484us/step - loss: 0.4415 - acc: 0.8039 - val_loss: 1.7509 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4232 - acc: 0.8039 - val_loss: 1.7732 - val_acc: 0.7000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 717us/step - loss: 0.4097 - acc: 0.8039 - val_loss: 1.7942 - val_acc: 0.7000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.3990 - acc: 0.8235 - val_loss: 1.8164 - val_acc: 0.7000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3893 - acc: 0.8431 - val_loss: 1.8359 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 282us/step - loss: 0.3798 - acc: 0.8431 - val_loss: 1.8483 - val_acc: 0.7000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 533us/step - loss: 0.3732 - acc: 0.8431 - val_loss: 1.8565 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3685 - acc: 0.8431 - val_loss: 1.8664 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3644 - acc: 0.8431 - val_loss: 1.8781 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.3600 - acc: 0.8431 - val_loss: 1.8831 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.3557 - acc: 0.8627 - val_loss: 1.8933 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.3509 - acc: 0.8824 - val_loss: 1.8985 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.3477 - acc: 0.8824 - val_loss: 1.9157 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.3457 - acc: 0.8627 - val_loss: 1.9175 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3406 - acc: 0.8824 - val_loss: 1.9294 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3372 - acc: 0.8824 - val_loss: 1.9356 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 462us/step - loss: 0.3349 - acc: 0.8824 - val_loss: 1.9398 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.3338 - acc: 0.9020 - val_loss: 1.9414 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3312 - acc: 0.8824 - val_loss: 1.9556 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 753us/step - loss: 0.3277 - acc: 0.9020 - val_loss: 1.9610 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 751us/step - loss: 0.3245 - acc: 0.9020 - val_loss: 1.9691 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3245 - acc: 0.9020 - val_loss: 1.9806 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 209us/step - loss: 0.3210 - acc: 0.8824 - val_loss: 1.9853 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.3188 - acc: 0.9020 - val_loss: 1.9951 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3188 - acc: 0.9020 - val_loss: 2.0056 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3135 - acc: 0.8824 - val_loss: 2.0111 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 371us/step - loss: 0.3128 - acc: 0.8824 - val_loss: 2.0212 - val_acc: 0.7000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3098 - acc: 0.8824 - val_loss: 2.0249 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3075 - acc: 0.8627 - val_loss: 2.0249 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3053 - acc: 0.9020 - val_loss: 2.0371 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3044 - acc: 0.9020 - val_loss: 2.0497 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3012 - acc: 0.9020 - val_loss: 2.0573 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2992 - acc: 0.8824 - val_loss: 2.0683 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2971 - acc: 0.8824 - val_loss: 2.0745 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 587us/step - loss: 0.2955 - acc: 0.8824 - val_loss: 2.0742 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.2934 - acc: 0.8824 - val_loss: 2.0853 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2940 - acc: 0.8824 - val_loss: 2.0827 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2898 - acc: 0.9020 - val_loss: 2.0967 - val_acc: 0.6000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.2884 - acc: 0.8824 - val_loss: 2.1011 - val_acc: 0.6000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 650us/step - loss: 0.2865 - acc: 0.9020 - val_loss: 2.1137 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 286us/step - loss: 0.2857 - acc: 0.8824 - val_loss: 2.1169 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.2838 - acc: 0.9020 - val_loss: 2.1177 - val_acc: 0.6000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 524us/step - loss: 0.2847 - acc: 0.8824 - val_loss: 2.1164 - val_acc: 0.6000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 464us/step - loss: 0.2802 - acc: 0.9020 - val_loss: 2.1196 - val_acc: 0.6000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2786 - acc: 0.9020 - val_loss: 2.1328 - val_acc: 0.6000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 468us/step - loss: 0.2774 - acc: 0.9020 - val_loss: 2.1357 - val_acc: 0.6000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.2757 - acc: 0.9020 - val_loss: 2.1471 - val_acc: 0.6000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 798us/step - loss: 0.2735 - acc: 0.9020 - val_loss: 2.1533 - val_acc: 0.6000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.2735 - acc: 0.9020 - val_loss: 2.1613 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.2718 - acc: 0.9020 - val_loss: 2.1722 - val_acc: 0.6000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2707 - acc: 0.8824 - val_loss: 2.1760 - val_acc: 0.6000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.2700 - acc: 0.9020 - val_loss: 2.1774 - val_acc: 0.6000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.2677 - acc: 0.9020 - val_loss: 2.1914 - val_acc: 0.6000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.2673 - acc: 0.8824 - val_loss: 2.1906 - val_acc: 0.6000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.2657 - acc: 0.8824 - val_loss: 2.1949 - val_acc: 0.6000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 347us/step - loss: 0.2628 - acc: 0.9020 - val_loss: 2.2050 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2621 - acc: 0.9020 - val_loss: 2.2197 - val_acc: 0.6000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 620us/step - loss: 0.2626 - acc: 0.8824 - val_loss: 2.2274 - val_acc: 0.6000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 211us/step - loss: 0.2595 - acc: 0.9020 - val_loss: 2.2365 - val_acc: 0.6000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.2598 - acc: 0.9020 - val_loss: 2.2436 - val_acc: 0.6000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2609 - acc: 0.9020 - val_loss: 2.2602 - val_acc: 0.6000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2567 - acc: 0.9020 - val_loss: 2.2680 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.2573 - acc: 0.8824 - val_loss: 2.2677 - val_acc: 0.6000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2540 - acc: 0.9020 - val_loss: 2.2798 - val_acc: 0.6000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 493us/step - loss: 0.2524 - acc: 0.9020 - val_loss: 2.2895 - val_acc: 0.6000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.2524 - acc: 0.9020 - val_loss: 2.2984 - val_acc: 0.6000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2508 - acc: 0.9020 - val_loss: 2.3003 - val_acc: 0.6000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.2497 - acc: 0.9020 - val_loss: 2.3063 - val_acc: 0.6000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 812us/step - loss: 0.2498 - acc: 0.9020 - val_loss: 2.3194 - val_acc: 0.6000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2496 - acc: 0.9020 - val_loss: 2.3288 - val_acc: 0.6000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 458us/step - loss: 0.2468 - acc: 0.9020 - val_loss: 2.3360 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2454 - acc: 0.9020 - val_loss: 2.3397 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 368us/step - loss: 0.2439 - acc: 0.9020 - val_loss: 2.3465 - val_acc: 0.6000\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 255us/step - loss: 0.2450 - acc: 0.9020 - val_loss: 2.3480 - val_acc: 0.6000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2447 - acc: 0.9020 - val_loss: 2.3556 - val_acc: 0.6000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.2419 - acc: 0.8824 - val_loss: 2.3627 - val_acc: 0.6000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 383us/step - loss: 0.2404 - acc: 0.9020 - val_loss: 2.3705 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2397 - acc: 0.9020 - val_loss: 2.3748 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 721us/step - loss: 0.2384 - acc: 0.9020 - val_loss: 2.3771 - val_acc: 0.6000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2379 - acc: 0.9020 - val_loss: 2.3822 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.2374 - acc: 0.9020 - val_loss: 2.3911 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 634us/step - loss: 0.2369 - acc: 0.9020 - val_loss: 2.3901 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 40us/step - loss: 0.2353 - acc: 0.9020 - val_loss: 2.3964 - val_acc: 0.6000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2344 - acc: 0.9020 - val_loss: 2.4038 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 684us/step - loss: 0.2327 - acc: 0.9020 - val_loss: 2.4168 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 482us/step - loss: 0.2322 - acc: 0.9020 - val_loss: 2.4294 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 487us/step - loss: 0.2309 - acc: 0.9020 - val_loss: 2.4399 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 377us/step - loss: 0.2317 - acc: 0.9020 - val_loss: 2.4436 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.2302 - acc: 0.9020 - val_loss: 2.4519 - val_acc: 0.6000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 411us/step - loss: 0.2288 - acc: 0.9020 - val_loss: 2.4598 - val_acc: 0.6000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 426us/step - loss: 0.2284 - acc: 0.9020 - val_loss: 2.4609 - val_acc: 0.6000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 198us/step - loss: 0.2271 - acc: 0.9020 - val_loss: 2.4719 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 563us/step - loss: 0.2262 - acc: 0.8824 - val_loss: 2.4843 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2259 - acc: 0.9020 - val_loss: 2.4847 - val_acc: 0.6000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 331us/step - loss: 0.2242 - acc: 0.9020 - val_loss: 2.4921 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.2237 - acc: 0.8824 - val_loss: 2.4989 - val_acc: 0.6000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2235 - acc: 0.8824 - val_loss: 2.5051 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2218 - acc: 0.9020 - val_loss: 2.5216 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2219 - acc: 0.9020 - val_loss: 2.5369 - val_acc: 0.6000\n",
      "2018-07-11\n",
      "2018-07-12\n",
      "2018-07-13\n",
      "2018-07-16\n",
      "2018-07-17\n",
      "2018-07-18\n",
      "2018-07-19\n",
      "2018-07-20\n",
      "2018-07-23\n",
      "2018-07-24\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 0.6873 - acc: 0.6667 - val_loss: 1.3705 - val_acc: 0.4000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.6501 - acc: 0.7059 - val_loss: 1.3521 - val_acc: 0.4000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.6301 - acc: 0.7059 - val_loss: 1.3372 - val_acc: 0.4000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.6152 - acc: 0.7255 - val_loss: 1.3323 - val_acc: 0.4000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 290us/step - loss: 0.6029 - acc: 0.7255 - val_loss: 1.3318 - val_acc: 0.4000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.5934 - acc: 0.7255 - val_loss: 1.3277 - val_acc: 0.4000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 833us/step - loss: 0.5840 - acc: 0.7255 - val_loss: 1.3178 - val_acc: 0.4000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5735 - acc: 0.7255 - val_loss: 1.3139 - val_acc: 0.4000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 499us/step - loss: 0.5652 - acc: 0.7255 - val_loss: 1.2994 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 800us/step - loss: 0.5575 - acc: 0.7255 - val_loss: 1.2854 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 645us/step - loss: 0.5472 - acc: 0.7255 - val_loss: 1.2817 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.5381 - acc: 0.7255 - val_loss: 1.2752 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.5281 - acc: 0.7255 - val_loss: 1.2697 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 212us/step - loss: 0.5202 - acc: 0.7255 - val_loss: 1.2633 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.5154 - acc: 0.7255 - val_loss: 1.2697 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 773us/step - loss: 0.5058 - acc: 0.7255 - val_loss: 1.2628 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4992 - acc: 0.7255 - val_loss: 1.2543 - val_acc: 0.4000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4902 - acc: 0.7255 - val_loss: 1.2525 - val_acc: 0.4000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 286us/step - loss: 0.4835 - acc: 0.7451 - val_loss: 1.2410 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 550us/step - loss: 0.4771 - acc: 0.7451 - val_loss: 1.2322 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.4701 - acc: 0.7451 - val_loss: 1.2372 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.4661 - acc: 0.7451 - val_loss: 1.2297 - val_acc: 0.4000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 261us/step - loss: 0.4588 - acc: 0.7451 - val_loss: 1.2231 - val_acc: 0.4000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 455us/step - loss: 0.4500 - acc: 0.7451 - val_loss: 1.2279 - val_acc: 0.4000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 351us/step - loss: 0.4452 - acc: 0.7451 - val_loss: 1.2240 - val_acc: 0.4000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 360us/step - loss: 0.4396 - acc: 0.7451 - val_loss: 1.2285 - val_acc: 0.4000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4337 - acc: 0.7451 - val_loss: 1.2220 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.4278 - acc: 0.7451 - val_loss: 1.2276 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.4228 - acc: 0.7451 - val_loss: 1.2272 - val_acc: 0.4000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.4214 - acc: 0.7843 - val_loss: 1.2181 - val_acc: 0.4000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.4137 - acc: 0.7843 - val_loss: 1.2158 - val_acc: 0.4000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 828us/step - loss: 0.4089 - acc: 0.7843 - val_loss: 1.2173 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.4047 - acc: 0.7843 - val_loss: 1.2194 - val_acc: 0.4000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 60us/step - loss: 0.4009 - acc: 0.7843 - val_loss: 1.2212 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3975 - acc: 0.8039 - val_loss: 1.2331 - val_acc: 0.4000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3936 - acc: 0.7843 - val_loss: 1.2301 - val_acc: 0.4000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.3891 - acc: 0.8039 - val_loss: 1.2375 - val_acc: 0.4000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 249us/step - loss: 0.3841 - acc: 0.8039 - val_loss: 1.2388 - val_acc: 0.4000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 459us/step - loss: 0.3818 - acc: 0.8235 - val_loss: 1.2376 - val_acc: 0.4000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 398us/step - loss: 0.3788 - acc: 0.8235 - val_loss: 1.2297 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3746 - acc: 0.8235 - val_loss: 1.2405 - val_acc: 0.4000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 330us/step - loss: 0.3718 - acc: 0.8235 - val_loss: 1.2555 - val_acc: 0.4000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 322us/step - loss: 0.3677 - acc: 0.8235 - val_loss: 1.2573 - val_acc: 0.4000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3638 - acc: 0.8431 - val_loss: 1.2586 - val_acc: 0.4000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 1000us/step - loss: 0.3587 - acc: 0.8627 - val_loss: 1.2672 - val_acc: 0.4000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 454us/step - loss: 0.3541 - acc: 0.8627 - val_loss: 1.2603 - val_acc: 0.4000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.3503 - acc: 0.8824 - val_loss: 1.2687 - val_acc: 0.4000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 769us/step - loss: 0.3473 - acc: 0.8824 - val_loss: 1.2758 - val_acc: 0.4000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 606us/step - loss: 0.3421 - acc: 0.8824 - val_loss: 1.2812 - val_acc: 0.4000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 516us/step - loss: 0.3384 - acc: 0.8824 - val_loss: 1.2775 - val_acc: 0.4000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3355 - acc: 0.8824 - val_loss: 1.2724 - val_acc: 0.4000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 604us/step - loss: 0.3323 - acc: 0.8824 - val_loss: 1.2669 - val_acc: 0.4000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 487us/step - loss: 0.3295 - acc: 0.8824 - val_loss: 1.2606 - val_acc: 0.4000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 0.3269 - acc: 0.8824 - val_loss: 1.2589 - val_acc: 0.4000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.3243 - acc: 0.8824 - val_loss: 1.2552 - val_acc: 0.4000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 633us/step - loss: 0.3230 - acc: 0.8824 - val_loss: 1.2637 - val_acc: 0.4000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 441us/step - loss: 0.3193 - acc: 0.8824 - val_loss: 1.2673 - val_acc: 0.4000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3172 - acc: 0.8824 - val_loss: 1.2692 - val_acc: 0.4000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 685us/step - loss: 0.3140 - acc: 0.8824 - val_loss: 1.2636 - val_acc: 0.4000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 592us/step - loss: 0.3123 - acc: 0.8824 - val_loss: 1.2746 - val_acc: 0.4000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 434us/step - loss: 0.3101 - acc: 0.8824 - val_loss: 1.2787 - val_acc: 0.4000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 281us/step - loss: 0.3072 - acc: 0.8824 - val_loss: 1.2779 - val_acc: 0.4000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 791us/step - loss: 0.3044 - acc: 0.8824 - val_loss: 1.2773 - val_acc: 0.4000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 229us/step - loss: 0.3026 - acc: 0.8824 - val_loss: 1.2830 - val_acc: 0.4000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 921us/step - loss: 0.3021 - acc: 0.8824 - val_loss: 1.2656 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 402us/step - loss: 0.2990 - acc: 0.8824 - val_loss: 1.2685 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.2972 - acc: 0.8824 - val_loss: 1.2788 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2949 - acc: 0.8824 - val_loss: 1.2867 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 563us/step - loss: 0.2935 - acc: 0.8824 - val_loss: 1.2960 - val_acc: 0.4000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 480us/step - loss: 0.2922 - acc: 0.8824 - val_loss: 1.3029 - val_acc: 0.4000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.2914 - acc: 0.8824 - val_loss: 1.3015 - val_acc: 0.4000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 637us/step - loss: 0.2890 - acc: 0.8824 - val_loss: 1.3088 - val_acc: 0.4000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 355us/step - loss: 0.2885 - acc: 0.8824 - val_loss: 1.3197 - val_acc: 0.4000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 367us/step - loss: 0.2855 - acc: 0.8824 - val_loss: 1.3240 - val_acc: 0.4000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 743us/step - loss: 0.2845 - acc: 0.8824 - val_loss: 1.3319 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 409us/step - loss: 0.2829 - acc: 0.8824 - val_loss: 1.3290 - val_acc: 0.4000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 397us/step - loss: 0.2811 - acc: 0.8824 - val_loss: 1.3351 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 819us/step - loss: 0.2805 - acc: 0.8824 - val_loss: 1.3245 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 10us/step - loss: 0.2788 - acc: 0.8824 - val_loss: 1.3316 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2767 - acc: 0.8824 - val_loss: 1.3323 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 316us/step - loss: 0.2758 - acc: 0.8824 - val_loss: 1.3354 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 611us/step - loss: 0.2738 - acc: 0.8824 - val_loss: 1.3315 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 553us/step - loss: 0.2729 - acc: 0.8824 - val_loss: 1.3394 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.2705 - acc: 0.8824 - val_loss: 1.3431 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.2694 - acc: 0.8824 - val_loss: 1.3394 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 244us/step - loss: 0.2674 - acc: 0.8824 - val_loss: 1.3394 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2670 - acc: 0.8824 - val_loss: 1.3365 - val_acc: 0.4000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2669 - acc: 0.8824 - val_loss: 1.3171 - val_acc: 0.4000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 348us/step - loss: 0.2637 - acc: 0.8824 - val_loss: 1.3202 - val_acc: 0.4000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 263us/step - loss: 0.2635 - acc: 0.8824 - val_loss: 1.3279 - val_acc: 0.4000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.2617 - acc: 0.8824 - val_loss: 1.3323 - val_acc: 0.4000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 394us/step - loss: 0.2604 - acc: 0.8824 - val_loss: 1.3324 - val_acc: 0.4000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2586 - acc: 0.8824 - val_loss: 1.3333 - val_acc: 0.4000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 454us/step - loss: 0.2589 - acc: 0.8824 - val_loss: 1.3438 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 676us/step - loss: 0.2566 - acc: 0.8824 - val_loss: 1.3558 - val_acc: 0.3000\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 0us/step - loss: 0.2551 - acc: 0.8824 - val_loss: 1.3531 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 738us/step - loss: 0.2551 - acc: 0.8824 - val_loss: 1.3638 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 379us/step - loss: 0.2527 - acc: 0.8824 - val_loss: 1.3687 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 0.2530 - acc: 0.8824 - val_loss: 1.3630 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 232us/step - loss: 0.2523 - acc: 0.8824 - val_loss: 1.3596 - val_acc: 0.3000\n",
      "2018-07-25\n",
      "2018-07-26\n",
      "2018-07-27\n",
      "2018-07-30\n",
      "2018-07-31\n",
      "2018-08-01\n",
      "2018-08-02\n",
      "2018-08-03\n",
      "2018-08-06\n",
      "2018-08-07\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 0.9201 - acc: 0.6275 - val_loss: 3.6585 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.8864 - acc: 0.6078 - val_loss: 3.6546 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8547 - acc: 0.6078 - val_loss: 3.6283 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 332us/step - loss: 0.8331 - acc: 0.6078 - val_loss: 3.6047 - val_acc: 0.3000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 339us/step - loss: 0.8143 - acc: 0.6078 - val_loss: 3.5878 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 694us/step - loss: 0.7961 - acc: 0.6078 - val_loss: 3.5936 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.7862 - acc: 0.6078 - val_loss: 3.5997 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 766us/step - loss: 0.7667 - acc: 0.6275 - val_loss: 3.5690 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.7527 - acc: 0.6275 - val_loss: 3.5514 - val_acc: 0.3000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 679us/step - loss: 0.7407 - acc: 0.6667 - val_loss: 3.5587 - val_acc: 0.3000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.7292 - acc: 0.6471 - val_loss: 3.5635 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.7210 - acc: 0.6667 - val_loss: 3.5594 - val_acc: 0.3000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.7098 - acc: 0.6275 - val_loss: 3.5397 - val_acc: 0.3000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.6971 - acc: 0.6667 - val_loss: 3.5295 - val_acc: 0.3000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 619us/step - loss: 0.6889 - acc: 0.6667 - val_loss: 3.5136 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 286us/step - loss: 0.6807 - acc: 0.6667 - val_loss: 3.4911 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 425us/step - loss: 0.6642 - acc: 0.6667 - val_loss: 3.4847 - val_acc: 0.3000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 420us/step - loss: 0.6556 - acc: 0.6667 - val_loss: 3.4717 - val_acc: 0.3000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 477us/step - loss: 0.6470 - acc: 0.6667 - val_loss: 3.4368 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 332us/step - loss: 0.6356 - acc: 0.6667 - val_loss: 3.4232 - val_acc: 0.3000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 492us/step - loss: 0.6272 - acc: 0.6667 - val_loss: 3.4056 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 730us/step - loss: 0.6198 - acc: 0.6667 - val_loss: 3.3966 - val_acc: 0.3000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 570us/step - loss: 0.6122 - acc: 0.6667 - val_loss: 3.3962 - val_acc: 0.3000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 213us/step - loss: 0.6030 - acc: 0.6863 - val_loss: 3.3878 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 358us/step - loss: 0.5967 - acc: 0.6863 - val_loss: 3.3696 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 492us/step - loss: 0.5886 - acc: 0.6863 - val_loss: 3.3585 - val_acc: 0.3000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 556us/step - loss: 0.5791 - acc: 0.7059 - val_loss: 3.3382 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 420us/step - loss: 0.5664 - acc: 0.7059 - val_loss: 3.2902 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.5539 - acc: 0.7059 - val_loss: 3.2744 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 253us/step - loss: 0.5447 - acc: 0.7451 - val_loss: 3.2400 - val_acc: 0.3000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 190us/step - loss: 0.5346 - acc: 0.7647 - val_loss: 3.2596 - val_acc: 0.3000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.5239 - acc: 0.7647 - val_loss: 3.2177 - val_acc: 0.3000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.5157 - acc: 0.7647 - val_loss: 3.2370 - val_acc: 0.3000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 277us/step - loss: 0.5062 - acc: 0.7647 - val_loss: 3.2224 - val_acc: 0.3000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.4976 - acc: 0.7647 - val_loss: 3.2334 - val_acc: 0.3000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 585us/step - loss: 0.4906 - acc: 0.7647 - val_loss: 3.1933 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 332us/step - loss: 0.4833 - acc: 0.7647 - val_loss: 3.1859 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.4782 - acc: 0.7647 - val_loss: 3.1870 - val_acc: 0.3000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 557us/step - loss: 0.4728 - acc: 0.7647 - val_loss: 3.2045 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4644 - acc: 0.7647 - val_loss: 3.2134 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 373us/step - loss: 0.4605 - acc: 0.7843 - val_loss: 3.1913 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.4529 - acc: 0.7647 - val_loss: 3.1807 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4471 - acc: 0.7843 - val_loss: 3.1716 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 248us/step - loss: 0.4417 - acc: 0.7843 - val_loss: 3.1673 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4380 - acc: 0.7843 - val_loss: 3.1667 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 483us/step - loss: 0.4352 - acc: 0.8039 - val_loss: 3.1537 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4318 - acc: 0.8039 - val_loss: 3.1571 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 231us/step - loss: 0.4288 - acc: 0.8039 - val_loss: 3.1426 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.4239 - acc: 0.8039 - val_loss: 3.1496 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4219 - acc: 0.8039 - val_loss: 3.1663 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 238us/step - loss: 0.4171 - acc: 0.8431 - val_loss: 3.1457 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4149 - acc: 0.8235 - val_loss: 3.1631 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 528us/step - loss: 0.4107 - acc: 0.8431 - val_loss: 3.1657 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 690us/step - loss: 0.4086 - acc: 0.8431 - val_loss: 3.1705 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.4059 - acc: 0.8431 - val_loss: 3.1154 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 550us/step - loss: 0.4026 - acc: 0.8431 - val_loss: 3.0939 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 194us/step - loss: 0.4001 - acc: 0.8235 - val_loss: 3.1065 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 358us/step - loss: 0.3994 - acc: 0.8431 - val_loss: 3.1142 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 598us/step - loss: 0.3949 - acc: 0.8431 - val_loss: 3.0999 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 620us/step - loss: 0.3929 - acc: 0.8431 - val_loss: 3.0839 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 0.3894 - acc: 0.8431 - val_loss: 3.0662 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.3884 - acc: 0.8431 - val_loss: 3.0432 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 287us/step - loss: 0.3845 - acc: 0.8235 - val_loss: 3.0337 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 245us/step - loss: 0.3822 - acc: 0.8235 - val_loss: 3.0337 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 242us/step - loss: 0.3789 - acc: 0.8431 - val_loss: 3.0308 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 532us/step - loss: 0.3769 - acc: 0.8431 - val_loss: 3.0237 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 320us/step - loss: 0.3736 - acc: 0.8431 - val_loss: 3.0087 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 348us/step - loss: 0.3710 - acc: 0.8431 - val_loss: 2.9985 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 621us/step - loss: 0.3683 - acc: 0.8431 - val_loss: 3.0032 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 253us/step - loss: 0.3661 - acc: 0.8627 - val_loss: 3.0052 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.3629 - acc: 0.8627 - val_loss: 2.9988 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 272us/step - loss: 0.3612 - acc: 0.8627 - val_loss: 3.0153 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 200us/step - loss: 0.3578 - acc: 0.8627 - val_loss: 3.0315 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 301us/step - loss: 0.3559 - acc: 0.8824 - val_loss: 3.0140 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3557 - acc: 0.8627 - val_loss: 3.0145 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.3510 - acc: 0.8824 - val_loss: 3.0098 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.3496 - acc: 0.8824 - val_loss: 3.0209 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 0.3483 - acc: 0.8627 - val_loss: 3.0319 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.3439 - acc: 0.8824 - val_loss: 3.0286 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 337us/step - loss: 0.3420 - acc: 0.8824 - val_loss: 3.0265 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 222us/step - loss: 0.3400 - acc: 0.8824 - val_loss: 3.0155 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3372 - acc: 0.8824 - val_loss: 3.0106 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 203us/step - loss: 0.3350 - acc: 0.8824 - val_loss: 3.0153 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.3326 - acc: 0.8824 - val_loss: 2.9989 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 725us/step - loss: 0.3324 - acc: 0.8627 - val_loss: 3.0260 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 260us/step - loss: 0.3284 - acc: 0.8824 - val_loss: 3.0208 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 182us/step - loss: 0.3294 - acc: 0.8627 - val_loss: 3.0367 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 549us/step - loss: 0.3247 - acc: 0.8824 - val_loss: 3.0311 - val_acc: 0.3000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3227 - acc: 0.8824 - val_loss: 3.0231 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 394us/step - loss: 0.3212 - acc: 0.8824 - val_loss: 3.0289 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3190 - acc: 0.8824 - val_loss: 3.0124 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 826us/step - loss: 0.3173 - acc: 0.8824 - val_loss: 3.0230 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 508us/step - loss: 0.3151 - acc: 0.8824 - val_loss: 2.9642 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.3132 - acc: 0.8824 - val_loss: 2.9739 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 219us/step - loss: 0.3109 - acc: 0.8824 - val_loss: 2.9644 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 603us/step - loss: 0.3104 - acc: 0.8824 - val_loss: 2.9452 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 642us/step - loss: 0.3088 - acc: 0.8824 - val_loss: 2.9457 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.3062 - acc: 0.8824 - val_loss: 2.9449 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 507us/step - loss: 0.3053 - acc: 0.8824 - val_loss: 2.9582 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 503us/step - loss: 0.3029 - acc: 0.8824 - val_loss: 2.9436 - val_acc: 0.3000\n",
      "2018-08-08\n",
      "2018-08-09\n",
      "2018-08-10\n",
      "2018-08-13\n",
      "2018-08-14\n",
      "2018-08-15\n",
      "2018-08-16\n",
      "2018-08-17\n",
      "2018-08-20\n",
      "2018-08-21\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 2.1353 - acc: 0.4510 - val_loss: 1.7240 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.9996 - acc: 0.4706 - val_loss: 1.7283 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 266us/step - loss: 1.9136 - acc: 0.4902 - val_loss: 1.7328 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 290us/step - loss: 1.8402 - acc: 0.4902 - val_loss: 1.7361 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 218us/step - loss: 1.7746 - acc: 0.5098 - val_loss: 1.7378 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 201us/step - loss: 1.7226 - acc: 0.5098 - val_loss: 1.7448 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.6822 - acc: 0.5098 - val_loss: 1.7575 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 627us/step - loss: 1.6419 - acc: 0.5098 - val_loss: 1.7574 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.6049 - acc: 0.5098 - val_loss: 1.7608 - val_acc: 0.1000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.5661 - acc: 0.5098 - val_loss: 1.7679 - val_acc: 0.1000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.5231 - acc: 0.5098 - val_loss: 1.7618 - val_acc: 0.1000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 568us/step - loss: 1.4779 - acc: 0.5098 - val_loss: 1.7574 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.4352 - acc: 0.5098 - val_loss: 1.7584 - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 1.3992 - acc: 0.5098 - val_loss: 1.7570 - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 1.3654 - acc: 0.5098 - val_loss: 1.7524 - val_acc: 0.1000\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 748us/step - loss: 1.3308 - acc: 0.5098 - val_loss: 1.7539 - val_acc: 0.1000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.2970 - acc: 0.5098 - val_loss: 1.7523 - val_acc: 0.1000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 588us/step - loss: 1.2639 - acc: 0.5098 - val_loss: 1.7499 - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 569us/step - loss: 1.2354 - acc: 0.5098 - val_loss: 1.7510 - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 1.2064 - acc: 0.5098 - val_loss: 1.7487 - val_acc: 0.1000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 631us/step - loss: 1.1769 - acc: 0.5294 - val_loss: 1.7432 - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1528 - acc: 0.5294 - val_loss: 1.7433 - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.1296 - acc: 0.5294 - val_loss: 1.7452 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1063 - acc: 0.5294 - val_loss: 1.7416 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 864us/step - loss: 1.0834 - acc: 0.5294 - val_loss: 1.7352 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 597us/step - loss: 1.0576 - acc: 0.5294 - val_loss: 1.7323 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 1.0376 - acc: 0.5294 - val_loss: 1.7227 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 699us/step - loss: 1.0117 - acc: 0.5294 - val_loss: 1.7289 - val_acc: 0.2000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 241us/step - loss: 0.9899 - acc: 0.5490 - val_loss: 1.7258 - val_acc: 0.2000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9675 - acc: 0.5294 - val_loss: 1.7335 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.9459 - acc: 0.5294 - val_loss: 1.7256 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9225 - acc: 0.5294 - val_loss: 1.7284 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 552us/step - loss: 0.9027 - acc: 0.5294 - val_loss: 1.7177 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 355us/step - loss: 0.8804 - acc: 0.5294 - val_loss: 1.7131 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8645 - acc: 0.5294 - val_loss: 1.7091 - val_acc: 0.3000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.8510 - acc: 0.5294 - val_loss: 1.7048 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 220us/step - loss: 0.8349 - acc: 0.5294 - val_loss: 1.6977 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.8195 - acc: 0.5490 - val_loss: 1.6904 - val_acc: 0.3000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8073 - acc: 0.5490 - val_loss: 1.7008 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.7924 - acc: 0.5686 - val_loss: 1.7048 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.7788 - acc: 0.5686 - val_loss: 1.7120 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.7660 - acc: 0.5686 - val_loss: 1.6992 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 606us/step - loss: 0.7500 - acc: 0.5686 - val_loss: 1.6923 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 418us/step - loss: 0.7348 - acc: 0.5686 - val_loss: 1.6943 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7235 - acc: 0.5490 - val_loss: 1.7009 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 253us/step - loss: 0.7098 - acc: 0.5882 - val_loss: 1.7125 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6993 - acc: 0.5882 - val_loss: 1.7291 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.6849 - acc: 0.5686 - val_loss: 1.7363 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 288us/step - loss: 0.6733 - acc: 0.5686 - val_loss: 1.7322 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 598us/step - loss: 0.6602 - acc: 0.6078 - val_loss: 1.7510 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 0.6464 - acc: 0.6275 - val_loss: 1.7480 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.6319 - acc: 0.6471 - val_loss: 1.7600 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6218 - acc: 0.6471 - val_loss: 1.7747 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 511us/step - loss: 0.6107 - acc: 0.6667 - val_loss: 1.7821 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 503us/step - loss: 0.5970 - acc: 0.6667 - val_loss: 1.7821 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5852 - acc: 0.6863 - val_loss: 1.7995 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5795 - acc: 0.6863 - val_loss: 1.7948 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 387us/step - loss: 0.5693 - acc: 0.6863 - val_loss: 1.8004 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 509us/step - loss: 0.5615 - acc: 0.6863 - val_loss: 1.8115 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5555 - acc: 0.7059 - val_loss: 1.8384 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.5477 - acc: 0.7255 - val_loss: 1.8471 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 201us/step - loss: 0.5413 - acc: 0.7255 - val_loss: 1.8592 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5346 - acc: 0.7451 - val_loss: 1.8648 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.5269 - acc: 0.7451 - val_loss: 1.8886 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 955us/step - loss: 0.5206 - acc: 0.7451 - val_loss: 1.9044 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 633us/step - loss: 0.5137 - acc: 0.7451 - val_loss: 1.9149 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 208us/step - loss: 0.5079 - acc: 0.7451 - val_loss: 1.9395 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.5013 - acc: 0.7647 - val_loss: 1.9576 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.4961 - acc: 0.7647 - val_loss: 1.9737 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 223us/step - loss: 0.4906 - acc: 0.7647 - val_loss: 1.9801 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 608us/step - loss: 0.4874 - acc: 0.7451 - val_loss: 2.0071 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 280us/step - loss: 0.4804 - acc: 0.7647 - val_loss: 2.0201 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 426us/step - loss: 0.4764 - acc: 0.7647 - val_loss: 2.0440 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 257us/step - loss: 0.4702 - acc: 0.7647 - val_loss: 2.0581 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 457us/step - loss: 0.4652 - acc: 0.7647 - val_loss: 2.0679 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 0.4613 - acc: 0.7647 - val_loss: 2.0912 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.4575 - acc: 0.7843 - val_loss: 2.0921 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4525 - acc: 0.7843 - val_loss: 2.1190 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.4479 - acc: 0.7843 - val_loss: 2.1287 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 516us/step - loss: 0.4426 - acc: 0.7843 - val_loss: 2.1394 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 467us/step - loss: 0.4400 - acc: 0.8039 - val_loss: 2.1402 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4352 - acc: 0.8039 - val_loss: 2.1466 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 576us/step - loss: 0.4335 - acc: 0.7843 - val_loss: 2.1709 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4285 - acc: 0.8235 - val_loss: 2.1957 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 214us/step - loss: 0.4237 - acc: 0.8235 - val_loss: 2.2015 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4209 - acc: 0.8235 - val_loss: 2.2021 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 547us/step - loss: 0.4172 - acc: 0.8235 - val_loss: 2.2260 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 319us/step - loss: 0.4134 - acc: 0.8235 - val_loss: 2.2313 - val_acc: 0.3000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 409us/step - loss: 0.4094 - acc: 0.8235 - val_loss: 2.2501 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 563us/step - loss: 0.4053 - acc: 0.8235 - val_loss: 2.2660 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 669us/step - loss: 0.4027 - acc: 0.8235 - val_loss: 2.2727 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.3999 - acc: 0.8235 - val_loss: 2.2832 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3968 - acc: 0.8235 - val_loss: 2.3205 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 649us/step - loss: 0.3936 - acc: 0.8235 - val_loss: 2.3192 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 270us/step - loss: 0.3890 - acc: 0.8235 - val_loss: 2.3323 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.3862 - acc: 0.8235 - val_loss: 2.3569 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3835 - acc: 0.8235 - val_loss: 2.3729 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 378us/step - loss: 0.3804 - acc: 0.8235 - val_loss: 2.4137 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3775 - acc: 0.8431 - val_loss: 2.4313 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 703us/step - loss: 0.3744 - acc: 0.8431 - val_loss: 2.4457 - val_acc: 0.3000\n",
      "2018-08-22\n",
      "2018-08-23\n",
      "2018-08-24\n",
      "2018-08-27\n",
      "2018-08-28\n",
      "2018-08-29\n",
      "2018-08-30\n",
      "2018-08-31\n",
      "2018-09-03\n",
      "2018-09-04\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 1.0029 - acc: 0.7647 - val_loss: 6.2010 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.9435 - acc: 0.7059 - val_loss: 6.2284 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.9142 - acc: 0.7059 - val_loss: 6.2583 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.8867 - acc: 0.7059 - val_loss: 6.2938 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.8659 - acc: 0.7059 - val_loss: 6.3308 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8482 - acc: 0.6863 - val_loss: 6.3566 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.8336 - acc: 0.6863 - val_loss: 6.3792 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8169 - acc: 0.6863 - val_loss: 6.4092 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.8038 - acc: 0.6667 - val_loss: 6.4437 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.7889 - acc: 0.6863 - val_loss: 6.4678 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7693 - acc: 0.6863 - val_loss: 6.4958 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7550 - acc: 0.6863 - val_loss: 6.5257 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7403 - acc: 0.6863 - val_loss: 6.5610 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7226 - acc: 0.6471 - val_loss: 6.5894 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.7066 - acc: 0.6471 - val_loss: 6.6170 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6866 - acc: 0.6667 - val_loss: 6.6598 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 452us/step - loss: 0.6686 - acc: 0.6667 - val_loss: 6.6906 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.6540 - acc: 0.6667 - val_loss: 6.7180 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.6419 - acc: 0.6667 - val_loss: 6.7303 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.6316 - acc: 0.6863 - val_loss: 6.7453 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6218 - acc: 0.6667 - val_loss: 6.7650 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 529us/step - loss: 0.6118 - acc: 0.6863 - val_loss: 6.7793 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.6042 - acc: 0.6863 - val_loss: 6.7964 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5969 - acc: 0.6863 - val_loss: 6.8029 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5895 - acc: 0.6863 - val_loss: 6.8162 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5826 - acc: 0.6863 - val_loss: 6.8386 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.5751 - acc: 0.6863 - val_loss: 6.8523 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5693 - acc: 0.6863 - val_loss: 6.8640 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.5646 - acc: 0.6863 - val_loss: 6.8814 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5575 - acc: 0.6863 - val_loss: 6.8879 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 627us/step - loss: 0.5519 - acc: 0.6863 - val_loss: 6.9043 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5451 - acc: 0.6863 - val_loss: 6.9146 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5400 - acc: 0.7059 - val_loss: 6.9342 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.5351 - acc: 0.7059 - val_loss: 6.9364 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5291 - acc: 0.7255 - val_loss: 6.9606 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5224 - acc: 0.7451 - val_loss: 6.9848 - val_acc: 0.5000\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 294us/step - loss: 0.5167 - acc: 0.7451 - val_loss: 6.9929 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5150 - acc: 0.7451 - val_loss: 7.0040 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5104 - acc: 0.7451 - val_loss: 7.0244 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.5042 - acc: 0.7451 - val_loss: 7.0346 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.5003 - acc: 0.7451 - val_loss: 7.0391 - val_acc: 0.5000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 0.4967 - acc: 0.7451 - val_loss: 7.0589 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4904 - acc: 0.7451 - val_loss: 7.0633 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4862 - acc: 0.7451 - val_loss: 7.0921 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4836 - acc: 0.7451 - val_loss: 7.1082 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 292us/step - loss: 0.4786 - acc: 0.7451 - val_loss: 7.1186 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 411us/step - loss: 0.4745 - acc: 0.7451 - val_loss: 7.1280 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4710 - acc: 0.7451 - val_loss: 7.1332 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 188us/step - loss: 0.4668 - acc: 0.7647 - val_loss: 7.1462 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4623 - acc: 0.7647 - val_loss: 7.1552 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.4584 - acc: 0.7647 - val_loss: 7.1662 - val_acc: 0.5000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 568us/step - loss: 0.4558 - acc: 0.7647 - val_loss: 7.1804 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4536 - acc: 0.7647 - val_loss: 7.1967 - val_acc: 0.5000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 299us/step - loss: 0.4496 - acc: 0.7647 - val_loss: 7.2097 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.4445 - acc: 0.7647 - val_loss: 7.2163 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4439 - acc: 0.7647 - val_loss: 7.2285 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 285us/step - loss: 0.4415 - acc: 0.7647 - val_loss: 7.2375 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.4359 - acc: 0.7843 - val_loss: 7.2362 - val_acc: 0.5000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.4336 - acc: 0.7843 - val_loss: 7.2585 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4302 - acc: 0.7843 - val_loss: 7.2740 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4261 - acc: 0.7843 - val_loss: 7.2814 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4235 - acc: 0.8039 - val_loss: 7.2907 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 396us/step - loss: 0.4204 - acc: 0.8235 - val_loss: 7.3054 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4177 - acc: 0.8039 - val_loss: 7.3167 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.4157 - acc: 0.8235 - val_loss: 7.3277 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.4145 - acc: 0.8235 - val_loss: 7.3299 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 486us/step - loss: 0.4090 - acc: 0.8235 - val_loss: 7.3359 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.4079 - acc: 0.8235 - val_loss: 7.3373 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4049 - acc: 0.8235 - val_loss: 7.3423 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 43us/step - loss: 0.4026 - acc: 0.8235 - val_loss: 7.3460 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 313us/step - loss: 0.4013 - acc: 0.8235 - val_loss: 7.3478 - val_acc: 0.5000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 387us/step - loss: 0.3993 - acc: 0.8235 - val_loss: 7.3545 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.3960 - acc: 0.8235 - val_loss: 7.3629 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 156us/step - loss: 0.3948 - acc: 0.8235 - val_loss: 7.3727 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3936 - acc: 0.8235 - val_loss: 7.3755 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 0.3945 - acc: 0.8235 - val_loss: 7.3803 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3887 - acc: 0.8235 - val_loss: 7.3793 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 254us/step - loss: 0.3870 - acc: 0.8235 - val_loss: 7.3845 - val_acc: 0.5000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.3857 - acc: 0.8235 - val_loss: 7.3857 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.3843 - acc: 0.8235 - val_loss: 7.3930 - val_acc: 0.5000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3814 - acc: 0.8235 - val_loss: 7.3974 - val_acc: 0.5000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3811 - acc: 0.8235 - val_loss: 7.3970 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 448us/step - loss: 0.3782 - acc: 0.8235 - val_loss: 7.3998 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 366us/step - loss: 0.3785 - acc: 0.8235 - val_loss: 7.3960 - val_acc: 0.5000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.3746 - acc: 0.8235 - val_loss: 7.4025 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 660us/step - loss: 0.3726 - acc: 0.8235 - val_loss: 7.4052 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 389us/step - loss: 0.3713 - acc: 0.8431 - val_loss: 7.4149 - val_acc: 0.5000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3688 - acc: 0.8431 - val_loss: 7.4234 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 0.3690 - acc: 0.8431 - val_loss: 7.4307 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.3663 - acc: 0.8431 - val_loss: 7.4356 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 595us/step - loss: 0.3655 - acc: 0.8431 - val_loss: 7.4320 - val_acc: 0.5000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3635 - acc: 0.8431 - val_loss: 7.4357 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 729us/step - loss: 0.3611 - acc: 0.8431 - val_loss: 7.4384 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 543us/step - loss: 0.3607 - acc: 0.8431 - val_loss: 7.4396 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 368us/step - loss: 0.3593 - acc: 0.8627 - val_loss: 7.4380 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3566 - acc: 0.8627 - val_loss: 7.4384 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 447us/step - loss: 0.3560 - acc: 0.8431 - val_loss: 7.4434 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 785us/step - loss: 0.3565 - acc: 0.8627 - val_loss: 7.4483 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 445us/step - loss: 0.3526 - acc: 0.8627 - val_loss: 7.4567 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3515 - acc: 0.8627 - val_loss: 7.4584 - val_acc: 0.5000\n",
      "2018-09-05\n",
      "2018-09-06\n",
      "2018-09-07\n",
      "2018-09-10\n",
      "2018-09-11\n",
      "2018-09-12\n",
      "2018-09-13\n",
      "2018-09-14\n",
      "2018-09-17\n",
      "2018-09-18\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 2.4560 - acc: 0.5882 - val_loss: 1.9339 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 239us/step - loss: 2.3996 - acc: 0.6078 - val_loss: 1.8766 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 2.3634 - acc: 0.6078 - val_loss: 1.8362 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 321us/step - loss: 2.3373 - acc: 0.6078 - val_loss: 1.8023 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 2.3189 - acc: 0.6078 - val_loss: 1.7717 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 2.2991 - acc: 0.6078 - val_loss: 1.7183 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 2.2758 - acc: 0.6078 - val_loss: 1.6800 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.2519 - acc: 0.6275 - val_loss: 1.6310 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.2314 - acc: 0.6078 - val_loss: 1.5964 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 677us/step - loss: 2.2162 - acc: 0.6078 - val_loss: 1.5575 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 165us/step - loss: 2.1974 - acc: 0.6078 - val_loss: 1.5124 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 663us/step - loss: 2.1803 - acc: 0.6471 - val_loss: 1.4751 - val_acc: 0.6000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 2.1656 - acc: 0.6275 - val_loss: 1.4473 - val_acc: 0.6000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 500us/step - loss: 2.1512 - acc: 0.6078 - val_loss: 1.4276 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 474us/step - loss: 2.1422 - acc: 0.6275 - val_loss: 1.4048 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 2.1308 - acc: 0.6275 - val_loss: 1.3911 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 2.1277 - acc: 0.6275 - val_loss: 1.3783 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 195us/step - loss: 2.1195 - acc: 0.6275 - val_loss: 1.3539 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 487us/step - loss: 2.1139 - acc: 0.6078 - val_loss: 1.3372 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 2.1088 - acc: 0.6078 - val_loss: 1.3181 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 2.1004 - acc: 0.6078 - val_loss: 1.3066 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 2.0947 - acc: 0.6078 - val_loss: 1.2915 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 2.0886 - acc: 0.6078 - val_loss: 1.2686 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 2.0826 - acc: 0.6078 - val_loss: 1.2561 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 2.0786 - acc: 0.6078 - val_loss: 1.2424 - val_acc: 0.6000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 237us/step - loss: 2.0715 - acc: 0.6275 - val_loss: 1.2284 - val_acc: 0.6000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 2.0642 - acc: 0.6078 - val_loss: 1.2179 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 499us/step - loss: 2.0581 - acc: 0.6471 - val_loss: 1.1989 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 2.0517 - acc: 0.6471 - val_loss: 1.1832 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 455us/step - loss: 2.0468 - acc: 0.6275 - val_loss: 1.1766 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 2.0409 - acc: 0.6471 - val_loss: 1.1579 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 500us/step - loss: 2.0356 - acc: 0.6471 - val_loss: 1.1482 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 455us/step - loss: 2.0326 - acc: 0.6471 - val_loss: 1.1314 - val_acc: 0.7000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 348us/step - loss: 2.0255 - acc: 0.6471 - val_loss: 1.1199 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 2.0180 - acc: 0.6471 - val_loss: 1.0907 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 587us/step - loss: 1.9990 - acc: 0.6471 - val_loss: 1.0626 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.9755 - acc: 0.6471 - val_loss: 1.0389 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 1.9606 - acc: 0.6471 - val_loss: 1.0231 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 564us/step - loss: 1.9445 - acc: 0.6471 - val_loss: 1.0011 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 271us/step - loss: 1.9295 - acc: 0.6471 - val_loss: 0.9801 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.9184 - acc: 0.6471 - val_loss: 0.9690 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.9025 - acc: 0.6471 - val_loss: 0.9480 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 651us/step - loss: 1.8868 - acc: 0.6471 - val_loss: 0.9262 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.8702 - acc: 0.6471 - val_loss: 0.9163 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 1.8578 - acc: 0.6471 - val_loss: 0.9062 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.8463 - acc: 0.6471 - val_loss: 0.8896 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 526us/step - loss: 1.8333 - acc: 0.6471 - val_loss: 0.8706 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 1.8220 - acc: 0.6471 - val_loss: 0.8618 - val_acc: 0.7000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.8085 - acc: 0.6471 - val_loss: 0.8469 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 1.7998 - acc: 0.6471 - val_loss: 0.8350 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 1.7826 - acc: 0.6471 - val_loss: 0.8201 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.7666 - acc: 0.6471 - val_loss: 0.8024 - val_acc: 0.7000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.7484 - acc: 0.6471 - val_loss: 0.7876 - val_acc: 0.7000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.7297 - acc: 0.6667 - val_loss: 0.7720 - val_acc: 0.7000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 343us/step - loss: 1.7158 - acc: 0.6667 - val_loss: 0.7561 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.7021 - acc: 0.6667 - val_loss: 0.7418 - val_acc: 0.7000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.6842 - acc: 0.6667 - val_loss: 0.7292 - val_acc: 0.7000\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 176us/step - loss: 1.6709 - acc: 0.6667 - val_loss: 0.7143 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.6555 - acc: 0.6667 - val_loss: 0.6984 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 1.6344 - acc: 0.6667 - val_loss: 0.6880 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 435us/step - loss: 1.6142 - acc: 0.6667 - val_loss: 0.6749 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.5962 - acc: 0.6667 - val_loss: 0.6618 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.5755 - acc: 0.6667 - val_loss: 0.6484 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 1.5556 - acc: 0.6667 - val_loss: 0.6363 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.5371 - acc: 0.6667 - val_loss: 0.6282 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.5192 - acc: 0.6667 - val_loss: 0.6194 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 186us/step - loss: 1.5005 - acc: 0.6667 - val_loss: 0.6091 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 1.4799 - acc: 0.6667 - val_loss: 0.5990 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.4625 - acc: 0.6667 - val_loss: 0.5921 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 192us/step - loss: 1.4443 - acc: 0.6667 - val_loss: 0.5818 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 553us/step - loss: 1.4284 - acc: 0.6667 - val_loss: 0.5750 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 1.4114 - acc: 0.6863 - val_loss: 0.5659 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.3979 - acc: 0.6667 - val_loss: 0.5597 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.3787 - acc: 0.6863 - val_loss: 0.5507 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 1.3634 - acc: 0.6863 - val_loss: 0.5435 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.3454 - acc: 0.6863 - val_loss: 0.5350 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 334us/step - loss: 1.3265 - acc: 0.6863 - val_loss: 0.5298 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 1.3136 - acc: 0.6863 - val_loss: 0.5224 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 1.2951 - acc: 0.6863 - val_loss: 0.5166 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 1.2829 - acc: 0.6863 - val_loss: 0.5118 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 1.2704 - acc: 0.6863 - val_loss: 0.5067 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.2564 - acc: 0.6863 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 549us/step - loss: 1.2395 - acc: 0.6863 - val_loss: 0.4950 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 1.2241 - acc: 0.6863 - val_loss: 0.4912 - val_acc: 0.7000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 764us/step - loss: 1.2120 - acc: 0.6863 - val_loss: 0.4884 - val_acc: 0.7000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 1.1962 - acc: 0.6863 - val_loss: 0.4864 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 1.1815 - acc: 0.6863 - val_loss: 0.4843 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 1.1680 - acc: 0.6863 - val_loss: 0.4830 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 445us/step - loss: 1.1546 - acc: 0.6863 - val_loss: 0.4798 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.1418 - acc: 0.6863 - val_loss: 0.4793 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 1.1292 - acc: 0.6863 - val_loss: 0.4820 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 79us/step - loss: 1.1127 - acc: 0.6863 - val_loss: 0.4821 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 1.0988 - acc: 0.6863 - val_loss: 0.4822 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 336us/step - loss: 1.0908 - acc: 0.6863 - val_loss: 0.4817 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 1.0781 - acc: 0.6863 - val_loss: 0.4843 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 1.0654 - acc: 0.6863 - val_loss: 0.4856 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 1.0537 - acc: 0.6863 - val_loss: 0.4876 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 1.0425 - acc: 0.7059 - val_loss: 0.4878 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 1.0319 - acc: 0.7059 - val_loss: 0.4895 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 662us/step - loss: 1.0213 - acc: 0.7059 - val_loss: 0.4926 - val_acc: 0.8000\n",
      "2018-09-19\n",
      "2018-09-20\n",
      "2018-09-21\n",
      "2018-09-25\n",
      "2018-09-26\n",
      "2018-09-27\n",
      "2018-09-28\n",
      "2018-10-08\n",
      "2018-10-09\n",
      "2018-10-10\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 2s 40ms/step - loss: 1.1809 - acc: 0.7255 - val_loss: 0.3880 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 1.1130 - acc: 0.7255 - val_loss: 0.4003 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 376us/step - loss: 1.0722 - acc: 0.7451 - val_loss: 0.4068 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 527us/step - loss: 1.0388 - acc: 0.7451 - val_loss: 0.4211 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 521us/step - loss: 1.0073 - acc: 0.7451 - val_loss: 0.4364 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.9833 - acc: 0.7451 - val_loss: 0.4432 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 752us/step - loss: 0.9603 - acc: 0.7451 - val_loss: 0.4463 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.9390 - acc: 0.7451 - val_loss: 0.4590 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.9184 - acc: 0.7451 - val_loss: 0.4714 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.9028 - acc: 0.7451 - val_loss: 0.4835 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 470us/step - loss: 0.8889 - acc: 0.7451 - val_loss: 0.4909 - val_acc: 0.7000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 319us/step - loss: 0.8756 - acc: 0.7451 - val_loss: 0.5053 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.8647 - acc: 0.7451 - val_loss: 0.5153 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.8514 - acc: 0.7451 - val_loss: 0.5261 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 363us/step - loss: 0.8383 - acc: 0.7647 - val_loss: 0.5396 - val_acc: 0.7000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 739us/step - loss: 0.8275 - acc: 0.7647 - val_loss: 0.5558 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 780us/step - loss: 0.8150 - acc: 0.7451 - val_loss: 0.5633 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8032 - acc: 0.7451 - val_loss: 0.5697 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.7920 - acc: 0.7451 - val_loss: 0.5816 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.7812 - acc: 0.7647 - val_loss: 0.5852 - val_acc: 0.7000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.7690 - acc: 0.7647 - val_loss: 0.5926 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.7597 - acc: 0.7647 - val_loss: 0.6084 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.7462 - acc: 0.7647 - val_loss: 0.6158 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 490us/step - loss: 0.7362 - acc: 0.7647 - val_loss: 0.6244 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7252 - acc: 0.7647 - val_loss: 0.6303 - val_acc: 0.7000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 339us/step - loss: 0.7143 - acc: 0.7647 - val_loss: 0.6374 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 180us/step - loss: 0.7065 - acc: 0.7647 - val_loss: 0.6493 - val_acc: 0.7000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 232us/step - loss: 0.7002 - acc: 0.7647 - val_loss: 0.6519 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.6942 - acc: 0.7647 - val_loss: 0.6550 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.6868 - acc: 0.7451 - val_loss: 0.6705 - val_acc: 0.6000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6799 - acc: 0.7255 - val_loss: 0.6854 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6712 - acc: 0.7647 - val_loss: 0.6965 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 424us/step - loss: 0.6631 - acc: 0.7255 - val_loss: 0.7125 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.6566 - acc: 0.7255 - val_loss: 0.7295 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.6475 - acc: 0.7451 - val_loss: 0.7342 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6407 - acc: 0.7451 - val_loss: 0.7445 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6319 - acc: 0.7451 - val_loss: 0.7632 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 270us/step - loss: 0.6244 - acc: 0.7451 - val_loss: 0.7864 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6157 - acc: 0.7451 - val_loss: 0.8020 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 550us/step - loss: 0.6082 - acc: 0.7451 - val_loss: 0.8179 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.6002 - acc: 0.7451 - val_loss: 0.8272 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 657us/step - loss: 0.5939 - acc: 0.7255 - val_loss: 0.8442 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 397us/step - loss: 0.5857 - acc: 0.7255 - val_loss: 0.8560 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 488us/step - loss: 0.5795 - acc: 0.7255 - val_loss: 0.8753 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 0.5711 - acc: 0.7451 - val_loss: 0.8856 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 261us/step - loss: 0.5659 - acc: 0.7255 - val_loss: 0.9019 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 534us/step - loss: 0.5579 - acc: 0.7255 - val_loss: 0.9186 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 381us/step - loss: 0.5496 - acc: 0.7255 - val_loss: 0.9232 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 518us/step - loss: 0.5448 - acc: 0.7255 - val_loss: 0.9346 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 848us/step - loss: 0.5376 - acc: 0.7255 - val_loss: 0.9471 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5328 - acc: 0.7255 - val_loss: 0.9509 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 248us/step - loss: 0.5253 - acc: 0.7255 - val_loss: 0.9620 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5201 - acc: 0.7255 - val_loss: 0.9782 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.5154 - acc: 0.7255 - val_loss: 0.9920 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 460us/step - loss: 0.5085 - acc: 0.7255 - val_loss: 1.0133 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 378us/step - loss: 0.5016 - acc: 0.7255 - val_loss: 1.0092 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4947 - acc: 0.7255 - val_loss: 1.0081 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4864 - acc: 0.7255 - val_loss: 1.0183 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 652us/step - loss: 0.4813 - acc: 0.7255 - val_loss: 1.0378 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 300us/step - loss: 0.4771 - acc: 0.7255 - val_loss: 1.0404 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 350us/step - loss: 0.4722 - acc: 0.7451 - val_loss: 1.0513 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4666 - acc: 0.7451 - val_loss: 1.0662 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 532us/step - loss: 0.4615 - acc: 0.7451 - val_loss: 1.0738 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4576 - acc: 0.7451 - val_loss: 1.0822 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 206us/step - loss: 0.4517 - acc: 0.7451 - val_loss: 1.0967 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.4459 - acc: 0.7451 - val_loss: 1.1110 - val_acc: 0.2000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.4411 - acc: 0.7451 - val_loss: 1.1168 - val_acc: 0.2000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 580us/step - loss: 0.4388 - acc: 0.7647 - val_loss: 1.1155 - val_acc: 0.2000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 182us/step - loss: 0.4342 - acc: 0.7451 - val_loss: 1.1164 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 400us/step - loss: 0.4307 - acc: 0.7647 - val_loss: 1.1315 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 740us/step - loss: 0.4247 - acc: 0.7647 - val_loss: 1.1315 - val_acc: 0.2000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4209 - acc: 0.7647 - val_loss: 1.1400 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.4172 - acc: 0.7647 - val_loss: 1.1391 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 829us/step - loss: 0.4173 - acc: 0.7647 - val_loss: 1.1444 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.4133 - acc: 0.7647 - val_loss: 1.1441 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 89us/step - loss: 0.4100 - acc: 0.7451 - val_loss: 1.1367 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.4064 - acc: 0.7451 - val_loss: 1.1323 - val_acc: 0.2000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 243us/step - loss: 0.4048 - acc: 0.7451 - val_loss: 1.1434 - val_acc: 0.2000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 167us/step - loss: 0.4005 - acc: 0.7647 - val_loss: 1.1458 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 344us/step - loss: 0.3983 - acc: 0.7647 - val_loss: 1.1434 - val_acc: 0.2000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 563us/step - loss: 0.3966 - acc: 0.7451 - val_loss: 1.1564 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 546us/step - loss: 0.3942 - acc: 0.7647 - val_loss: 1.1645 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3932 - acc: 0.7647 - val_loss: 1.1670 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3918 - acc: 0.7647 - val_loss: 1.1598 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3893 - acc: 0.7647 - val_loss: 1.1524 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3875 - acc: 0.7647 - val_loss: 1.1528 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 236us/step - loss: 0.3846 - acc: 0.7647 - val_loss: 1.1589 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3837 - acc: 0.7647 - val_loss: 1.1714 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 725us/step - loss: 0.3806 - acc: 0.7647 - val_loss: 1.1757 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 718us/step - loss: 0.3798 - acc: 0.7647 - val_loss: 1.1843 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 432us/step - loss: 0.3787 - acc: 0.7647 - val_loss: 1.1849 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 417us/step - loss: 0.3756 - acc: 0.7843 - val_loss: 1.1882 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 413us/step - loss: 0.3760 - acc: 0.7843 - val_loss: 1.1768 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 341us/step - loss: 0.3763 - acc: 0.7843 - val_loss: 1.1674 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 217us/step - loss: 0.3704 - acc: 0.7843 - val_loss: 1.1672 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3703 - acc: 0.7843 - val_loss: 1.1636 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.3690 - acc: 0.7647 - val_loss: 1.1784 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.3664 - acc: 0.7843 - val_loss: 1.1778 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.3633 - acc: 0.7843 - val_loss: 1.1790 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3625 - acc: 0.7843 - val_loss: 1.1858 - val_acc: 0.2000\n",
      "2018-10-11\n",
      "2018-10-12\n",
      "2018-10-15\n",
      "2018-10-16\n",
      "2018-10-17\n",
      "2018-10-18\n",
      "2018-10-19\n",
      "2018-10-22\n",
      "2018-10-23\n",
      "2018-10-24\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1138 - acc: 0.4902 - val_loss: 1.0784 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 1.0446 - acc: 0.5098 - val_loss: 1.0878 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.9999 - acc: 0.4902 - val_loss: 1.0991 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.9658 - acc: 0.5098 - val_loss: 1.1097 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 412us/step - loss: 0.9318 - acc: 0.5098 - val_loss: 1.1173 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 392us/step - loss: 0.9086 - acc: 0.5098 - val_loss: 1.1181 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.8858 - acc: 0.5490 - val_loss: 1.1327 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8693 - acc: 0.5490 - val_loss: 1.1434 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 234us/step - loss: 0.8490 - acc: 0.5686 - val_loss: 1.1584 - val_acc: 0.1000\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.8312 - acc: 0.5686 - val_loss: 1.1674 - val_acc: 0.1000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.8157 - acc: 0.6078 - val_loss: 1.1817 - val_acc: 0.1000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.7994 - acc: 0.6078 - val_loss: 1.1962 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 370us/step - loss: 0.7820 - acc: 0.6078 - val_loss: 1.2064 - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 312us/step - loss: 0.7673 - acc: 0.6078 - val_loss: 1.2145 - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 349us/step - loss: 0.7547 - acc: 0.6275 - val_loss: 1.2293 - val_acc: 0.1000\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 278us/step - loss: 0.7372 - acc: 0.6275 - val_loss: 1.2403 - val_acc: 0.1000\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.7237 - acc: 0.6275 - val_loss: 1.2501 - val_acc: 0.1000\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.7120 - acc: 0.6275 - val_loss: 1.2666 - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 197us/step - loss: 0.6983 - acc: 0.6275 - val_loss: 1.2819 - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 157us/step - loss: 0.6866 - acc: 0.6275 - val_loss: 1.2981 - val_acc: 0.1000\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 489us/step - loss: 0.6746 - acc: 0.6275 - val_loss: 1.3139 - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 458us/step - loss: 0.6621 - acc: 0.6471 - val_loss: 1.3299 - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 69us/step - loss: 0.6504 - acc: 0.6471 - val_loss: 1.3390 - val_acc: 0.1000\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 138us/step - loss: 0.6400 - acc: 0.6667 - val_loss: 1.3477 - val_acc: 0.1000\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.6299 - acc: 0.6667 - val_loss: 1.3607 - val_acc: 0.1000\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 98us/step - loss: 0.6191 - acc: 0.6667 - val_loss: 1.3739 - val_acc: 0.1000\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.6101 - acc: 0.6667 - val_loss: 1.3791 - val_acc: 0.1000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 372us/step - loss: 0.5997 - acc: 0.6863 - val_loss: 1.3846 - val_acc: 0.1000\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.5896 - acc: 0.6863 - val_loss: 1.3903 - val_acc: 0.1000\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.5813 - acc: 0.7059 - val_loss: 1.3884 - val_acc: 0.1000\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5774 - acc: 0.7059 - val_loss: 1.3932 - val_acc: 0.1000\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.5656 - acc: 0.7059 - val_loss: 1.3924 - val_acc: 0.1000\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.5594 - acc: 0.7059 - val_loss: 1.3946 - val_acc: 0.1000\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.5525 - acc: 0.7255 - val_loss: 1.3927 - val_acc: 0.1000\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 327us/step - loss: 0.5463 - acc: 0.7255 - val_loss: 1.3938 - val_acc: 0.1000\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 0.5438 - acc: 0.7255 - val_loss: 1.3978 - val_acc: 0.1000\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5346 - acc: 0.7255 - val_loss: 1.3993 - val_acc: 0.1000\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 251us/step - loss: 0.5282 - acc: 0.7451 - val_loss: 1.4028 - val_acc: 0.1000\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 302us/step - loss: 0.5206 - acc: 0.7451 - val_loss: 1.4061 - val_acc: 0.1000\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5141 - acc: 0.7451 - val_loss: 1.4072 - val_acc: 0.1000\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5081 - acc: 0.7451 - val_loss: 1.4108 - val_acc: 0.1000\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.5035 - acc: 0.7647 - val_loss: 1.4122 - val_acc: 0.1000\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 207us/step - loss: 0.4967 - acc: 0.7647 - val_loss: 1.4167 - val_acc: 0.1000\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 458us/step - loss: 0.4919 - acc: 0.7451 - val_loss: 1.4205 - val_acc: 0.1000\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.4850 - acc: 0.7647 - val_loss: 1.4238 - val_acc: 0.1000\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4832 - acc: 0.7647 - val_loss: 1.4279 - val_acc: 0.1000\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 264us/step - loss: 0.4755 - acc: 0.7451 - val_loss: 1.4277 - val_acc: 0.1000\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 413us/step - loss: 0.4693 - acc: 0.7843 - val_loss: 1.4302 - val_acc: 0.1000\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 383us/step - loss: 0.4645 - acc: 0.7843 - val_loss: 1.4302 - val_acc: 0.1000\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4595 - acc: 0.7647 - val_loss: 1.4320 - val_acc: 0.1000\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 312us/step - loss: 0.4536 - acc: 0.8039 - val_loss: 1.4298 - val_acc: 0.1000\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 385us/step - loss: 0.4518 - acc: 0.7647 - val_loss: 1.4322 - val_acc: 0.1000\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 266us/step - loss: 0.4449 - acc: 0.8039 - val_loss: 1.4370 - val_acc: 0.1000\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 233us/step - loss: 0.4404 - acc: 0.8039 - val_loss: 1.4356 - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4367 - acc: 0.8039 - val_loss: 1.4352 - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4324 - acc: 0.8039 - val_loss: 1.4353 - val_acc: 0.1000\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 274us/step - loss: 0.4283 - acc: 0.8431 - val_loss: 1.4388 - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.4238 - acc: 0.8431 - val_loss: 1.4347 - val_acc: 0.1000\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 208us/step - loss: 0.4195 - acc: 0.8235 - val_loss: 1.4370 - val_acc: 0.1000\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 425us/step - loss: 0.4163 - acc: 0.8235 - val_loss: 1.4358 - val_acc: 0.1000\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.4119 - acc: 0.8235 - val_loss: 1.4337 - val_acc: 0.1000\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.4074 - acc: 0.8235 - val_loss: 1.4364 - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 510us/step - loss: 0.4033 - acc: 0.8235 - val_loss: 1.4311 - val_acc: 0.1000\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 177us/step - loss: 0.3993 - acc: 0.8235 - val_loss: 1.4290 - val_acc: 0.1000\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 356us/step - loss: 0.3964 - acc: 0.8039 - val_loss: 1.4342 - val_acc: 0.1000\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 297us/step - loss: 0.3919 - acc: 0.8431 - val_loss: 1.4311 - val_acc: 0.1000\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3890 - acc: 0.8431 - val_loss: 1.4361 - val_acc: 0.1000\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3859 - acc: 0.8627 - val_loss: 1.4336 - val_acc: 0.1000\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 369us/step - loss: 0.3811 - acc: 0.8627 - val_loss: 1.4296 - val_acc: 0.1000\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 378us/step - loss: 0.3777 - acc: 0.8627 - val_loss: 1.4262 - val_acc: 0.1000\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 522us/step - loss: 0.3746 - acc: 0.8627 - val_loss: 1.4302 - val_acc: 0.1000\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.3723 - acc: 0.8431 - val_loss: 1.4272 - val_acc: 0.1000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 388us/step - loss: 0.3680 - acc: 0.8431 - val_loss: 1.4249 - val_acc: 0.1000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3660 - acc: 0.8235 - val_loss: 1.4314 - val_acc: 0.1000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3611 - acc: 0.8627 - val_loss: 1.4339 - val_acc: 0.1000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3582 - acc: 0.8627 - val_loss: 1.4307 - val_acc: 0.1000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.3551 - acc: 0.8627 - val_loss: 1.4295 - val_acc: 0.1000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 158us/step - loss: 0.3519 - acc: 0.8627 - val_loss: 1.4337 - val_acc: 0.1000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 725us/step - loss: 0.3488 - acc: 0.8824 - val_loss: 1.4313 - val_acc: 0.1000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3467 - acc: 0.8824 - val_loss: 1.4306 - val_acc: 0.1000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 395us/step - loss: 0.3424 - acc: 0.8824 - val_loss: 1.4384 - val_acc: 0.1000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 291us/step - loss: 0.3397 - acc: 0.8824 - val_loss: 1.4334 - val_acc: 0.1000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 569us/step - loss: 0.3367 - acc: 0.8824 - val_loss: 1.4415 - val_acc: 0.1000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 628us/step - loss: 0.3341 - acc: 0.8824 - val_loss: 1.4370 - val_acc: 0.1000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 417us/step - loss: 0.3315 - acc: 0.8824 - val_loss: 1.4315 - val_acc: 0.1000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3281 - acc: 0.8824 - val_loss: 1.4346 - val_acc: 0.1000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 467us/step - loss: 0.3287 - acc: 0.9020 - val_loss: 1.4308 - val_acc: 0.1000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 451us/step - loss: 0.3234 - acc: 0.9020 - val_loss: 1.4339 - val_acc: 0.1000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 361us/step - loss: 0.3252 - acc: 0.9020 - val_loss: 1.4303 - val_acc: 0.1000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3197 - acc: 0.9020 - val_loss: 1.4305 - val_acc: 0.1000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3167 - acc: 0.9020 - val_loss: 1.4246 - val_acc: 0.1000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3152 - acc: 0.9020 - val_loss: 1.4183 - val_acc: 0.1000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3143 - acc: 0.9020 - val_loss: 1.4159 - val_acc: 0.1000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 167us/step - loss: 0.3095 - acc: 0.9020 - val_loss: 1.4098 - val_acc: 0.1000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 317us/step - loss: 0.3081 - acc: 0.9020 - val_loss: 1.4146 - val_acc: 0.1000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.3071 - acc: 0.9020 - val_loss: 1.4088 - val_acc: 0.1000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.3042 - acc: 0.8824 - val_loss: 1.4033 - val_acc: 0.1000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3048 - acc: 0.8824 - val_loss: 1.3990 - val_acc: 0.1000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3000 - acc: 0.9020 - val_loss: 1.3896 - val_acc: 0.1000\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 484us/step - loss: 0.2988 - acc: 0.8824 - val_loss: 1.3922 - val_acc: 0.1000\n",
      "2018-10-25\n",
      "2018-10-26\n",
      "2018-10-29\n",
      "2018-10-30\n",
      "2018-10-31\n",
      "2018-11-01\n",
      "2018-11-02\n",
      "2018-11-05\n",
      "2018-11-06\n",
      "2018-11-07\n",
      "Train on 51 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8248 - acc: 0.5686 - val_loss: 1.3978 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 221us/step - loss: 0.7782 - acc: 0.5882 - val_loss: 1.3994 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 228us/step - loss: 0.7549 - acc: 0.6471 - val_loss: 1.3959 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 430us/step - loss: 0.7346 - acc: 0.6471 - val_loss: 1.3871 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.7195 - acc: 0.6471 - val_loss: 1.3817 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 436us/step - loss: 0.7078 - acc: 0.6471 - val_loss: 1.3757 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.6939 - acc: 0.6471 - val_loss: 1.3724 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 346us/step - loss: 0.6833 - acc: 0.6471 - val_loss: 1.3717 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 187us/step - loss: 0.6703 - acc: 0.6471 - val_loss: 1.3654 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 227us/step - loss: 0.6600 - acc: 0.6667 - val_loss: 1.3565 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.6486 - acc: 0.6863 - val_loss: 1.3509 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 421us/step - loss: 0.6383 - acc: 0.7059 - val_loss: 1.3456 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 386us/step - loss: 0.6266 - acc: 0.7059 - val_loss: 1.3433 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 219us/step - loss: 0.6165 - acc: 0.7255 - val_loss: 1.3353 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 374us/step - loss: 0.6041 - acc: 0.7255 - val_loss: 1.3309 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.5938 - acc: 0.7451 - val_loss: 1.3294 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 49us/step - loss: 0.5842 - acc: 0.7451 - val_loss: 1.3290 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.5753 - acc: 0.7451 - val_loss: 1.3255 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.5655 - acc: 0.7451 - val_loss: 1.3166 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 540us/step - loss: 0.5553 - acc: 0.7451 - val_loss: 1.3122 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 444us/step - loss: 0.5448 - acc: 0.7451 - val_loss: 1.3067 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.5357 - acc: 0.7451 - val_loss: 1.2979 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 176us/step - loss: 0.5268 - acc: 0.7451 - val_loss: 1.2926 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 295us/step - loss: 0.5202 - acc: 0.7647 - val_loss: 1.2872 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 319us/step - loss: 0.5130 - acc: 0.7647 - val_loss: 1.2858 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 213us/step - loss: 0.5059 - acc: 0.7843 - val_loss: 1.2834 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 302us/step - loss: 0.4980 - acc: 0.7843 - val_loss: 1.2749 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.4914 - acc: 0.7843 - val_loss: 1.2717 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 556us/step - loss: 0.4841 - acc: 0.7843 - val_loss: 1.2655 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 292us/step - loss: 0.4792 - acc: 0.8039 - val_loss: 1.2594 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 323us/step - loss: 0.4723 - acc: 0.8039 - val_loss: 1.2540 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 655us/step - loss: 0.4660 - acc: 0.8235 - val_loss: 1.2473 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4599 - acc: 0.8235 - val_loss: 1.2492 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 643us/step - loss: 0.4524 - acc: 0.8235 - val_loss: 1.2439 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.4469 - acc: 0.8235 - val_loss: 1.2445 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 607us/step - loss: 0.4410 - acc: 0.8431 - val_loss: 1.2410 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 226us/step - loss: 0.4355 - acc: 0.8431 - val_loss: 1.2377 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 240us/step - loss: 0.4305 - acc: 0.8431 - val_loss: 1.2357 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 283us/step - loss: 0.4244 - acc: 0.8431 - val_loss: 1.2369 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 532us/step - loss: 0.4197 - acc: 0.8431 - val_loss: 1.2381 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 746us/step - loss: 0.4134 - acc: 0.8431 - val_loss: 1.2307 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.4114 - acc: 0.8431 - val_loss: 1.2344 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 258us/step - loss: 0.4022 - acc: 0.8431 - val_loss: 1.2313 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 471us/step - loss: 0.3968 - acc: 0.8431 - val_loss: 1.2280 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 307us/step - loss: 0.3920 - acc: 0.8431 - val_loss: 1.2264 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 399us/step - loss: 0.3878 - acc: 0.8431 - val_loss: 1.2212 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 190us/step - loss: 0.3837 - acc: 0.8431 - val_loss: 1.2216 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 246us/step - loss: 0.3813 - acc: 0.8431 - val_loss: 1.2161 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.3744 - acc: 0.8627 - val_loss: 1.2175 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 548us/step - loss: 0.3706 - acc: 0.8627 - val_loss: 1.2143 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 315us/step - loss: 0.3678 - acc: 0.8627 - val_loss: 1.2083 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 554us/step - loss: 0.3621 - acc: 0.8627 - val_loss: 1.2077 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 219us/step - loss: 0.3591 - acc: 0.8627 - val_loss: 1.2061 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 215us/step - loss: 0.3536 - acc: 0.8627 - val_loss: 1.2113 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3503 - acc: 0.8627 - val_loss: 1.2112 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.3469 - acc: 0.8627 - val_loss: 1.2120 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 321us/step - loss: 0.3430 - acc: 0.8627 - val_loss: 1.2055 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.3379 - acc: 0.8627 - val_loss: 1.1976 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 333us/step - loss: 0.3343 - acc: 0.8627 - val_loss: 1.1928 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 314us/step - loss: 0.3310 - acc: 0.8627 - val_loss: 1.1867 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 250us/step - loss: 0.3291 - acc: 0.8627 - val_loss: 1.1817 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3241 - acc: 0.8627 - val_loss: 1.1825 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 353us/step - loss: 0.3238 - acc: 0.8824 - val_loss: 1.1761 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 211us/step - loss: 0.3176 - acc: 0.8824 - val_loss: 1.1747 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.3144 - acc: 0.8824 - val_loss: 1.1723 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 377us/step - loss: 0.3101 - acc: 0.8824 - val_loss: 1.1739 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3093 - acc: 0.8824 - val_loss: 1.1666 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 249us/step - loss: 0.3037 - acc: 0.8824 - val_loss: 1.1632 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.3021 - acc: 0.8824 - val_loss: 1.1643 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 306us/step - loss: 0.2986 - acc: 0.8824 - val_loss: 1.1600 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2938 - acc: 0.8824 - val_loss: 1.1595 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2908 - acc: 0.8824 - val_loss: 1.1573 - val_acc: 0.1000\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2870 - acc: 0.8824 - val_loss: 1.1536 - val_acc: 0.1000\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2852 - acc: 0.8824 - val_loss: 1.1553 - val_acc: 0.1000\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 275us/step - loss: 0.2818 - acc: 0.8824 - val_loss: 1.1464 - val_acc: 0.1000\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2788 - acc: 0.8824 - val_loss: 1.1397 - val_acc: 0.1000\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2751 - acc: 0.8824 - val_loss: 1.1351 - val_acc: 0.1000\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 294us/step - loss: 0.2721 - acc: 0.8824 - val_loss: 1.1382 - val_acc: 0.1000\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 292us/step - loss: 0.2685 - acc: 0.8824 - val_loss: 1.1288 - val_acc: 0.1000\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 473us/step - loss: 0.2655 - acc: 0.8824 - val_loss: 1.1341 - val_acc: 0.1000\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2613 - acc: 0.8824 - val_loss: 1.1307 - val_acc: 0.1000\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 216us/step - loss: 0.2579 - acc: 0.8824 - val_loss: 1.1313 - val_acc: 0.1000\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 183us/step - loss: 0.2543 - acc: 0.8824 - val_loss: 1.1263 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 406us/step - loss: 0.2518 - acc: 0.8824 - val_loss: 1.1175 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2494 - acc: 0.8824 - val_loss: 1.1164 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 431us/step - loss: 0.2454 - acc: 0.8824 - val_loss: 1.1140 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 255us/step - loss: 0.2447 - acc: 0.9020 - val_loss: 1.1043 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 235us/step - loss: 0.2397 - acc: 0.9216 - val_loss: 1.1036 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 382us/step - loss: 0.2366 - acc: 0.9216 - val_loss: 1.1001 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2338 - acc: 0.9216 - val_loss: 1.0968 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 416us/step - loss: 0.2335 - acc: 0.9216 - val_loss: 1.0887 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 404us/step - loss: 0.2296 - acc: 0.9216 - val_loss: 1.0860 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 196us/step - loss: 0.2273 - acc: 0.9216 - val_loss: 1.0794 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 265us/step - loss: 0.2247 - acc: 0.9216 - val_loss: 1.0781 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 375us/step - loss: 0.2216 - acc: 0.9216 - val_loss: 1.0727 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 404us/step - loss: 0.2197 - acc: 0.9216 - val_loss: 1.0694 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 249us/step - loss: 0.2165 - acc: 0.9216 - val_loss: 1.0634 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 219us/step - loss: 0.2144 - acc: 0.9216 - val_loss: 1.0561 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 203us/step - loss: 0.2131 - acc: 0.9020 - val_loss: 1.0636 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 0us/step - loss: 0.2106 - acc: 0.9216 - val_loss: 1.0634 - val_acc: 0.2000\n",
      "2018-11-08\n",
      "2018-11-09\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for j, date in enumerate(datelist):\n",
    "    print(date)\n",
    "    if j < days+valid_num:\n",
    "        continue\n",
    "    # 滚动样本\n",
    "    X = data.loc[j - days - valid_num: j, factorlist]\n",
    "    # y_raw = data.loc[j - days + 1: j, 'PCT_CHG']\n",
    "    y_raw = data.loc[j - days - valid_num: j, 'CLOSE_CHG_1']\n",
    "    # 延长样本\n",
    "    # X = model.loc[:j-1, 'ADTM':'SI']\n",
    "    # y_raw = model.loc[1:j-1, 'PCT_CHG']\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    quantile_30 = y_raw.quantile(0.3)\n",
    "    quantile_70 = y_raw.quantile(0.7)\n",
    "\n",
    "\n",
    "    def _get_label(x):\n",
    "        if x >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    y = y_raw.apply(lambda x: _get_label(x)).values\n",
    "\n",
    "    # 主成分分析\n",
    "    pca = PCA(n_components=7)\n",
    "    pca.fit(X)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    # 转变数据类型\n",
    "    train_x, train_y, valid_x, valid_y = interstra.transform_data(X, y, time_step, valid_num)\n",
    "\n",
    "    # 模型训练和预测\n",
    "    # train_lstm(train_x,train_y,time_step)\n",
    "    if (j-(days+valid_num)) % valid_num == 0:  # 受限于计算速度，这里每20天更新下模型\n",
    "        interstra.train_lstm(train_x, train_y, valid_x, valid_y)\n",
    "    predict2 = interstra.prediction(valid_x[:1, :])\n",
    "\n",
    "    ## 结果输出\n",
    "    pnl.loc[j-valid_num, 'y'] = data.loc[j-valid_num, 'CLOSE_CHG_7']\n",
    "    pnl.loc[j-valid_num, 'yhat_lstm'] = np.argmax(predict2[0])-1\n",
    "    pnl.loc[j-valid_num, 'yhat_lstm_0'] = predict2[0, 0]\n",
    "    pnl.loc[j-valid_num, 'yhat_lstm_1'] = predict2[0, 1]\n",
    "    # print(date, metrics.accuracy_score(y[time_step - 1:], sample_yhat - 1), predict2)\n",
    "\n",
    "# pnl = pnl.loc[days + 1:, ]\n",
    "pnl.set_index([\"date\"], inplace=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pnl = pnl.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat_lstm</th>\n",
       "      <th>yhat_lstm_0</th>\n",
       "      <th>yhat_lstm_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-24</th>\n",
       "      <td>0.253108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260545</td>\n",
       "      <td>0.739455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-25</th>\n",
       "      <td>0.138903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.752588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>0.074396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316883</td>\n",
       "      <td>0.683117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>0.262786</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.538429</td>\n",
       "      <td>0.461571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>0.039596</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.597575</td>\n",
       "      <td>0.402425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>-0.074230</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.662330</td>\n",
       "      <td>0.337670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>-0.267658</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.617679</td>\n",
       "      <td>0.382321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>-0.630353</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.666605</td>\n",
       "      <td>0.333395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>-0.238202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414231</td>\n",
       "      <td>0.585769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>-0.148832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311722</td>\n",
       "      <td>0.688278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>-0.133952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.737241</td>\n",
       "      <td>0.262759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>-0.436704</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.724025</td>\n",
       "      <td>0.275975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>-0.515977</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.901901</td>\n",
       "      <td>0.098099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>-0.416709</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.853284</td>\n",
       "      <td>0.146716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>-0.362977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112469</td>\n",
       "      <td>0.887531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>0.164175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116682</td>\n",
       "      <td>0.883318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>-0.094445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109061</td>\n",
       "      <td>0.890940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-19</th>\n",
       "      <td>-0.039726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.858696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-20</th>\n",
       "      <td>-0.114249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404979</td>\n",
       "      <td>0.595021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>0.293000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.580863</td>\n",
       "      <td>0.419137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>0.357498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472828</td>\n",
       "      <td>0.527172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-25</th>\n",
       "      <td>0.322605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427045</td>\n",
       "      <td>0.572955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-26</th>\n",
       "      <td>0.541495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401839</td>\n",
       "      <td>0.598161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-27</th>\n",
       "      <td>0.540368</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.707640</td>\n",
       "      <td>0.292360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-28</th>\n",
       "      <td>0.634545</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.722077</td>\n",
       "      <td>0.277923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-29</th>\n",
       "      <td>0.421283</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.785210</td>\n",
       "      <td>0.214790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-03</th>\n",
       "      <td>0.599591</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>0.020204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-04</th>\n",
       "      <td>0.331692</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.979792</td>\n",
       "      <td>0.020208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-05</th>\n",
       "      <td>0.148581</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.960779</td>\n",
       "      <td>0.039221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-06</th>\n",
       "      <td>0.113904</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.974861</td>\n",
       "      <td>0.025139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-07</th>\n",
       "      <td>-0.117795</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.248544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-10</th>\n",
       "      <td>-0.194862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069716</td>\n",
       "      <td>0.930284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11</th>\n",
       "      <td>-0.374676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.986773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12</th>\n",
       "      <td>-0.194862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143567</td>\n",
       "      <td>0.856433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13</th>\n",
       "      <td>-0.179464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.995512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-14</th>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235994</td>\n",
       "      <td>0.764006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>0.138224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250855</td>\n",
       "      <td>0.749145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-18</th>\n",
       "      <td>0.097224</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.751840</td>\n",
       "      <td>0.248160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19</th>\n",
       "      <td>0.168967</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.915936</td>\n",
       "      <td>0.084064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20</th>\n",
       "      <td>0.409795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087508</td>\n",
       "      <td>0.912492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>0.630496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419390</td>\n",
       "      <td>0.580610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-25</th>\n",
       "      <td>0.665066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-26</th>\n",
       "      <td>0.639470</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>0.403876</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.532605</td>\n",
       "      <td>0.467395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>0.342177</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.920642</td>\n",
       "      <td>0.079358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-08</th>\n",
       "      <td>0.255402</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.881087</td>\n",
       "      <td>0.118913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-09</th>\n",
       "      <td>0.398244</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.087581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-10</th>\n",
       "      <td>0.275665</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.729533</td>\n",
       "      <td>0.270467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11</th>\n",
       "      <td>0.127665</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.701939</td>\n",
       "      <td>0.298061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-12</th>\n",
       "      <td>0.025491</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.715998</td>\n",
       "      <td>0.284002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>0.107031</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.724890</td>\n",
       "      <td>0.275109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-16</th>\n",
       "      <td>0.193690</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>0.190133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>0.132471</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>0.190133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-18</th>\n",
       "      <td>0.371719</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>0.190133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19</th>\n",
       "      <td>0.229037</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.661958</td>\n",
       "      <td>0.338042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-22</th>\n",
       "      <td>0.290158</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.563417</td>\n",
       "      <td>0.436583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-23</th>\n",
       "      <td>0.422683</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.559079</td>\n",
       "      <td>0.440921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-24</th>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414131</td>\n",
       "      <td>0.585869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25</th>\n",
       "      <td>0.035652</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.593747</td>\n",
       "      <td>0.406253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-26</th>\n",
       "      <td>0.188233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474946</td>\n",
       "      <td>0.525054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y  yhat_lstm  yhat_lstm_0  yhat_lstm_1\n",
       "date                                                     \n",
       "2016-03-24  0.253108        0.0     0.260545     0.739455\n",
       "2016-03-25  0.138903        0.0     0.247412     0.752588\n",
       "2016-03-28  0.074396        0.0     0.316883     0.683117\n",
       "2016-03-29  0.262786       -1.0     0.538429     0.461571\n",
       "2016-03-30  0.039596       -1.0     0.597575     0.402425\n",
       "2016-03-31 -0.074230       -1.0     0.662330     0.337670\n",
       "2016-04-01 -0.267658       -1.0     0.617679     0.382321\n",
       "2016-04-05 -0.630353       -1.0     0.666605     0.333395\n",
       "2016-04-06 -0.238202        0.0     0.414231     0.585769\n",
       "2016-04-07 -0.148832        0.0     0.311722     0.688278\n",
       "2016-04-08 -0.133952       -1.0     0.737241     0.262759\n",
       "2016-04-11 -0.436704       -1.0     0.724025     0.275975\n",
       "2016-04-12 -0.515977       -1.0     0.901901     0.098099\n",
       "2016-04-13 -0.416709       -1.0     0.853284     0.146716\n",
       "2016-04-14 -0.362977        0.0     0.112469     0.887531\n",
       "2016-04-15  0.164175        0.0     0.116682     0.883318\n",
       "2016-04-18 -0.094445        0.0     0.109061     0.890940\n",
       "2016-04-19 -0.039726        0.0     0.141304     0.858696\n",
       "2016-04-20 -0.114249        0.0     0.404979     0.595021\n",
       "2016-04-21  0.293000       -1.0     0.580863     0.419137\n",
       "2016-04-22  0.357498        0.0     0.472828     0.527172\n",
       "2016-04-25  0.322605        0.0     0.427045     0.572955\n",
       "2016-04-26  0.541495        0.0     0.401839     0.598161\n",
       "2016-04-27  0.540368       -1.0     0.707640     0.292360\n",
       "2016-04-28  0.634545       -1.0     0.722077     0.277923\n",
       "2016-04-29  0.421283       -1.0     0.785210     0.214790\n",
       "2016-05-03  0.599591       -1.0     0.979796     0.020204\n",
       "2016-05-04  0.331692       -1.0     0.979792     0.020208\n",
       "2016-05-05  0.148581       -1.0     0.960779     0.039221\n",
       "2016-05-06  0.113904       -1.0     0.974861     0.025139\n",
       "...              ...        ...          ...          ...\n",
       "2018-09-07 -0.117795       -1.0     0.751456     0.248544\n",
       "2018-09-10 -0.194862        0.0     0.069716     0.930284\n",
       "2018-09-11 -0.374676        0.0     0.013227     0.986773\n",
       "2018-09-12 -0.194862        0.0     0.143567     0.856433\n",
       "2018-09-13 -0.179464        0.0     0.004488     0.995512\n",
       "2018-09-14  0.005123        0.0     0.235994     0.764006\n",
       "2018-09-17  0.138224        0.0     0.250855     0.749145\n",
       "2018-09-18  0.097224       -1.0     0.751840     0.248160\n",
       "2018-09-19  0.168967       -1.0     0.915936     0.084064\n",
       "2018-09-20  0.409795        0.0     0.087508     0.912492\n",
       "2018-09-21  0.630496        0.0     0.419390     0.580610\n",
       "2018-09-25  0.665066       -1.0     0.681900     0.318100\n",
       "2018-09-26  0.639470       -1.0     0.804878     0.195122\n",
       "2018-09-27  0.403876       -1.0     0.532605     0.467395\n",
       "2018-09-28  0.342177       -1.0     0.920642     0.079358\n",
       "2018-10-08  0.255402       -1.0     0.881087     0.118913\n",
       "2018-10-09  0.398244       -1.0     0.912419     0.087581\n",
       "2018-10-10  0.275665       -1.0     0.729533     0.270467\n",
       "2018-10-11  0.127665       -1.0     0.701939     0.298061\n",
       "2018-10-12  0.025491       -1.0     0.715998     0.284002\n",
       "2018-10-15  0.107031       -1.0     0.724890     0.275109\n",
       "2018-10-16  0.193690       -1.0     0.809867     0.190133\n",
       "2018-10-17  0.132471       -1.0     0.809867     0.190133\n",
       "2018-10-18  0.371719       -1.0     0.809867     0.190133\n",
       "2018-10-19  0.229037       -1.0     0.661958     0.338042\n",
       "2018-10-22  0.290158       -1.0     0.563417     0.436583\n",
       "2018-10-23  0.422683       -1.0     0.559079     0.440921\n",
       "2018-10-24  0.045868        0.0     0.414131     0.585869\n",
       "2018-10-25  0.035652       -1.0     0.593747     0.406253\n",
       "2018-10-26  0.188233        0.0     0.474946     0.525054\n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl.index = pd.to_datetime(list(map(str,pnl.index.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27e9ec5e9e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnl[['yhat_lstm_1','y']].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_yhat = pnl[['yhat_lstm_0','yhat_lstm_1']].values\n",
    "y_raw = pnl.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(y_raw[sample_yhat.argmax(axis=1)==1],color=\"r\",bins=30,kde=True)\n",
    "sns.distplot(y_raw[sample_yhat.argmax(axis=1)==0],color=\"b\",bins=30,kde=True)\n",
    "plt.savefig(\"HIGH_CHG_7\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import model.DataReg as DR\n",
    "# reload(model.DataReg)\n",
    "dr = DR.DataReg()\n",
    "x0,ks = dr.plotROC(sample_yhat[:,1],pnl.y.apply(lambda x: 1 if x>=0 else 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07328677475452423"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.39454567e-01, 7.52588153e-01, 6.83116734e-01, 4.61570621e-01,\n",
       "       4.02424991e-01, 3.37669969e-01, 3.82321179e-01, 3.33395362e-01,\n",
       "       5.85768759e-01, 6.88278437e-01, 2.62758911e-01, 2.75974780e-01,\n",
       "       9.80989337e-02, 1.46716312e-01, 8.87530863e-01, 8.83317828e-01,\n",
       "       8.90939534e-01, 8.58695984e-01, 5.95020771e-01, 4.19137001e-01,\n",
       "       5.27171791e-01, 5.72955251e-01, 5.98161161e-01, 2.92360306e-01,\n",
       "       2.77923018e-01, 2.14789718e-01, 2.02044100e-02, 2.02076696e-02,\n",
       "       3.92205939e-02, 2.51391605e-02, 8.48680586e-02, 5.31205311e-02,\n",
       "       4.00014482e-02, 1.17443055e-01, 4.46203470e-01, 2.38876060e-01,\n",
       "       8.85829106e-02, 1.39824629e-01, 1.87421098e-01, 5.68981953e-02,\n",
       "       1.67066783e-01, 1.74240187e-01, 9.49490741e-02, 4.65382516e-01,\n",
       "       3.82439226e-01, 5.69667339e-01, 2.26931065e-01, 3.44949186e-01,\n",
       "       3.07848185e-01, 3.02148581e-01, 2.36473471e-01, 2.43432209e-01,\n",
       "       2.75846124e-01, 4.63919908e-01, 4.65336502e-01, 4.65031505e-01,\n",
       "       6.18871987e-01, 6.75097287e-01, 9.13882136e-01, 9.60368335e-01,\n",
       "       9.96621132e-01, 9.97519016e-01, 7.70542383e-01, 1.05526805e-01,\n",
       "       6.11790270e-02, 2.17662156e-02, 2.65936926e-03, 2.80505177e-02,\n",
       "       1.58892602e-01, 1.72488227e-01, 3.48761588e-01, 6.71017110e-01,\n",
       "       7.81803310e-01, 2.62967795e-01, 3.53697121e-01, 2.47670114e-01,\n",
       "       8.21534455e-01, 8.05114090e-01, 1.63255677e-01, 5.30920684e-01,\n",
       "       6.16965175e-01, 8.09842229e-01, 6.44679487e-01, 9.12673235e-01,\n",
       "       7.48362362e-01, 4.06878591e-01, 3.18002641e-01, 7.03408301e-01,\n",
       "       5.88618755e-01, 3.28749597e-01, 9.86357987e-01, 9.53018606e-01,\n",
       "       9.00448918e-01, 8.18585277e-01, 6.35233998e-01, 8.67019355e-01,\n",
       "       6.51390851e-01, 9.69894171e-01, 9.84869480e-01, 9.79654610e-01,\n",
       "       8.68520141e-01, 1.97353050e-01, 7.31176972e-01, 6.13173008e-01,\n",
       "       5.65291703e-01, 9.33157384e-01, 9.96637106e-01, 9.85293925e-01,\n",
       "       9.79474187e-01, 2.05373585e-01, 7.90151000e-01, 8.50507557e-01,\n",
       "       9.08959866e-01, 9.54034865e-01, 9.59877789e-01, 9.53164816e-01,\n",
       "       9.74744260e-01, 9.30088758e-01, 8.58710825e-01, 6.60591781e-01,\n",
       "       5.68766296e-01, 1.75611004e-01, 8.32054317e-01, 9.56069767e-01,\n",
       "       9.19851005e-01, 9.34563458e-01, 9.59447980e-01, 9.63401437e-01,\n",
       "       7.41723239e-01, 8.02367151e-01, 9.99239564e-01, 9.99658227e-01,\n",
       "       9.99888062e-01, 9.99739230e-01, 9.99430358e-01, 9.99909639e-01,\n",
       "       9.99146104e-01, 9.98462081e-01, 9.99376953e-01, 9.80056703e-01,\n",
       "       8.35430058e-07, 2.18820878e-05, 1.77370217e-02, 3.69642019e-01,\n",
       "       7.60716379e-01, 7.54626691e-02, 1.76948130e-01, 2.85904706e-01,\n",
       "       7.02978015e-01, 5.50140858e-01, 1.25441402e-02, 1.26394555e-01,\n",
       "       2.79642105e-01, 1.86406802e-02, 4.33494240e-01, 3.43954772e-01,\n",
       "       2.16590002e-01, 2.81462848e-01, 6.91058338e-02, 1.60111591e-01,\n",
       "       9.98873055e-01, 9.96320486e-01, 9.99981642e-01, 3.58732454e-02,\n",
       "       2.72401031e-02, 1.03792340e-01, 5.35768628e-01, 9.96452332e-01,\n",
       "       3.14365119e-01, 1.91952974e-01, 1.78739913e-02, 1.45856077e-02,\n",
       "       1.92035194e-02, 3.64972949e-02, 9.82402340e-02, 6.46363616e-01,\n",
       "       9.66315031e-01, 7.53546536e-01, 4.10068133e-05, 7.01646090e-01,\n",
       "       6.80490360e-02, 1.21180974e-02, 9.64915514e-01, 8.27565417e-02,\n",
       "       4.09745565e-03, 8.22613295e-03, 1.51064654e-03, 1.16164491e-01,\n",
       "       1.64680913e-01, 3.58858168e-01, 5.62070131e-01, 4.41240430e-01,\n",
       "       3.13727587e-01, 3.33069354e-01, 3.21978241e-01, 3.37416977e-01,\n",
       "       2.98363775e-01, 1.62203237e-01, 9.94988978e-02, 4.58120584e-01,\n",
       "       1.66095361e-01, 1.44804314e-01, 3.18745822e-02, 4.27062698e-02,\n",
       "       3.31753120e-02, 2.90047616e-01, 1.73933327e-01, 7.72888660e-02,\n",
       "       2.30160296e-01, 1.18972093e-01, 2.41055921e-01, 1.32463142e-01,\n",
       "       9.69349369e-02, 1.32249117e-01, 1.60090193e-01, 1.92955881e-01,\n",
       "       3.32070887e-01, 2.42070094e-01, 1.61316261e-01, 1.97696969e-01,\n",
       "       4.72605675e-01, 5.04178107e-01, 4.10779655e-01, 4.17911977e-01,\n",
       "       4.50325936e-01, 2.04116762e-01, 1.61364138e-01, 1.78574011e-01,\n",
       "       1.00618035e-01, 1.22194827e-01, 4.04555798e-02, 4.50308360e-02,\n",
       "       7.56724253e-02, 1.13710761e-01, 5.32459199e-01, 9.88620162e-01,\n",
       "       9.99760091e-01, 9.94376838e-01, 9.98453617e-01, 9.79418159e-01,\n",
       "       9.89575863e-01, 9.15323257e-01, 7.48925507e-02, 4.86560613e-01,\n",
       "       1.47860900e-01, 1.41585365e-01, 6.31313920e-01, 5.17752290e-01,\n",
       "       4.73151565e-01, 9.81443226e-01, 4.62454855e-02, 2.68061548e-01,\n",
       "       1.03727385e-01, 1.47502005e-01, 5.02412260e-01, 4.40573394e-01,\n",
       "       1.21082127e-01, 2.12574508e-02, 9.05347347e-01, 9.78337169e-01,\n",
       "       1.92624152e-01, 1.54937748e-02, 4.18569846e-03, 3.99611682e-01,\n",
       "       4.60587949e-01, 3.81120503e-01, 5.68926632e-01, 8.85283470e-01,\n",
       "       6.45657659e-01, 6.03026934e-02, 1.19031756e-04, 1.80497987e-03,\n",
       "       5.19505106e-02, 1.39810160e-01, 3.21515352e-02, 3.03718626e-01,\n",
       "       5.60412467e-01, 2.57507712e-01, 7.29548484e-02, 5.13364607e-03,\n",
       "       3.78979341e-04, 2.64427606e-02, 3.99511773e-03, 4.48803991e-01,\n",
       "       3.87114406e-01, 2.05990131e-04, 1.11209840e-01, 2.57849932e-01,\n",
       "       4.58478724e-04, 1.56777125e-04, 1.23845857e-05, 7.52942142e-05,\n",
       "       1.55690316e-06, 4.12408923e-07, 9.99689221e-01, 5.91666222e-01,\n",
       "       6.01158142e-01, 6.84457123e-01, 1.50167510e-01, 2.19489709e-01,\n",
       "       9.61317897e-01, 2.81783164e-01, 4.31263959e-03, 4.68853749e-02,\n",
       "       5.09815037e-01, 6.33592382e-02, 4.60899435e-03, 3.89808905e-03,\n",
       "       4.39121301e-04, 8.36135732e-05, 4.43597187e-10, 1.85348441e-07,\n",
       "       3.64909269e-04, 6.06083677e-06, 1.10571754e-07, 5.35954769e-07,\n",
       "       5.93995283e-05, 3.55141601e-05, 1.58105877e-06, 5.05589787e-06,\n",
       "       2.27643689e-03, 8.52554047e-04, 2.87673503e-01, 1.31656295e-02,\n",
       "       1.91077720e-02, 1.50504321e-01, 1.51101202e-02, 2.36184970e-01,\n",
       "       1.07609741e-01, 1.63089871e-01, 2.52881534e-02, 3.54144424e-02,\n",
       "       5.61392717e-02, 2.63314337e-01, 5.81169367e-01, 7.41421819e-01,\n",
       "       9.91976559e-01, 8.41474652e-01, 9.85934734e-01, 9.99996066e-01,\n",
       "       9.79847431e-01, 9.97404277e-01, 9.98561203e-01, 9.97355580e-01,\n",
       "       9.29560125e-01, 9.06303167e-01, 9.21457857e-02, 5.95483333e-02,\n",
       "       1.52881101e-01, 4.24816042e-01, 3.89016807e-01, 1.05848551e-01,\n",
       "       1.50399944e-02, 7.10034044e-03, 2.06913412e-01, 1.65953580e-02,\n",
       "       6.98138960e-03, 1.76790133e-02, 2.44119763e-02, 4.44968492e-01,\n",
       "       9.70853120e-02, 2.02345192e-01, 1.87001028e-03, 3.26477457e-04,\n",
       "       5.34900427e-01, 8.79993021e-01, 8.26253176e-01, 5.35759151e-01,\n",
       "       9.78816569e-01, 9.79362726e-01, 1.39972091e-01, 1.56867027e-01,\n",
       "       7.37846643e-02, 1.00789413e-01, 1.01633519e-02, 9.42697942e-01,\n",
       "       8.64077151e-01, 5.84274173e-01, 4.14912552e-01, 9.42247570e-01,\n",
       "       4.78225440e-04, 1.31715098e-02, 5.82088158e-03, 4.96351272e-01,\n",
       "       5.41245937e-01, 8.22450340e-01, 3.79055053e-01, 3.19123149e-01,\n",
       "       8.66853632e-04, 4.65007324e-05, 1.04688035e-04, 2.17670575e-04,\n",
       "       3.21314769e-06, 1.80593106e-05, 9.91862107e-05, 1.26459363e-05,\n",
       "       1.29794389e-01, 1.85510427e-01, 1.73364042e-05, 8.27239273e-06,\n",
       "       6.85244322e-01, 2.96659465e-03, 2.92761147e-01, 1.86000112e-02,\n",
       "       9.68788743e-01, 1.51538262e-02, 2.70850491e-04, 6.53271284e-03,\n",
       "       4.23155248e-01, 7.06865251e-01, 7.64549375e-01, 5.90867639e-01,\n",
       "       5.42336464e-01, 8.61807346e-01, 8.05612862e-01, 8.93519998e-01,\n",
       "       8.43712747e-01, 7.32224762e-01, 6.21370614e-01, 3.59695673e-01,\n",
       "       5.34265220e-01, 2.69843370e-01, 6.37334228e-01, 5.48903704e-01,\n",
       "       4.00061280e-01, 8.98754895e-01, 5.51329255e-01, 6.17050290e-01,\n",
       "       9.80785370e-01, 8.23682487e-01, 5.91912806e-01, 4.41113770e-01,\n",
       "       4.13030744e-01, 2.49705017e-01, 7.96843395e-02, 4.94971693e-01,\n",
       "       6.05127573e-01, 9.21168983e-01, 3.37531447e-01, 8.38353932e-02,\n",
       "       3.57840117e-03, 1.14661306e-02, 5.46745598e-01, 6.69771689e-04,\n",
       "       1.58551522e-03, 4.80934652e-03, 1.09143381e-03, 5.27629733e-01,\n",
       "       7.38701820e-01, 4.36981142e-01, 7.09956408e-01, 7.26150721e-02,\n",
       "       7.27202836e-03, 3.83675359e-02, 9.95612025e-01, 9.84039843e-01,\n",
       "       1.33512318e-01, 4.24372226e-01, 1.40552953e-01, 4.37314063e-01,\n",
       "       7.89907396e-01, 9.98473704e-01, 4.96349066e-01, 8.93124819e-01,\n",
       "       9.72509682e-01, 9.95953560e-01, 9.35109794e-01, 7.35171020e-01,\n",
       "       3.28792006e-01, 3.63744758e-02, 9.94415998e-01, 9.93621528e-01,\n",
       "       9.36945379e-01, 1.81379065e-01, 6.78982675e-01, 9.78458107e-01,\n",
       "       4.24916834e-01, 7.50108778e-01, 9.55455422e-01, 9.99787509e-01,\n",
       "       9.18742791e-02, 4.54087034e-02, 1.23841107e-01, 3.22353214e-01,\n",
       "       5.28214335e-01, 4.25701231e-01, 2.95085967e-01, 4.88747001e-01,\n",
       "       3.90531927e-01, 3.59655619e-01, 5.54992497e-01, 4.79399323e-01,\n",
       "       6.92317784e-01, 6.12295091e-01, 5.22899449e-01, 5.85080028e-01,\n",
       "       5.97198546e-01, 5.66463292e-01, 7.92007506e-01, 6.34567797e-01,\n",
       "       5.99582672e-01, 9.49317634e-01, 5.94038926e-02, 4.72617522e-03,\n",
       "       1.28741516e-03, 4.42655175e-04, 2.44908519e-02, 6.50542509e-03,\n",
       "       5.45439899e-01, 9.99999642e-01, 9.97097731e-01, 9.99077797e-01,\n",
       "       9.47911263e-01, 8.88342559e-01, 9.76627707e-01, 9.97221828e-01,\n",
       "       9.38111186e-01, 9.19492781e-01, 9.38846350e-01, 7.12335289e-01,\n",
       "       5.26597917e-01, 6.76339090e-01, 7.14552939e-01, 6.09012842e-01,\n",
       "       8.40301216e-01, 9.00576472e-01, 8.13068151e-01, 8.46447766e-01,\n",
       "       9.93351161e-01, 9.46518779e-01, 8.67225766e-01, 9.43902016e-01,\n",
       "       4.65574056e-01, 4.61239934e-01, 5.52940071e-01, 3.88157725e-01,\n",
       "       3.78755033e-01, 9.32927728e-01, 9.47161734e-01, 9.32951570e-01,\n",
       "       9.98131454e-01, 9.99617577e-01, 9.99994636e-01, 9.38799977e-01,\n",
       "       7.85814822e-01, 9.46097314e-01, 7.44682670e-01, 5.60805082e-01,\n",
       "       5.50451934e-01, 1.31800175e-01, 9.27970886e-01, 8.64980698e-01,\n",
       "       9.79423642e-01, 9.16890383e-01, 2.60823756e-01, 9.99427319e-01,\n",
       "       8.56908202e-01, 7.52383769e-01, 3.15116830e-02, 1.24056721e-02,\n",
       "       9.98934686e-01, 9.94743466e-01, 9.00113046e-01, 5.89741230e-01,\n",
       "       5.47107875e-01, 4.90470707e-01, 5.45550108e-01, 8.46554995e-01,\n",
       "       3.93704683e-01, 9.99944091e-01, 9.99993086e-01, 3.48914742e-01,\n",
       "       3.48914742e-01, 2.00685039e-01, 3.85586321e-01, 3.48914742e-01,\n",
       "       4.44273382e-01, 8.25227439e-01, 1.59316942e-01, 9.82396007e-01,\n",
       "       9.67543602e-01, 9.67276871e-01, 9.78539348e-01, 9.94325936e-01,\n",
       "       9.07024503e-01, 9.16672945e-01, 9.41537142e-01, 9.62376535e-01,\n",
       "       9.81473029e-01, 9.71600890e-01, 9.99906301e-01, 9.99992490e-01,\n",
       "       9.99997258e-01, 9.99817073e-01, 9.99999881e-01, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       3.15834612e-01, 4.24008042e-01, 2.30024114e-01, 2.48543888e-01,\n",
       "       9.30284381e-01, 9.86772954e-01, 8.56433094e-01, 9.95511711e-01,\n",
       "       7.64006376e-01, 7.49145329e-01, 2.48160332e-01, 8.40635896e-02,\n",
       "       9.12491858e-01, 5.80610335e-01, 3.18100423e-01, 1.95121720e-01,\n",
       "       4.67395008e-01, 7.93582201e-02, 1.18912555e-01, 8.75806808e-02,\n",
       "       2.70466954e-01, 2.98061490e-01, 2.84001827e-01, 2.75109470e-01,\n",
       "       1.90132633e-01, 1.90132633e-01, 1.90132633e-01, 3.38042289e-01,\n",
       "       4.36582744e-01, 4.40920681e-01, 5.85868835e-01, 4.06252891e-01,\n",
       "       5.25053859e-01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_yhat[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.39454567e-01, 7.52588153e-01, 6.83116734e-01, 4.61570621e-01,\n",
       "       4.02424991e-01, 3.37669969e-01, 3.82321179e-01, 3.33395362e-01,\n",
       "       5.85768759e-01, 6.88278437e-01, 2.62758911e-01, 2.75974780e-01,\n",
       "       9.80989337e-02, 1.46716312e-01, 8.87530863e-01, 8.83317828e-01,\n",
       "       8.90939534e-01, 8.58695984e-01, 5.95020771e-01, 4.19137001e-01,\n",
       "       5.27171791e-01, 5.72955251e-01, 5.98161161e-01, 2.92360306e-01,\n",
       "       2.77923018e-01, 2.14789718e-01, 2.02044100e-02, 2.02076696e-02,\n",
       "       3.92205939e-02, 2.51391605e-02, 8.48680586e-02, 5.31205311e-02,\n",
       "       4.00014482e-02, 1.17443055e-01, 4.46203470e-01, 2.38876060e-01,\n",
       "       8.85829106e-02, 1.39824629e-01, 1.87421098e-01, 5.68981953e-02,\n",
       "       1.67066783e-01, 1.74240187e-01, 9.49490741e-02, 4.65382516e-01,\n",
       "       3.82439226e-01, 5.69667339e-01, 2.26931065e-01, 3.44949186e-01,\n",
       "       3.07848185e-01, 3.02148581e-01, 2.36473471e-01, 2.43432209e-01,\n",
       "       2.75846124e-01, 4.63919908e-01, 4.65336502e-01, 4.65031505e-01,\n",
       "       6.18871987e-01, 6.75097287e-01, 9.13882136e-01, 9.60368335e-01,\n",
       "       9.96621132e-01, 9.97519016e-01, 7.70542383e-01, 1.05526805e-01,\n",
       "       6.11790270e-02, 2.17662156e-02, 2.65936926e-03, 2.80505177e-02,\n",
       "       1.58892602e-01, 1.72488227e-01, 3.48761588e-01, 6.71017110e-01,\n",
       "       7.81803310e-01, 2.62967795e-01, 3.53697121e-01, 2.47670114e-01,\n",
       "       8.21534455e-01, 8.05114090e-01, 1.63255677e-01, 5.30920684e-01,\n",
       "       6.16965175e-01, 8.09842229e-01, 6.44679487e-01, 9.12673235e-01,\n",
       "       7.48362362e-01, 4.06878591e-01, 3.18002641e-01, 7.03408301e-01,\n",
       "       5.88618755e-01, 3.28749597e-01, 9.86357987e-01, 9.53018606e-01,\n",
       "       9.00448918e-01, 8.18585277e-01, 6.35233998e-01, 8.67019355e-01,\n",
       "       6.51390851e-01, 9.69894171e-01, 9.84869480e-01, 9.79654610e-01,\n",
       "       8.68520141e-01, 1.97353050e-01, 7.31176972e-01, 6.13173008e-01,\n",
       "       5.65291703e-01, 9.33157384e-01, 9.96637106e-01, 9.85293925e-01,\n",
       "       9.79474187e-01, 2.05373585e-01, 7.90151000e-01, 8.50507557e-01,\n",
       "       9.08959866e-01, 9.54034865e-01, 9.59877789e-01, 9.53164816e-01,\n",
       "       9.74744260e-01, 9.30088758e-01, 8.58710825e-01, 6.60591781e-01,\n",
       "       5.68766296e-01, 1.75611004e-01, 8.32054317e-01, 9.56069767e-01,\n",
       "       9.19851005e-01, 9.34563458e-01, 9.59447980e-01, 9.63401437e-01,\n",
       "       7.41723239e-01, 8.02367151e-01, 9.99239564e-01, 9.99658227e-01,\n",
       "       9.99888062e-01, 9.99739230e-01, 9.99430358e-01, 9.99909639e-01,\n",
       "       9.99146104e-01, 9.98462081e-01, 9.99376953e-01, 9.80056703e-01,\n",
       "       8.35430058e-07, 2.18820878e-05, 1.77370217e-02, 3.69642019e-01,\n",
       "       7.60716379e-01, 7.54626691e-02, 1.76948130e-01, 2.85904706e-01,\n",
       "       7.02978015e-01, 5.50140858e-01, 1.25441402e-02, 1.26394555e-01,\n",
       "       2.79642105e-01, 1.86406802e-02, 4.33494240e-01, 3.43954772e-01,\n",
       "       2.16590002e-01, 2.81462848e-01, 6.91058338e-02, 1.60111591e-01,\n",
       "       9.98873055e-01, 9.96320486e-01, 9.99981642e-01, 3.58732454e-02,\n",
       "       2.72401031e-02, 1.03792340e-01, 5.35768628e-01, 9.96452332e-01,\n",
       "       3.14365119e-01, 1.91952974e-01, 1.78739913e-02, 1.45856077e-02,\n",
       "       1.92035194e-02, 3.64972949e-02, 9.82402340e-02, 6.46363616e-01,\n",
       "       9.66315031e-01, 7.53546536e-01, 4.10068133e-05, 7.01646090e-01,\n",
       "       6.80490360e-02, 1.21180974e-02, 9.64915514e-01, 8.27565417e-02,\n",
       "       4.09745565e-03, 8.22613295e-03, 1.51064654e-03, 1.16164491e-01,\n",
       "       1.64680913e-01, 3.58858168e-01, 5.62070131e-01, 4.41240430e-01,\n",
       "       3.13727587e-01, 3.33069354e-01, 3.21978241e-01, 3.37416977e-01,\n",
       "       2.98363775e-01, 1.62203237e-01, 9.94988978e-02, 4.58120584e-01,\n",
       "       1.66095361e-01, 1.44804314e-01, 3.18745822e-02, 4.27062698e-02,\n",
       "       3.31753120e-02, 2.90047616e-01, 1.73933327e-01, 7.72888660e-02,\n",
       "       2.30160296e-01, 1.18972093e-01, 2.41055921e-01, 1.32463142e-01,\n",
       "       9.69349369e-02, 1.32249117e-01, 1.60090193e-01, 1.92955881e-01,\n",
       "       3.32070887e-01, 2.42070094e-01, 1.61316261e-01, 1.97696969e-01,\n",
       "       4.72605675e-01, 5.04178107e-01, 4.10779655e-01, 4.17911977e-01,\n",
       "       4.50325936e-01, 2.04116762e-01, 1.61364138e-01, 1.78574011e-01,\n",
       "       1.00618035e-01, 1.22194827e-01, 4.04555798e-02, 4.50308360e-02,\n",
       "       7.56724253e-02, 1.13710761e-01, 5.32459199e-01, 9.88620162e-01,\n",
       "       9.99760091e-01, 9.94376838e-01, 9.98453617e-01, 9.79418159e-01,\n",
       "       9.89575863e-01, 9.15323257e-01, 7.48925507e-02, 4.86560613e-01,\n",
       "       1.47860900e-01, 1.41585365e-01, 6.31313920e-01, 5.17752290e-01,\n",
       "       4.73151565e-01, 9.81443226e-01, 4.62454855e-02, 2.68061548e-01,\n",
       "       1.03727385e-01, 1.47502005e-01, 5.02412260e-01, 4.40573394e-01,\n",
       "       1.21082127e-01, 2.12574508e-02, 9.05347347e-01, 9.78337169e-01,\n",
       "       1.92624152e-01, 1.54937748e-02, 4.18569846e-03, 3.99611682e-01,\n",
       "       4.60587949e-01, 3.81120503e-01, 5.68926632e-01, 8.85283470e-01,\n",
       "       6.45657659e-01, 6.03026934e-02, 1.19031756e-04, 1.80497987e-03,\n",
       "       5.19505106e-02, 1.39810160e-01, 3.21515352e-02, 3.03718626e-01,\n",
       "       5.60412467e-01, 2.57507712e-01, 7.29548484e-02, 5.13364607e-03,\n",
       "       3.78979341e-04, 2.64427606e-02, 3.99511773e-03, 4.48803991e-01,\n",
       "       3.87114406e-01, 2.05990131e-04, 1.11209840e-01, 2.57849932e-01,\n",
       "       4.58478724e-04, 1.56777125e-04, 1.23845857e-05, 7.52942142e-05,\n",
       "       1.55690316e-06, 4.12408923e-07, 9.99689221e-01, 5.91666222e-01,\n",
       "       6.01158142e-01, 6.84457123e-01, 1.50167510e-01, 2.19489709e-01,\n",
       "       9.61317897e-01, 2.81783164e-01, 4.31263959e-03, 4.68853749e-02,\n",
       "       5.09815037e-01, 6.33592382e-02, 4.60899435e-03, 3.89808905e-03,\n",
       "       4.39121301e-04, 8.36135732e-05, 4.43597187e-10, 1.85348441e-07,\n",
       "       3.64909269e-04, 6.06083677e-06, 1.10571754e-07, 5.35954769e-07,\n",
       "       5.93995283e-05, 3.55141601e-05, 1.58105877e-06, 5.05589787e-06,\n",
       "       2.27643689e-03, 8.52554047e-04, 2.87673503e-01, 1.31656295e-02,\n",
       "       1.91077720e-02, 1.50504321e-01, 1.51101202e-02, 2.36184970e-01,\n",
       "       1.07609741e-01, 1.63089871e-01, 2.52881534e-02, 3.54144424e-02,\n",
       "       5.61392717e-02, 2.63314337e-01, 5.81169367e-01, 7.41421819e-01,\n",
       "       9.91976559e-01, 8.41474652e-01, 9.85934734e-01, 9.99996066e-01,\n",
       "       9.79847431e-01, 9.97404277e-01, 9.98561203e-01, 9.97355580e-01,\n",
       "       9.29560125e-01, 9.06303167e-01, 9.21457857e-02, 5.95483333e-02,\n",
       "       1.52881101e-01, 4.24816042e-01, 3.89016807e-01, 1.05848551e-01,\n",
       "       1.50399944e-02, 7.10034044e-03, 2.06913412e-01, 1.65953580e-02,\n",
       "       6.98138960e-03, 1.76790133e-02, 2.44119763e-02, 4.44968492e-01,\n",
       "       9.70853120e-02, 2.02345192e-01, 1.87001028e-03, 3.26477457e-04,\n",
       "       5.34900427e-01, 8.79993021e-01, 8.26253176e-01, 5.35759151e-01,\n",
       "       9.78816569e-01, 9.79362726e-01, 1.39972091e-01, 1.56867027e-01,\n",
       "       7.37846643e-02, 1.00789413e-01, 1.01633519e-02, 9.42697942e-01,\n",
       "       8.64077151e-01, 5.84274173e-01, 4.14912552e-01, 9.42247570e-01,\n",
       "       4.78225440e-04, 1.31715098e-02, 5.82088158e-03, 4.96351272e-01,\n",
       "       5.41245937e-01, 8.22450340e-01, 3.79055053e-01, 3.19123149e-01,\n",
       "       8.66853632e-04, 4.65007324e-05, 1.04688035e-04, 2.17670575e-04,\n",
       "       3.21314769e-06, 1.80593106e-05, 9.91862107e-05, 1.26459363e-05,\n",
       "       1.29794389e-01, 1.85510427e-01, 1.73364042e-05, 8.27239273e-06,\n",
       "       6.85244322e-01, 2.96659465e-03, 2.92761147e-01, 1.86000112e-02,\n",
       "       9.68788743e-01, 1.51538262e-02, 2.70850491e-04, 6.53271284e-03,\n",
       "       4.23155248e-01, 7.06865251e-01, 7.64549375e-01, 5.90867639e-01,\n",
       "       5.42336464e-01, 8.61807346e-01, 8.05612862e-01, 8.93519998e-01,\n",
       "       8.43712747e-01, 7.32224762e-01, 6.21370614e-01, 3.59695673e-01,\n",
       "       5.34265220e-01, 2.69843370e-01, 6.37334228e-01, 5.48903704e-01,\n",
       "       4.00061280e-01, 8.98754895e-01, 5.51329255e-01, 6.17050290e-01,\n",
       "       9.80785370e-01, 8.23682487e-01, 5.91912806e-01, 4.41113770e-01,\n",
       "       4.13030744e-01, 2.49705017e-01, 7.96843395e-02, 4.94971693e-01,\n",
       "       6.05127573e-01, 9.21168983e-01, 3.37531447e-01, 8.38353932e-02,\n",
       "       3.57840117e-03, 1.14661306e-02, 5.46745598e-01, 6.69771689e-04,\n",
       "       1.58551522e-03, 4.80934652e-03, 1.09143381e-03, 5.27629733e-01,\n",
       "       7.38701820e-01, 4.36981142e-01, 7.09956408e-01, 7.26150721e-02,\n",
       "       7.27202836e-03, 3.83675359e-02, 9.95612025e-01, 9.84039843e-01,\n",
       "       1.33512318e-01, 4.24372226e-01, 1.40552953e-01, 4.37314063e-01,\n",
       "       7.89907396e-01, 9.98473704e-01, 4.96349066e-01, 8.93124819e-01,\n",
       "       9.72509682e-01, 9.95953560e-01, 9.35109794e-01, 7.35171020e-01,\n",
       "       3.28792006e-01, 3.63744758e-02, 9.94415998e-01, 9.93621528e-01,\n",
       "       9.36945379e-01, 1.81379065e-01, 6.78982675e-01, 9.78458107e-01,\n",
       "       4.24916834e-01, 7.50108778e-01, 9.55455422e-01, 9.99787509e-01,\n",
       "       9.18742791e-02, 4.54087034e-02, 1.23841107e-01, 3.22353214e-01,\n",
       "       5.28214335e-01, 4.25701231e-01, 2.95085967e-01, 4.88747001e-01,\n",
       "       3.90531927e-01, 3.59655619e-01, 5.54992497e-01, 4.79399323e-01,\n",
       "       6.92317784e-01, 6.12295091e-01, 5.22899449e-01, 5.85080028e-01,\n",
       "       5.97198546e-01, 5.66463292e-01, 7.92007506e-01, 6.34567797e-01,\n",
       "       5.99582672e-01, 9.49317634e-01, 5.94038926e-02, 4.72617522e-03,\n",
       "       1.28741516e-03, 4.42655175e-04, 2.44908519e-02, 6.50542509e-03,\n",
       "       5.45439899e-01, 9.99999642e-01, 9.97097731e-01, 9.99077797e-01,\n",
       "       9.47911263e-01, 8.88342559e-01, 9.76627707e-01, 9.97221828e-01,\n",
       "       9.38111186e-01, 9.19492781e-01, 9.38846350e-01, 7.12335289e-01,\n",
       "       5.26597917e-01, 6.76339090e-01, 7.14552939e-01, 6.09012842e-01,\n",
       "       8.40301216e-01, 9.00576472e-01, 8.13068151e-01, 8.46447766e-01,\n",
       "       9.93351161e-01, 9.46518779e-01, 8.67225766e-01, 9.43902016e-01,\n",
       "       4.65574056e-01, 4.61239934e-01, 5.52940071e-01, 3.88157725e-01,\n",
       "       3.78755033e-01, 9.32927728e-01, 9.47161734e-01, 9.32951570e-01,\n",
       "       9.98131454e-01, 9.99617577e-01, 9.99994636e-01, 9.38799977e-01,\n",
       "       7.85814822e-01, 9.46097314e-01, 7.44682670e-01, 5.60805082e-01,\n",
       "       5.50451934e-01, 1.31800175e-01, 9.27970886e-01, 8.64980698e-01,\n",
       "       9.79423642e-01, 9.16890383e-01, 2.60823756e-01, 9.99427319e-01,\n",
       "       8.56908202e-01, 7.52383769e-01, 3.15116830e-02, 1.24056721e-02,\n",
       "       9.98934686e-01, 9.94743466e-01, 9.00113046e-01, 5.89741230e-01,\n",
       "       5.47107875e-01, 4.90470707e-01, 5.45550108e-01, 8.46554995e-01,\n",
       "       3.93704683e-01, 9.99944091e-01, 9.99993086e-01, 3.48914742e-01,\n",
       "       3.48914742e-01, 2.00685039e-01, 3.85586321e-01, 3.48914742e-01,\n",
       "       4.44273382e-01, 8.25227439e-01, 1.59316942e-01, 9.82396007e-01,\n",
       "       9.67543602e-01, 9.67276871e-01, 9.78539348e-01, 9.94325936e-01,\n",
       "       9.07024503e-01, 9.16672945e-01, 9.41537142e-01, 9.62376535e-01,\n",
       "       9.81473029e-01, 9.71600890e-01, 9.99906301e-01, 9.99992490e-01,\n",
       "       9.99997258e-01, 9.99817073e-01, 9.99999881e-01, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       3.15834612e-01, 4.24008042e-01, 2.30024114e-01, 2.48543888e-01,\n",
       "       9.30284381e-01, 9.86772954e-01, 8.56433094e-01, 9.95511711e-01,\n",
       "       7.64006376e-01, 7.49145329e-01, 2.48160332e-01, 8.40635896e-02,\n",
       "       9.12491858e-01, 5.80610335e-01, 3.18100423e-01, 1.95121720e-01,\n",
       "       4.67395008e-01, 7.93582201e-02, 1.18912555e-01, 8.75806808e-02,\n",
       "       2.70466954e-01, 2.98061490e-01, 2.84001827e-01, 2.75109470e-01,\n",
       "       1.90132633e-01, 1.90132633e-01, 1.90132633e-01, 3.38042289e-01,\n",
       "       4.36582744e-01, 4.40920681e-01, 5.85868835e-01, 4.06252891e-01,\n",
       "       5.25053859e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_yhat[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_y[:,2]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30057803468208094"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "208/692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropout后正确率的变化情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./pnl1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>y</th>\n",
       "      <th>yhat_lstm</th>\n",
       "      <th>yhat_lstm_0</th>\n",
       "      <th>yhat_lstm_1</th>\n",
       "      <th>predict</th>\n",
       "      <th>predicttrue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016/3/24</td>\n",
       "      <td>0.253108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480324</td>\n",
       "      <td>0.519676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016/3/25</td>\n",
       "      <td>0.138903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473298</td>\n",
       "      <td>0.526702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016/3/28</td>\n",
       "      <td>0.074396</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.547318</td>\n",
       "      <td>0.452682</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016/3/29</td>\n",
       "      <td>0.262786</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.591885</td>\n",
       "      <td>0.408115</td>\n",
       "      <td>-0.262786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016/3/30</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.545468</td>\n",
       "      <td>0.454532</td>\n",
       "      <td>-0.039596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016/3/31</td>\n",
       "      <td>-0.074230</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.564916</td>\n",
       "      <td>0.435084</td>\n",
       "      <td>0.074230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016/4/1</td>\n",
       "      <td>-0.267658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437431</td>\n",
       "      <td>0.562569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016/4/5</td>\n",
       "      <td>-0.630353</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454454</td>\n",
       "      <td>0.545546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016/4/6</td>\n",
       "      <td>-0.238202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417903</td>\n",
       "      <td>0.582097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016/4/7</td>\n",
       "      <td>-0.148832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016/4/8</td>\n",
       "      <td>-0.133952</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.524868</td>\n",
       "      <td>0.475132</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016/4/11</td>\n",
       "      <td>-0.436704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464419</td>\n",
       "      <td>0.535581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016/4/12</td>\n",
       "      <td>-0.515977</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.788603</td>\n",
       "      <td>0.211397</td>\n",
       "      <td>0.515977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016/4/13</td>\n",
       "      <td>-0.416709</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.775104</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.416709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016/4/14</td>\n",
       "      <td>-0.362977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195095</td>\n",
       "      <td>0.804905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016/4/15</td>\n",
       "      <td>0.164175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176371</td>\n",
       "      <td>0.823629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>-0.094445</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235536</td>\n",
       "      <td>0.764464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016/4/19</td>\n",
       "      <td>-0.039726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330066</td>\n",
       "      <td>0.669934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016/4/20</td>\n",
       "      <td>-0.114249</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334891</td>\n",
       "      <td>0.665109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016/4/21</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380483</td>\n",
       "      <td>0.619517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         y  yhat_lstm  yhat_lstm_0  yhat_lstm_1   predict  \\\n",
       "0   2016/3/24  0.253108          0     0.480324     0.519676  0.000000   \n",
       "1   2016/3/25  0.138903          0     0.473298     0.526702  0.000000   \n",
       "2   2016/3/28  0.074396         -1     0.547318     0.452682 -0.074396   \n",
       "3   2016/3/29  0.262786         -1     0.591885     0.408115 -0.262786   \n",
       "4   2016/3/30  0.039596         -1     0.545468     0.454532 -0.039596   \n",
       "5   2016/3/31 -0.074230         -1     0.564916     0.435084  0.074230   \n",
       "6    2016/4/1 -0.267658          0     0.437431     0.562569  0.000000   \n",
       "7    2016/4/5 -0.630353          0     0.454454     0.545546  0.000000   \n",
       "8    2016/4/6 -0.238202          0     0.417903     0.582097  0.000000   \n",
       "9    2016/4/7 -0.148832          0     0.490741     0.509259  0.000000   \n",
       "10   2016/4/8 -0.133952         -1     0.524868     0.475132  0.133952   \n",
       "11  2016/4/11 -0.436704          0     0.464419     0.535581  0.000000   \n",
       "12  2016/4/12 -0.515977         -1     0.788603     0.211397  0.515977   \n",
       "13  2016/4/13 -0.416709         -1     0.775104     0.224896  0.416709   \n",
       "14  2016/4/14 -0.362977          0     0.195095     0.804905  0.000000   \n",
       "15  2016/4/15  0.164175          0     0.176371     0.823629  0.000000   \n",
       "16  2016/4/18 -0.094445          0     0.235536     0.764464  0.000000   \n",
       "17  2016/4/19 -0.039726          0     0.330066     0.669934  0.000000   \n",
       "18  2016/4/20 -0.114249          0     0.334891     0.665109  0.000000   \n",
       "19  2016/4/21  0.293000          0     0.380483     0.619517  0.000000   \n",
       "\n",
       "    predicttrue  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "5             1  \n",
       "6             1  \n",
       "7             1  \n",
       "8             1  \n",
       "9             1  \n",
       "10            1  \n",
       "11            1  \n",
       "12            1  \n",
       "13            1  \n",
       "14            1  \n",
       "15            1  \n",
       "16            1  \n",
       "17            1  \n",
       "18            1  \n",
       "19            1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_yhat = df1[['yhat_lstm_0','yhat_lstm_1']].values\n",
    "y_raw = df1.y.values\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(y_raw[sample_yhat.argmax(axis=1)==1],color=\"r\",bins=30,kde=True)\n",
    "sns.distplot(y_raw[sample_yhat.argmax(axis=1)==0],color=\"b\",bins=30,kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25310815,  0.13890269, -0.26765815, -0.63035325, -0.23820169,\n",
       "       -0.1488317 , -0.43670359, -0.36297681,  0.16417506, -0.09444514,\n",
       "       -0.03972589, -0.11424883,  0.29300048,  0.32260494,  0.54149515,\n",
       "        0.42128281, -0.13348167, -0.18351814,  0.40723139,  0.18359099,\n",
       "        0.22331961,  0.37194122,  0.42599628,  0.31722455,  0.26771123,\n",
       "       -0.18800718,  0.05935599, -0.05435454,  0.07897335,  0.27652973,\n",
       "        0.38535693,  0.44462083,  0.25183333,  0.06905056,  0.11827905,\n",
       "        0.16258965,  0.26121901,  0.26559134,  0.52073216,  0.57922801,\n",
       "        0.45182279,  0.25526498,  0.27486029,  0.13743683,  0.19136884,\n",
       "        0.01962998, -0.18636592, -0.2990125 , -0.039208  , -0.22081022,\n",
       "       -0.12270241, -0.19155683, -0.15229302, -0.14738396, -0.53574629,\n",
       "       -0.49652291, -0.32473951,  0.01478379,  0.08374591,  0.19211355,\n",
       "        0.17728755,  0.16249357,  0.32470756,  0.29521769,  0.16728171,\n",
       "        0.20653036,  0.2064796 ,  0.26044881,  0.21625881,  0.33400493,\n",
       "        0.31386422,  0.34332272,  0.20625652,  0.05402087, -0.11793613,\n",
       "        0.        ,  0.0441772 , -0.25531511, -0.0098121 , -0.10802849,\n",
       "       -0.31475952, -0.32044199, -0.4005841 , -0.51006623, -0.35608346,\n",
       "       -0.39549191,  0.03963535, -3.18573603, -2.09227313,  0.14129998,\n",
       "       -0.06068575, -1.19207709, -1.05049846, -1.14149028,  0.44568319,\n",
       "        0.65699938,  0.77786027,  0.33314856,  0.38884028,  0.39894006,\n",
       "       -0.16140425, -0.50604834, -0.4601429 , -0.87248195, -0.15231522,\n",
       "       -0.43399522,  0.26018432, -0.14771428,  0.17464562,  0.10786656,\n",
       "       -0.03082456,  0.18510906,  0.19024609,  0.20072577,  0.09772909,\n",
       "       -0.87902486, -0.4988311 , -0.28316234, -0.80980509, -0.38043666,\n",
       "        0.55151024,  0.62980039,  0.03112679,  0.06224389,  0.25953817,\n",
       "        0.54993653,  0.42026679,  0.18676079, -0.17126402, -0.16602681,\n",
       "       -0.08294454,  0.26063401,  0.14601588,  0.07812704, -0.06255539,\n",
       "        0.02607086,  0.05725737,  0.32746865,  0.84121381,  0.6484266 ,\n",
       "        0.50814171,  0.63288067,  0.66410953,  0.82035766,  0.53455248,\n",
       "        0.        ,  0.04135863,  0.4910205 ,  0.43410921,  0.26858133,\n",
       "        0.25830463,  0.0671505 , -0.21145473, -0.0051561 , -0.17031823,\n",
       "       -0.04125625,  0.07732158,  0.13402064,  0.45300191,  0.62799403,\n",
       "        1.22637964,  0.9953394 ,  1.18618043,  0.87816715,  0.91811996,\n",
       "        0.79526342,  0.58380869,  0.25623957,  0.04094166, -0.04095423,\n",
       "        0.21526327,  0.43557424,  0.28175526,  0.08191686,  0.12290047,\n",
       "        0.18953467, -0.02046873,  0.05119017, -0.36900411, -0.16390088,\n",
       "       -0.00511784,  0.09718919,  0.32699804,  0.0869632 ,  0.30659196,\n",
       "        0.5877109 ,  0.69586855,  0.53679738,  0.50030735,  0.48962203,\n",
       "        0.37676334,  0.78435769,  0.30038462,  0.12738531, -0.07131941,\n",
       "       -0.15274952, -0.30995172,  0.0762292 ,  0.18291759,  0.06112781,\n",
       "       -0.10666126, -0.37467645,  0.04586805,  0.03565153,  0.18823296,\n",
       "        0.30896008,  1.04391491, -0.00513914, -0.13866422, -0.14898921,\n",
       "       -0.10796084, -0.14394409, -0.12850499,  0.40039066, -0.09829027,\n",
       "       -0.23819398, -0.25370868, -0.2018791 , -0.20186865, -0.0621311 ,\n",
       "        0.33674426, -0.07756147, -0.48567361, -0.11237678,  0.02551997,\n",
       "        0.0868832 , -0.16351562, -0.17390419, -0.09195403,  0.0869721 ,\n",
       "        0.2098959 , -0.29131444, -0.43517284, -0.42023328, -0.21011103,\n",
       "       -0.2148888 , -0.19963663, -0.26115692, -0.93265717, -0.95362665,\n",
       "       -0.66903546, -0.63388414, -0.46543828, -0.22002209, -0.37329695,\n",
       "       -0.30185999,  0.40979465,  0.63049649])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw[sample_yhat.argmax(axis=1)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
